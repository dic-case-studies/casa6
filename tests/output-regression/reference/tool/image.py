##################### generated by xml-casa (v2) from image.xml #####################
##################### 90eb06e41daf9aec99dc623b2fc874f3 ##############################
from __future__ import absolute_import 
from .__casac__ import image as _image
from .platform import str_encode as _str_ec
from .platform import str_decode as _str_dc
from .platform import dict_encode as _dict_ec
from .platform import dict_decode as _dict_dc
from .platform import dict_encode as _quant_ec
from .platform import dict_decode as _quant_dc
from .platform import encode as _any_ec
from .platform import decode as _any_dc
from .typecheck import validator as _pc
from .coercetype import coerce as _coerce
from .coordsys import coordsys as _wrap_coordsys
from .componentlist import componentlist as _wrap_componentlist
_wrap_image = lambda swig_object: image(swig_object=swig_object)

class image:
    ### self
    def __init__(self, *args, **kwargs):
        """
        """
        self._swigobj = kwargs.get('swig_object',None)
        if self._swigobj is None:
            self._swigobj = _image()

    def newimage(self, infile):
        """This method is identical to ia.newimagefromfile(). The description of
        how it works is in the online help for that method.
        """
        schema = {'infile': {'type': 'cStr'}}
        doc = {'infile': infile}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _newimage_result = _wrap_image(swig_object=self._swigobj.newimage(_str_ec(_pc.document['infile'])))
        return _newimage_result

    def newimagefromfile(self, infile):
        """This method returns an image analysis tool associated with the specified image.
        Constructing a image analysis tool in addition to the default ia tool allows the
        user to operate on multiple images without having to close one
        before opening another. All ia.newimagefrom*() methods share this functionality.
        
        The parameter infile may refer to a CASA image, a Miriad image, or a FITS image.
        FITS images of types Float, Double, Long, and Short are supported.
        
        When finished with the newly created tool, the user should close it to free
        up system resources (eg memory).
        
        ia.newimage() is an alias for this method.
        """
        schema = {'infile': {'type': 'cStr'}}
        doc = {'infile': infile}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _newimagefromfile_result = _wrap_image(swig_object=self._swigobj.newimagefromfile(_str_ec(_pc.document['infile'])))
        return _newimagefromfile_result

    def imagecalc(self, outfile='', pixels='', overwrite=False, imagemd=''):
        """This method is used to evaluate a mathematical expression involving
        existing images. It fully supports both float and complex valued images.
        The syntax of the expression supplied via the pixels
        parameter (in what is called the Lattice Expression Language, or LEL) is
        explained in detail in htmladdnormallink{note
        223}{http://aips2.nrao.edu/docs/notes/223/223.html}. This is a rich
        mathematical language with allows all manner of mathematical operations
        to be applied to images.
        
        Any image files embedded in the expression may be native casa or
        fits (but not yet Miriad) images.
        
        If successful, this method always returns an image analysis tool that
        references the image resulting from the calculation. This returned tool
        should always be captured and closed as soon as the user is done with it
        to free up system resources (eg, memory). The image analysis tool on which
        the method is called (eg the ia tool when one runs ia.imagecalc()) remains
        unaltered, eg it still refers to the same image it did prior to the imagecalc()
        call.
        
        Values of the returned tool are evaluated "on demand". That is, only when a method
        is run on the returned tool are the necessary values computed. And in fact, the
        values have to be reevaluated for each operation (method call). This means that
        there is a small performance hit for using the returned tool rather than the image
        written to disk and that none of the images which were used in the expression
        should be deleted while the returned tool is in use because they must be accessed
        for calculating the expression each time an operation of the returned tool is
        performed. These limitations do not apply to the ouput image if one is specified
        with the outfile parameter; it is a genuine CASA image with
        numerical values. If outfile is blank, no ouput image is written (although
        the resulting image can still be accessed via the returned image analysis tool
        as described below).
        
        Normally you should just write the image, close the returned
        tool, and open the results image with the default ia tool and operate on it. If
        you are interested in conserving disk space, you don't need to keep the result of
        the calculation around for very long, and/or you are only going to do a small
        number of operations on the result image, should you set outfile="".
        
        Note that when multiple image are used in the expression, there is
        no garauntee about which of those images will be used to create the metadata
        of the output image, unless imagemd is specified. If imagemd is specified, the following
        rules of metadata copying will be followed:
        
        1. The pixel data type of the image specified by imagemd and the output image must
        be the same.
        2. The metadata copied include the coordinate system (and so of course the dimensionality of
        the output image must correspond to the coordinate system to be copied), the image_info record
        (which contains things like the beam(s)), the misc_info record (should one exist in the image
        specified by imagemd), and the units.
        3. If the output image is a spectral image, the brightness units are set to the empty string.
        4. If the ouptut image is a polarization angle image, the brightness unit is set to "deg" and
        the stokes coordinate is set to have a single plane of type of Pangle.
        
        
        """
        schema = {'outfile': {'type': 'cStr'}, 'pixels': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'imagemd': {'type': 'cStr'}}
        doc = {'outfile': outfile, 'pixels': pixels, 'overwrite': overwrite, 'imagemd': imagemd}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _imagecalc_result = _wrap_image(swig_object=self._swigobj.imagecalc(_str_ec(_pc.document['outfile']), _str_ec(_pc.document['pixels']), _pc.document['overwrite'], _str_ec(_pc.document['imagemd'])))
        return _imagecalc_result

    def collapse(self, function='', axes=[ ], outfile='', region='', box='', chans='', stokes='', mask='', overwrite=False, stretch=False):
        """This method collapses an image along a specified axis or set of axes of length N pixels to a single pixel on each
        specified axis. Both float valued and complex valued images are supported. It computes a user-specified aggregate
        function for pixel values along the specified axes, and places those values in the single remaining plane of
        those axes in the output image. The method returns an image analysis tool containing the newly-created collapsed
        image. Valid choices of aggregate functions are: 'flux' (see below for constraitns), 'madm' (median absolute
        deviation from the median), 'max', 'mean', 'median', 'min', 'npts', 'rms', 'stddev', 'sum', 'variance' and 'xmadm'
        (median absolute deviation from the median multipied by x, where x is the reciprocal of Phi^-1(3/4), where Phi^-1
        is the reciprocal of the quantile function. Numerically, x = 1.482602218505602. See, eg,
        https://en.wikipedia.org/wiki/Median_absolute_deviation#Relation_to_standard_deviation). Minimal unique matching is
        supported for the function parameter (e.g. function = 'r' will compute the rms of the pixel values, 'med' will
        compute the median, etc.).
        
        If one specifies function='flux', the following constraints must be true:
        
        1. The image must have a direction coordinate,
        2. The image must have at least one beam,
        3. The specified axes must be exactly the direction coordinate axes,
        4. Only one of the non-directional axes may be non-degenerate,
        5. The iamge brightness unit must be conformant with x*yJy/beam, where x is an optional unit (such as km/s for moments images)
        and y is an optional SI prefix.
        
        Axes may be specified as a single integer or an array of integers indicating the zero-based
        axes along which to collapse the image. Axes may also be specified as a single or array of strings which
        minimally and uniquely match (ignoring case) world axis names in the image (e.g. 'dec' for
        collapsing along the declination axis or ['ri', 'd'] for collapsing along both the right ascension and
        declination axes).
        
        If outfile is not specified (or contains only whitespace characters), no image is written but the
        collapsed image is still accessible via the image analysis tool this method always returns (which
        references the collapsed image). If the returned object is not wanted, it should still be
        captured and destroyed via its done() method.  If this is not done, there is no guarantee
        as to when the Python garbage collector will delete it. If the returned object is wanted, it
        should still be deleted as soon as possible for the same reasons, e.g.
        
        collapsed_image = ia.collapse(...)
        begin{verbatim}
        # do things (or not) with the collapsed_image and when finished working with the object, do
        end{verbatim}
        collapsed_image.done()
        
        The reference pixel of the collapsed axis is set to 0 and its reference value is set to the mean
        of the the first and last values of that axis in the specified region of the input image. The
        reference value is the world coordinate value of the reference pixel. For instance, if an axis
        to be collapsed were to be the frequency axis, in the collapsed image, the reference value would
        be the mean value of the frequency range spanned, and would be stored in pixel 0.
        
        If the input image has per plane beams, the beam at the origin of the subimage determined by
        the selected region is arbitrarily made the global beam of the output image. In general, the user
        should understand the pitfalls of collapsing images with multiple beams (i.e. that employing an
        aggregate function on pixels with varying beam sizes more often than not leads to ill-defined
        results).  Convolution to a common beam is not performed automatically as part of the preprocessing
        before the actual rebinning occurs.  In such cases, therefore, the user should probably first
        convolve the input image with a common restoring beam so that each plane has the same resolution,
        and/or use imsmooth to smooth the data to have the same beam.
        
        
        """
        schema = {'function': {'type': 'cStr'}, 'axes': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'outfile': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cStr'}, {'type': 'cDict'}]}, 'box': {'type': 'cStr'}, 'chans': {'type': 'cStr'}, 'stokes': {'type': 'cStr'}, 'mask': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'function': function, 'axes': axes, 'outfile': outfile, 'region': region, 'box': box, 'chans': chans, 'stokes': stokes, 'mask': mask, 'overwrite': overwrite, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _collapse_result = _wrap_image(swig_object=self._swigobj.collapse(_str_ec(_pc.document['function']), _any_ec(_pc.document['axes']), _str_ec(_pc.document['outfile']), _any_ec(_pc.document['region']), _str_ec(_pc.document['box']), _str_ec(_pc.document['chans']), _str_ec(_pc.document['stokes']), _str_ec(_pc.document['mask']), _pc.document['overwrite'], _pc.document['stretch']))
        return _collapse_result

    def decimate(self, outfile='', axis=int(0), factor=int(1), method='copy', region='', mask='', overwrite=False, stretch=False):
        """This application removes planes along the specified axis of an image. It supports both float valued and complex
        valued images. The factor parameter represents the factor by which to reduce the number
        of planes.
        
        The method parameter represents how to calculate the pixel values of the output image. A
        value of method="copy" means that every factorth plane of the selected region in the input
        image will be directly copied to the corresponding plane in the output image. So, if one
        wanted to copy every third spectral plane in the input image to the output image, one would
        specify factor=3 and method="copy". If the selected region along the specified axis had 11
        planes, then there would be 4 output planes which would map to planes 0, 3, 6, and 9 of
        the specified region of input image. A value of method="mean" indicates that each of
        factor number of planes in the range starting at each factorth plane should be averaged to
        produce the corresponding output plane. So, if one specified factor=3 and method="mean" along
        an axis of the selected region of the input image which had 11 pixels, the corresponding axis
        in the output image would have three pixels and the pixel values for each of those output
        planes would corresponding to averaging along that axis planes 0-2, 3-5, and 6-8 of the
        selected region of the input image. Note that the remaining planes, 9 and 10, in the selected
        region of the input image would be ignored because the last interval must have exactly
        factor number of planes in order to be included in the output image.
        
        The coordinate system of the output image takes into account the decimation; that is, along the
        decimated axis, the increment of the output image is factor times that of the input image, and
        the reference pixel of the output image is located at pixel 1/factor times the reference pixel
        in the input image.
        
        This method returns an image analysis tool which references the output image. If this tool
        is not desired, one should capture it anyway and then close() it immediately to free up
        resources.
        
        Images with multiple beams are not supported; please convolve a multi-beam image to a single
        resolution before running this application.
        
        """
        schema = {'outfile': {'type': 'cStr'}, 'axis': {'type': 'cInt'}, 'factor': {'type': 'cInt'}, 'method': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cStr'}, {'type': 'cDict'}]}, 'mask': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'axis': axis, 'factor': factor, 'method': method, 'region': region, 'mask': mask, 'overwrite': overwrite, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _decimate_result = _wrap_image(swig_object=self._swigobj.decimate(_str_ec(_pc.document['outfile']), _pc.document['axis'], _pc.document['factor'], _str_ec(_pc.document['method']), _any_ec(_pc.document['region']), _str_ec(_pc.document['mask']), _pc.document['overwrite'], _pc.document['stretch']))
        return _decimate_result

    def dohistory(self, enable=True):
        """This allows control over if tool methods record history of what parameters they were called
        with to the input and/or output image. By default, tool methods will write to the image
        history. By explicitly disabling history writing, tool methods will not write to the history.
        When created, an ia tool will have history writing enabled. Note that the setting is specific
        to the individual tool, and that methods such as open(), close(), done(), fromshape(), etc do
        not implicitly change the internal state of whether or not history writing by methods is
        enabled. One can explicitly enable/disable history writing even if the tool is not yet attached
        to an image. In the case where a method returns a new ia tool, the method will not write history
        to the output image, but the returned tool will have history writing enabled, so that running
        methods on the returned tool will cause history to be written to the image attached to that
        tool, or any new image created by running methods on that tool, unless dohistory(False) is
        explicitly run on that tool prior to running other methods.
        
        IMPORTANT NOTE: This setting will not affect the behavior of ia.sethistory(); this tool
        method will always write to the history, no matter if ia.dohistory(False) was run prior.
        
        """
        schema = {'enable': {'type': 'cBool'}}
        doc = {'enable': enable}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _dohistory_result = self._swigobj.dohistory(_pc.document['enable'])
        return _dohistory_result

    def imageconcat(self, outfile='', infiles=[ ], axis=int(-1), relax=False, tempclose=True, overwrite=False, reorder=False):
        """This function is used to concatenate two or more input casa
        images into one output image.  For example, if you have two image cubes
        which are contiguous along one axis (say a spectral axis) and you would
        like to glue them together along this axis, then this function is the
        appropriate thing to use.
        
        The axis parameter is used to specify which zero-based axis the images
        should be concatenated along. A negative value indicates that the
        spectral axis should be used. If a negative value is given but there is no
        spectral axis, an exception will be thrown. The zero-based order of the
        axes of an image can be determined from ia.coordsys().names().
        
        If successful, this method will return an image analysis tool referencing
        the concatenated image. Even if it is not wanted, the returned tool should
        be captured and closed as soon as the user is finished with it to free up
        system resources (eg memory).
        
        If {stfaf outfile} is given, the image is written to the specified
        disk file.  If {stfaf outfile} is unset, the on-the-fly Image tool
        created by the function actually references all of the input files.
        So if you deleted any of the input image disk files, it would render
        this tool useless.  When you destroy this tool (with the done function) the
        reference connections are broken.
        
        The input and output images must be of the same dimensionality.  Therefore,
        if you wish to concatenate 2-D images into a 3-D image, the 2-D images
        must have a third axis (of length unity) so that the output image
        coordinates are known along the concatenation axis.
        
        The input images are concatenated in the order in which they are listed unless
        the reorder parameter is set to True. If True, the images are reordered if necessary
        so that the world coordinate values along the selected axis monotonically increase
        or decrease. The direction of the increment is determined by the first listed image.
        If reorder=True, the world coordinate ranges of the images along the selected axis
        are not permitted to overlap, and the signs of the increments for this axis in all
        images must be the same. If reorder=False, the coordinate system of the first listed
        image is used as the coordinate system for the output image. If reorder=True, the
        coordinate system of the first image in the list of the reordered images is used
        as the coordinate system of the output image. Setting reorder=True can be especially
        useful if the infiles are specified using a wildcard character(s).
        
        If relax=False, the input images are checked to see that they are
        contiguous along the concatenation axis and an error is generated if
        they are not.  In addition, the coordinate descriptors (e.g.  reference
        pixel, reference value etc) for the non-concatenation axes must be the
        same or an error will result.
        
        The input disk image files may be in native casa, fits, or Miriad
        formats.
        
        The contiguous criterion and coordinate descriptor equality criteria can
        be relaxed by setting {stfaf relax=T} whereupon only warnings will be
        issued.  Dimension and shape must still be the same though.  When the
        concatenation axis is not contiguous (but still monotonically increasing
        or decreasing) and {stfaf relax=T}, a tabular coordinate will be used
        to correctly describe the axis.  But be aware that it means adjacent
        pixels are not regularly spaced.  However, functions like
        toworld and
        topixel will correctly interconvert world
        and pixel coordinates.
        
        In giving the input image names, the {stfaf infiles} argument can be a
        single string if you wild card it with standard shell symbols.  For
        example, {stfaf infiles='cena_???.*'}, where the ``?'' represents one
        character and ``*'' any number of characters.
        
        Otherwise, you must input a vector of strings such as {stfaf
        infiles="cena1 cena2 cena3"}.  An input such as {stfaf
        infiles='files1,file2'} will be interpreted as one string naming one
        file and you will get an error.  The reason for this is that although
        the latter could be parsed to extract two file names by recognizing
        comma delimiters, it is not possible because an expression such as
        {stfaf infiles='cena.{a,b}'} (meaning files of name ``cena.a'' and
        ``cena.b'') would confuse such parsing (you would get two files of name
        {sff cena.{a} and {sff b}}.
        
        You can look at the coordinate system of the output image using the
        ia.summary() tool method
        to ensure it's correct.
        
        The argument {stfaf tempclose} is, by default, True.  This means that
        all internal reference copies of the input images are  kept closed until
        they are needed. Then they are opened temporarily and then closed again.
        This enables you to effectively concatenate as many images as you like
        without encountering any operating system open file number limits.  However, it
        comes at some performance loss, because opening and closing all those
        files takes time.  If you are concatenating a smallish number of files,
        you might use {stfaf tempclose=F}.  This will leave all internal
        reference copies permanently open, but performance, if you don't hit the
        file limit, will be better.
        
        This method requires multiple images which are specified with the infiles
        parameter. Therefore calling ia.open() is not necessary, although calling
        imageconcat() using an already open image analysis tool will work and the state
        of that tool (eg the image it references) will not be changed.
        """
        schema = {'outfile': {'type': 'cStr'}, 'infiles': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'axis': {'type': 'cInt'}, 'relax': {'type': 'cBool'}, 'tempclose': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'reorder': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'infiles': infiles, 'axis': axis, 'relax': relax, 'tempclose': tempclose, 'overwrite': overwrite, 'reorder': reorder}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _imageconcat_result = _wrap_image(swig_object=self._swigobj.imageconcat(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['infiles']), _pc.document['axis'], _pc.document['relax'], _pc.document['tempclose'], _pc.document['overwrite'], _pc.document['reorder']))
        return _imageconcat_result

    def fromarray(self, outfile='', pixels=[ ], csys={ }, linear=False, overwrite=False, log=True):
        """This function converts a numerical (integer or float) numpy array of any size and
        dimensionality into a casa image. It will create both float and complex valued images.
        
        The image analysis tool on which this method is called will reference the created image;
        if this tool referenced another image before this call, that image will no longer be referenced
        by the tool after the creation of the new image. If you would rather have a new image analysis
        tool returned, keeping the one on which this method is called unaltered, use newimagefromarray()
        instead. If {stfaf outfile} is given, the image is written to disk, if not, the image tool on
        which this method was called will reference a temporary image (either in memory or on disk,
        depending on its size) that will be deleted when the tool
        is closed.
        
        Float valued images are produced from real-valued arrays. Complex-valued images are produced from
        complex-valued arrays.
        
        The coordinate system, provided as a coordsys tool converted to a record
        is optional.  If you provide it, it must have the same number of dimensions
        as the pixels array (see also coordsys).
        Call the naxes() method on the coordinate system tool to see how many dimensions the coordinate
        system has. A coordinate system can be created from scratch using the coordinate system (cs) tool and
        methods therein, but often users prefer to use a coordinate system from an already existing image.
        This can be gotten using ia.coordsys() which returns a coordinate system tool. A torecord() call
        on that tool will result in a python dictionary describing the coordinate system which is the
        necessary format for the csys input parameter of ia.fromarray().
        
        If csys is not specified, a default coordinate system
        is created.  If {stfaf linear=F} (the default) the created coordinate system will have
        standard RA/DEC/Stokes/Spectral Coordinate axes depending upon
        the shape of the {stfaf pixels} array (Stokes axis must be no longer
        than 4 pixels and you may find the spectral axis preceding the
        Stokes axis if say, {cf shape=[64,64,32,4]}).  Extra dimensions are
        given linear coordinates.  If {stfaf linear=T}, then all the resulting coordinates
        are linear with the axes represent lengths. In this case each axis will have a value
        of 0.0 at its center pixel. The increment of each axis will be 1.0 km.
        
        The method returns True if creation of the image was successful, False otherwise,
        so you can check programmatically if the image creation was successful.
        """
        schema = {'outfile': {'type': 'cStr'}, 'pixels': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'csys': {'type': 'cDict'}, 'linear': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'log': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'pixels': pixels, 'csys': csys, 'linear': linear, 'overwrite': overwrite, 'log': log}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromarray_result = self._swigobj.fromarray(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['pixels']), _dict_ec(_pc.document['csys']), _pc.document['linear'], _pc.document['overwrite'], _pc.document['log'])
        return _fromarray_result

    def fromascii(self, outfile='', infile='', shape=[ int(-1) ], sep=':', csys={ }, linear=False, overwrite=False):
        """This function is used to create a casa
        image from a pre-existing ASCII file. You might want to use this if you
        just want to create a quick image to use to see what various image analysis methods
        do. The image analysis tool on
        which the method is called will always reference the created image if
        this method is successful. Thus, calling open() on that tool is not necessary, but
        if the tool is already open, referencing another image, that reference will be
        silently destroyed and replaced with a reference to the image created by
        fromascii().
        If {stfaf outfile} is given, the image is also written to the
        specified disk file.  If {stfaf outfile} is unset, the image analysis tool
        on which this method was called references a temporary image.  This temporary
        image may be in
        memory or on disk, depending on its size.  When you close the image analysis
        tool (with the close function) the
        temporary image is deleted.
        
        You must specify the shape of the image.  The image must be stored
        in the ascii file. If the shape of the image having N axes is to be
        [s_0, s_1, s_2, ..., s_(N-1)],
        where s_i is the integral number of pixels along axis number i, the file must have
        (s_1 * s_2 * ... * s_(N-1)) rows and each row must have s_0 numerical
        values delimited by the value specified by the sep parameter.
        Pixel locations are incremented by row number in such a way that the second
        axis changes fastest. As an example, say we want to create an image with
        shape=[3,4,2]. There must be 4*2 = 8 rows in the ascii file, and each row must have
        3 space-delimited numerical values. The first row represents values of pixels
        [0, 0, 0], [1, 0, 0], and [2, 0, 0]. The second row represents values of pixels [0, 1, 0],
        [1, 1, 0], and [2, 1, 0]. The fifth row represents values of pixels [0, 0, 1], [1, 0, 1],
        and [2, 0, 1]. The sixth values of pixels [0, 1, 1], [1, 1, 1], and [2, 1, 1,]. And so on.
        
        To further illustrate, say this is our file:
        
        1 2 3
        4 5 6
        7 8 9
        10 11 12
        13 14 15
        16 17 18
        19 20 21
        22 23 24
        
        When read with ia.fromascii(), ary = ia.getchunk() would return the following array:
        ary[0, 0, 0] = 1
        ary[1, 0, 0] = 2
        ary[2, 0, 0] = 3
        ary[0, 1, 0] = 4
        ary[1, 1, 0] = 5
        ary[2, 1, 0] = 6
        ary[0, 2, 0] = 7
        ary[1, 2, 0] = 8
        ary[2, 2, 0] = 9
        ary[0, 3, 0] = 10
        ary[1, 3, 0] = 11
        ary[2, 3, 0] = 12
        ary[0, 0, 1] = 13
        ary[1, 0, 1] = 14
        ary[2, 0, 1] = 15
        ary[0, 1, 1] = 16
        ary[1, 1, 1] = 17
        ary[2, 1, 1] = 18
        ary[0, 2, 1] = 19
        ary[1, 2, 1] = 20
        ary[2, 2, 1] = 21
        ary[0, 3, 1] = 22
        ary[1, 3, 1] = 23
        ary[2, 3, 1] = 24
        
        The coordinate system, provided as a coordsys {tool} converted to a record
        with coordsys torecord, is optional.  If you provide it, it must be
        dimensionally consistent with the pixels array you give (see also
        coordsys).
        
        If you don't provide the coordinate system, a default coordinate system
        is made for you.  If {stfaf linear=F} (the default) then it is a
        standard RA/DEC/Stokes/Spectral Coordinate System depending exactly upon
        the shape of the {stfaf pixels} array (Stokes axis must be no longer
        than 4 pixels and you may find the spectral axis coming out before the
        Stokes axis if say, {cf shape=[64,64,32,4]}).  Extra dimensions are
        given linear coordinates.  If {stfaf linear=T}, then all axes are linear
        in the resulting coordinate system.
        """
        schema = {'outfile': {'type': 'cStr'}, 'infile': {'type': 'cStr'}, 'shape': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'sep': {'type': 'cStr'}, 'csys': {'type': 'cDict'}, 'linear': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'infile': infile, 'shape': shape, 'sep': sep, 'csys': csys, 'linear': linear, 'overwrite': overwrite}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromascii_result = self._swigobj.fromascii(_str_ec(_pc.document['outfile']), _str_ec(_pc.document['infile']), _pc.document['shape'], _str_ec(_pc.document['sep']), _dict_ec(_pc.document['csys']), _pc.document['linear'], _pc.document['overwrite'])
        return _fromascii_result

    def fromcomplist(self, outfile='', shape=[  ], cl='', csys={ }, overwrite=False, log=True, cache=True):
        """This method allows one to create an image based on a component list. A component list
        is a list of simple models (point sources, Gaussians, disks, etc) that describe the
        sky brightness (cf the component list (cl) tool). Images that can be described in this
        way normally require significantly less space to store than traditional images in which
        all the pixel values are stored. For a component list image, pixel values are computed
        "on the fly". Pixel values can be cached by specifying cache=True (the default value)
        while the image is attached to an image tool, which permits faster access to them after
        they are computed the first time. The trade off to caching is that resources such as
        memory and disk space must be used to cache the pixel values.
        
        The image is constrained to have two, three, or four dimensions. One must specify an
        image shape (the dimensionality of which must adhere to this constraint). One may also
        supply a coordinate system specification using the csys parameter. If a coordinate system
        is not specified, a default coordinate system is used. If specified, the coordinate system
        must have a direction coordinate which has two pixel axes. It can also have a spectral
        and/or polarization coordinate. The maximum length of the polarization coordinate is four
        pixels, and the world coordinate values of the polarization coordinate are constrained to
        be in the set of stokes parameters I, Q, U, and V.
        
        As is common with image creation methods, specifying an empty string for the outfile parameter
        results in a tempoary image being created that will be deleted when either the done() or
        close() method is run on the tool. By specifying a non-empty string, the image is saved to
        disk and can be opened with the open() method later. A persistent component list image is
        composed of a component list table that has metadata describing the image-related information,
        such as the coordinate system and the shape, as well as a history (log) table.
        
        Because pixel values are computed from the component models, altering pixel values is not
        supported. So methods such as putchunk(), putregion(), and addnoise() will fail on component
        list images when trying to modify pixel values. However, persistent image masks and on the fly
        masks are fully supported.
        
        The brightness unit of a component list image is constrained to be "Jy/pixel". Attempts to
        modify this value using setbrightnessunit() will fail.
        
        Component list images do not support synthesized beams; attempting to run setrestoringbeam() on
        a component list image to add a beam(s) will fail.
        
        One can easily create an image in which the pixel values are persistently stored from a
        component list image by running methods such as fromimage(), subimage(), tofits(), etc. In
        general, any method run on a component list image that creates a new image will create a
        non-component list image (eg, a traditional CASA Paged image or Temporary image) in which the
        pixel values are explicitly stored.
        
        
        """
        schema = {'outfile': {'type': 'cStr'}, 'shape': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'cl': {'anyof': [{'type': 'cStr'}, {'type': 'cDict'}]}, 'csys': {'type': 'cDict'}, 'overwrite': {'type': 'cBool'}, 'log': {'type': 'cBool'}, 'cache': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'shape': shape, 'cl': cl, 'csys': csys, 'overwrite': overwrite, 'log': log, 'cache': cache}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromcomplist_result = self._swigobj.fromcomplist(_str_ec(_pc.document['outfile']), _pc.document['shape'], _any_ec(_pc.document['cl']), _dict_ec(_pc.document['csys']), _pc.document['overwrite'], _pc.document['log'], _pc.document['cache'])
        return _fromcomplist_result

    def fromfits(self, outfile='', infile='', whichrep=int(0), whichhdu=int(0), zeroblanks=False, overwrite=False):
        """This function is used to convert a FITS disk image file (Float,
        Double, Short, Long are supported) to an
        casa imagefile.  If {stfaf outfile} is given, the image is written
        to the specified disk file.  If {stfaf outfile} is unset, the Image
        tool is associated with a temporary image.  This temporary image may
        be in memory or on disk, depending on its size.  When you close the
        Image tool (with the close function) this
        temporary image is deleted.
        
        This function reads from the FITS primary array (when the image is at
        the beginning of the FITS file; {stfaf whichhdu=0}), or an image
        extension (when the image is elsewhere in the FITS file, {stfaf
        whichhdu $>$ 0}).
        
        By default, any blanked pixels will be converted to a mask value which
        is false, and a pixel value that is NaN.  If you set {stfaf
        zeroblanks=T} then the pixel value will be zero rather than NaN.  The
        mask will still be set to false.  See the function
        replacemaskedpixels if you
        need to replace masked pixel values after you have created the image.
        """
        schema = {'outfile': {'type': 'cStr'}, 'infile': {'type': 'cStr'}, 'whichrep': {'type': 'cInt'}, 'whichhdu': {'type': 'cInt'}, 'zeroblanks': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'infile': infile, 'whichrep': whichrep, 'whichhdu': whichhdu, 'zeroblanks': zeroblanks, 'overwrite': overwrite}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromfits_result = self._swigobj.fromfits(_str_ec(_pc.document['outfile']), _str_ec(_pc.document['infile']), _pc.document['whichrep'], _pc.document['whichhdu'], _pc.document['zeroblanks'], _pc.document['overwrite'])
        return _fromfits_result

    def fromimage(self, outfile='', infile='', region=[ ], mask='', dropdeg=False, overwrite=False):
        """This function applies a region to an imagefile, creates a new
        imagefile containing the (sub)image, and associates the imagetool
        with it.
        
        The input image file may be in native casa, fits, or Miriad
        format.  Look htmlref{here}{IMAGES:FOREIGNIMAGES}  for more
        information on foreign images.
        
        If {stfaf outfile} is given, the (sub)image is written to the specified
        disk file.
        
        If {stfaf outfile} is unset, the Image tool actually references
        the input image file.  So if you deleted the input image disk file, it
        would render this tool useless.  When you close this tool
        (with the close function)
        the reference connection is broken.
        
        Sometimes it is useful to drop axes of length one (degenerate axes).
        Use the {stfaf dropdeg} argument if you want to do this.
        
        The output mask is the combination (logical OR) of the default input
        pixelmask (if any) and the OTF mask.  Any other input pixelmasks
        will not be copied.  Use function
        maskhandler if you need to copy other
        masks too.
        
        See also the subimage function.
        """
        schema = {'outfile': {'type': 'cStr'}, 'infile': {'type': 'cStr'}, 'region': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'dropdeg': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'infile': infile, 'region': region, 'mask': mask, 'dropdeg': dropdeg, 'overwrite': overwrite}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromimage_result = self._swigobj.fromimage(_str_ec(_pc.document['outfile']), _str_ec(_pc.document['infile']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['dropdeg'], _pc.document['overwrite'])
        return _fromimage_result

    def fromshape(self, outfile='', shape=[ int(0) ], csys={ }, linear=False, overwrite=False, log=True, type='f'):
        """This function creates a casa imagefile with the specified shape.  All
        the pixel values in the image are set to 0. One may create either an image
        with float valued pixels (type='f') or a complex valued image (type='c').
        To use a numpy array of values to create an image, use ia.fromarray().
        To make a 2-D image from a packaged FITS file, use ia.maketestimage().
        
        If {stfaf outfile} is given, the image is written to the specified disk
        file.  If {stfaf outfile} is unset, the Image tool is associated with
        a temporary image.  This temporary image may be in memory or on disk,
        depending on its size.  When you close the Image tool  (with the
        close function) this temporary image is
        deleted.
        
        The Coordinate System, provided as a Coordsys
        tool, is optional.  If you provide it, it must be dimensionally
        consistent with the shape that you specify (see also
        coordsys).
        
        If you don't provide the Coordinate System, a default Coordinate System
        is made for you.  If {stfaf linear=F} (the default) then it is a
        standard RA/DEC/Stokes/Spectral Coordinate System depending exactly upon
        the shape (Stokes axis must be no longer than 4 pixels and you may find
        the spectral axis coming out before the Stokes axis if say, {cf
        shape=[64,64,32,4]}).  Extra dimensions are given linear coordinates.
        If {stfaf linear=T} then you get a linear Coordinate System.
        
        The method returns True if successful, False otherwise.
        """
        schema = {'outfile': {'type': 'cStr'}, 'shape': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'csys': {'type': 'cDict'}, 'linear': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'log': {'type': 'cBool'}, 'type': {'type': 'cStr'}}
        doc = {'outfile': outfile, 'shape': shape, 'csys': csys, 'linear': linear, 'overwrite': overwrite, 'log': log, 'type': type}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromshape_result = self._swigobj.fromshape(_str_ec(_pc.document['outfile']), _pc.document['shape'], _dict_ec(_pc.document['csys']), _pc.document['linear'], _pc.document['overwrite'], _pc.document['log'], _str_ec(_pc.document['type']))
        return _fromshape_result

    def maketestimage(self, outfile='', overwrite=False):
        """This function converts a FITS file resident in the casa  system into
        a casa  image.
        
        If outfile is given, the image is written to the specified disk
        file. If outfile is unset, the Image tool is associated with a
        temporary image. This temporary image may be in memory or on disk,
        depending on its size. When you close the Image tool (with the close
        function) this temporary image is deleted.
        """
        schema = {'outfile': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'overwrite': overwrite}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _maketestimage_result = self._swigobj.maketestimage(_str_ec(_pc.document['outfile']), _pc.document['overwrite'])
        return _maketestimage_result

    def deviation(self, outfile='', region='', mask='', overwrite=False, stretch=False, grid=[ int(1),int(1) ], anchor='ref', xlength='1pix', ylength='1pix', interp='cubic', stattype='sigma', statalg='classic', zscore=float(-1), maxiter=int(-1)):
        """This application creates an image that reflects the statistics of the input image. The output image has
        the same dimensions and coordinate system as the (selected region in) input image. The grid parameter
        describes how many pixels apart "grid" pixels are. Statistics are computed around each grid pixel. Grid
        pixels are limited to the direction plane only; independent statistics are computed for each direction plane
        (ie at each frequency/stokes pixel should the input image happen to have such additional axes). Using the
        xlength and ylength parameters, one may specify either a rectangular or circular region around each grid
        point that defines which surrounding pixels are used in the statistic computation for individual grid points.
        If the ylength parameter is the empty string, then a circle of diameter provided by xlength centered on
        the grid point is used. If ylength is not empty, then a rectangular box of dimensions xlength x ylength centered
        on the grid pixel is used. These two parameters may be specified in pixels, using either numerical values or
        valid quantities with "pix" as the unit (eg "4pix"). Otherwise, they must be specified as valid angular
        quantities, with recognized units (eg "4arcsec"). As with other region selections in CASA, full pixels are
        included in the computation even if the specified region includes only a fraction of that pixel. BEWARE OF
        MACHINE PRECISION ISSUES, because you may get a smaller number of pixels included in a region than you
        expect if you specify, eg, an integer number of pixels. In such cases, you probably want to specify that
        number plus a small epsilon value (eg "2.0001pix" rather than "2pix") to mitigate machine precision issues
        when computing region extents.
        
        The output image is formed by putting the statistics calculated at each grid point at the corresponding
        grid point in the output image. Interpolation of these output values is then used to compute values at
        non-grid-point pixels. The user may specify which interpolation algorithm to use for this computation
        using the interp parameter.
        
        The input image pixel mask is copied to the output image. If interpolation is performed, output pixels are
        masked where the interpolation fails.
        
        ANCHORING THE GRID
        
        The user may choose at which pixel to "anchor" the grid. For example, if one specifies grid=[4,4] and
        anchor=[0,0], grid points will be located at pixels [0,0], [0,4], [0,8] ... [4,0], [4,4], etc. This
        is exactly the same grid that would be produced if the user specified anchor=[4,4] or anchor=[20,44].
        If the user specifies anchor=[1, 2] and grid=[4,4], then the grid points will be at pixels [1,2], [5,2],
        [9,2]... [5,2], [5,6], etc. and the resulting grid is the same as it would be if the user specified eg
        anchor=[9,10] or anchor=[21, 18]. The value "ref", which is the default, indicates that the reference
        pixel of the input image should be used to anchor the grid. The x and y values of this pixel will be
        rounded to the nearest integer if necessary.
        
        SUPPORTED STATISTICS AND STATISTICS ALGORITHMS
        
        One may specify which statistic should be represented using the stattype parameter. The following values
        are recognized (minimum match supported):
        
        iqr                   inner quartile range (q3 - q1)
        max                   maximum
        mean                  mean
        medabsdevmed, madm    median absolute deviation from the median
        median                median
        min                   minimum
        npts                  number of points
        q1                    first quartile
        q3                    third quartile
        rms                   rms
        sigma, std            standard deviation
        sumsq                 sum of squares
        sum                   sum
        var                   variance
        xmadm                 median absolute deviation from the median multipied by x, where x is the reciprocal of Phi^-1(3/4),
        where Phi^-1 is the reciprocal of the quantile function. Numerically, x = 1.482602218505602. See, eg,
        https://en.wikipedia.org/wiki/Median_absolute_deviation#Relation_to_standard_deviation
        
        Using the statalg parameter, one may also select whether to use the Classical or Chauvenet/ZScore statistics algorithm to
        compute the desired statistic (see the help for ia.statistics() or imstat for a full description of these algorithms).
        
        
        """
        schema = {'outfile': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cStr'}, {'type': 'cDict'}]}, 'mask': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}, 'grid': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'anchor': {'anyof': [{'type': 'cStr'}, {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}]}, 'xlength': {'anyof': [{'type': 'cStr'}, {'type': 'cInt'}]}, 'ylength': {'anyof': [{'type': 'cStr'}, {'type': 'cInt'}]}, 'interp': {'type': 'cStr'}, 'stattype': {'type': 'cStr'}, 'statalg': {'type': 'cStr'}, 'zscore': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'maxiter': {'type': 'cInt'}}
        doc = {'outfile': outfile, 'region': region, 'mask': mask, 'overwrite': overwrite, 'stretch': stretch, 'grid': grid, 'anchor': anchor, 'xlength': xlength, 'ylength': ylength, 'interp': interp, 'stattype': stattype, 'statalg': statalg, 'zscore': zscore, 'maxiter': maxiter}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _deviation_result = _wrap_image(swig_object=self._swigobj.deviation(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['region']), _str_ec(_pc.document['mask']), _pc.document['overwrite'], _pc.document['stretch'], _pc.document['grid'], _any_ec(_pc.document['anchor']), _any_ec(_pc.document['xlength']), _any_ec(_pc.document['ylength']), _str_ec(_pc.document['interp']), _str_ec(_pc.document['stattype']), _str_ec(_pc.document['statalg']), _pc.document['zscore'], _pc.document['maxiter']))
        return _deviation_result

    def adddegaxes(self, outfile='', direction=False, spectral=False, stokes='', linear=False, tabular=False, overwrite=False, silent=False):
        """This method adds degenerate axes (i.e.
        axes of length 1) of the specified type.  Sometimes this can be useful
        although you will generally need to modify the coordinate system of the
        added axis to give it the coordinate you want (do this with the
        Coordsys tool). This method supports
        both float and complex valued images.
        
        You specify which type of axes you want to add.  You can't add
        an axis type that already exists in the image.  For the Stokes axis,
        the allowed value (a string such as  I, Q, XX, RR) can be found in the
        Coordsys newcoordsys function documentation.
        
        If {stfaf outfile} is given, the image is written to the specified
        disk file.  If {stfaf outfile} is unset, the on-the-fly Image tool
        returned by the function is associated with a temporary image.  This
        temporary image may be in memory or on disk, depending on its size.
        When you destroy the generated Image tool (with the done function) this
        temporary image is deleted.
        """
        schema = {'outfile': {'type': 'cStr'}, 'direction': {'type': 'cBool'}, 'spectral': {'type': 'cBool'}, 'stokes': {'type': 'cStr'}, 'linear': {'type': 'cBool'}, 'tabular': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'silent': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'direction': direction, 'spectral': spectral, 'stokes': stokes, 'linear': linear, 'tabular': tabular, 'overwrite': overwrite, 'silent': silent}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _adddegaxes_result = _wrap_image(swig_object=self._swigobj.adddegaxes(_str_ec(_pc.document['outfile']), _pc.document['direction'], _pc.document['spectral'], _str_ec(_pc.document['stokes']), _pc.document['linear'], _pc.document['tabular'], _pc.document['overwrite'], _pc.document['silent']))
        return _adddegaxes_result

    def addnoise(self, type='normal', pars=[ float(0.0),float(1.0) ], region={ }, zero=False, seeds=[  ]):
        """This function adds noise to the image.  You may zero the image first
        before the noise is added if you wish.
        
        The noise can be drawn from one of many distributions.
        
        For each distribution, you must supply the type via the {stfaf type}
        argument (minimum match is active) and parameters via the {stfaf
        pars} argument.   Briefly:
        
        begin{itemize}
        
        item {binomial} -- the binomial distribution models successfully drawing
        items from a pool. Specify two parameters, $n$ and $p$, respectively.
        $n$ is the number of items in the pool, and $p$, is the probability of
        each item being successfully drawn. It is required that $n > 0$ and
        $0 le p le 1$.
        
        item {discreteuniform} -- models a uniform random variable over the closed interval. Specify
        two parameters, the low and high values, respectively.
        The low parameter is the lowest possible return value and
        the high parameter is the highest. It is required that $low < high$.
        
        item {erlang} -- Specify two parameters, the  mean and variance,
        respectively. It is required that the mean is non-zero and the variance
        is positive.
        
        item {geometric} -- Specify one parameter, the probability.
        It is required that $0 le probability < 1$.
        
        item {hypergeometric} -- Specify two parameters, the mean and the variance.
        It is required that the variance is positive and that the mean is non-zero
        and not bigger than the square-root of the variance.
        
        item {normal} -- Specify two parameters, the mean and the variance.
        It is required that the variance is positive.
        
        item {lognormal} -- Specify two parameters, the mean and the variance.
        It is required that the supplied variance is positive and that the mean is non-zero.
        
        item {negativeexponential} -- Supply one parameter, the mean.
        
        item {poisson} -- Specify one parameter, the mean.
        It is required that the mean is non-negative.
        
        item {uniform} -- Model a uniform random variable over a closed
        interval. Specify two parameters, the low and high values.    The low
        parameter is the lowest possible return value and the high parameter can
        never be returned. It is required that $low < high$.
        
        item {weibull} -- Specify two parameters, alpha and beta.
        It is required that the alpha parameter is not zero.
        
        The random number generator seeds may be specified as an array of integers. Only the first
        two values are used. If none or a single value is provided, the necessary remaining value(s)
        are generated based on the current time, using the algorithm
        begin{verbatim}
        seedBase = 1e7*MJD
        seed[1] = (Int)seedBase;
        # and if seed[0] is also not supplied
        seed[0] = (Int)((1e7*(seedBase - seed[1])))
        end{verbatim}
        
        where MJD is the Modidfied Julian Day.
        
        end{itemize}
        """
        schema = {'type': {'type': 'cStr'}, 'pars': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'zero': {'type': 'cBool'}, 'seeds': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'type': type, 'pars': pars, 'region': region, 'zero': zero, 'seeds': seeds}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _addnoise_result = self._swigobj.addnoise(_str_ec(_pc.document['type']), _pc.document['pars'], _any_ec(_pc.document['region']), _pc.document['zero'], _pc.document['seeds'])
        return _addnoise_result

    def convolve(self, outfile='', kernel=[ ], scale=float(-1.0), region={ }, mask='', overwrite=False, stretch=False):
        """This function performs Fourier-based convolution of an imagefile by the
        given kernel.
        
        If {stfaf outfile} is given, the image is written to the specified
        disk file.  If {stfaf outfile} is left unset, the on-the-fly Image tool
        generated by this function is associated with a temporary image.  This
        temporary image may be stored in memory or on disk, depending on its size.
        When the user destroys the generated Image tool (with the done function) this
        temporary image is deleted.
        
        The kernel is provided as a multi-dimensional array or as the
        filename of a disk-based imagefile.   The provided kernel can have fewer
        dimensions than the image being convolved.  In this case, it will be
        padded with degenerate axes.  An error will result if the kernel has
        more dimensions than the image.   No additional scaling of the kernel is
        provided yet.
        
        The scaling of the output image is determined by the argument {stfaf scale}.
        If this is left unset, then the kernel is normalized to unit sum.
        If {stfaf scale} is not left unset, then the convolution kernel
        will be scaled (multiplied) by this value.
        
        Masked pixels will be assigned the value 0.0 before convolution.
        
        The output mask is the combination (logical OR) of the default input
        pixelmask (if any) and the OTF mask.  Any other input pixelmasks
        will not be copied.  The function
        maskhandler
        should be used if there is a need to copy other masks too.
        
        See also the other convolution functions:
        
        convolve2d,
        sepconvolve and
        hanning.
        """
        schema = {'outfile': {'type': 'cStr'}, 'kernel': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'scale': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'kernel': kernel, 'scale': scale, 'region': region, 'mask': mask, 'overwrite': overwrite, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _convolve_result = _wrap_image(swig_object=self._swigobj.convolve(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['kernel']), _pc.document['scale'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['overwrite'], _pc.document['stretch']))
        return _convolve_result

    def boundingbox(self, region={ }):
        """This function finds the bounding box of a
        region of interest when it is applied to a particular image. Both
        float and complex valued images are supported. It is
        returned in a record which has fields {cf `blc', `trc', `inc',
        `bbShape', `regionShape', `imageShape', `blcf'} and {cf `trcf'}
        containing the bottom-left corner, the top-right corner (in absolute
        image pixel coordinates), the increment (stride) of the region, the
        shape of the boundingbox, the shape of the region, the shape of the
        image,  the blc in formatted absolute world coordinates and the trc in
        formatted absolute world  coordinates, respectively.
        
        Note that the shape of the bounding box will be different from the shape
        of the region if a non-unit stride (increment) is involved (see the example
        below).
        
        Note that the integer size of the elements in blc, trc, inc, regionShape,
        bbShape, and imageShape are 32 bits, even on a 64 bit machine. This means that,
        on 64 bit machines, you may have to convert them to 64 bit ints using eg
        numpy.int64, before being able to use them as direct input to other
        methods such as ia.getchunk().
        """
        schema = {'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}}
        doc = {'region': region}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _boundingbox_result = _dict_dc(self._swigobj.boundingbox(_any_ec(_pc.document['region'])))
        return _boundingbox_result

    def boxcar(self, outfile='', region={ }, mask=[ ], axis=int(-1), width=int(2), drop=True, dmethod='copy', overwrite=False, stretch=False):
        """This application performs boxcar convolution of one axis of an image
        defined by
        
        z[i] = (y[i] + y[i+i] + ... + y[i+w])/w
        
        where z[i] is the value at pixel i in the box car smoothed image, y[k]
        is the pixel value of the input image at pixel k, and w is a postivie integer
        representing the width of the boxcar in pixels. Both float and complex
        valued images are supported. The length of the axis along which the
        convolution is to occur must be at least w pixels in the selected region,
        unless decimation using the mean function is chosen in which case the axis
        length must be at least 2*w (see below). Masked pixel values are set to
        zero prior to convolution. All nondefault pixel masks are ignored during
        the calculation. The convolution is done in the image domain (i.e., not
        with an FFT).
        
        If drop=False (no decimation), the length of the output axis will be equal
        to the length of the input axis - w + 1. The pixel mask, ORed with the OTF mask
        if specified, is copied from the selected region of the input image to the
        output image. Thus for example, if the selected region in the input image has
        six planes along the convolution axis, if the specified boxcar width is 2,
        and if the pixel values, which are all unmasked, on a slice along this axis
        are [1, 2, 5, 10, 17, 26], then the corresponding output slice will be of
        length five and the output pixel values will be [1.5, 3.5, 7.5, 13.5, 21.5].
        
        If drop=True and dmethod="copy", the output image is the image calculated
        if drop=True, except that only every wth plane is kept. Both the pixel and mask
        values of these planes are copied directly to the output image, without further
        processing. Thus for example, if the selected region in the input image has six
        planes along the convolution axis, the boxcar width is chosen to be 2, and if
        the pixel values, which are all unmasked, on a slice along this axis are [1, 2,
        5, 10, 17, 26], the corresponding output pixel values will be [1.5, 7.5, 21.5].
        
        If drop=True and dmethod="mean", first the image described in the drop=False
        case is calculated. Then, the ith plane of the output image is calculated by
        averaging the i*w to the (i+1)*w-1  planes of this intermediate image. Thus, for
        example, if the selected region in the input image has six planes along the
        convolution axis, the boxcar width is chosen to be 2, and if the pixel values,
        which are all unmasked, on a slice along this axis are [1, 2, 5, 10, 17, 26],
        then the corresponding output pixel values will be [2.5, 10.5]. Any pixels at the
        end of the plane of the intermediate image that do not fall into a complete bin of
        width w are ignored. Masked values are taken into consideration when forming this
        average, so if one of the values is masked, it is not used in the average. If at
        least one of the valuesin the intermediate image bin is not masked, the
        corresponding output pixel will not be masked.
        
        The smoothed image is written to disk with name {stfaf outfile}, if specified.
        If not, no image is written but the image is still accessible via the returned
        image analysis tool (see below).
        
        This method always returns an image analysis tool which is attached to the smoothed
        image. This tool should always be captured and closed after any desired manipulations
        have been done. Closing the tool frees up system resources (eg memory), eg,
        
        begin{verbatim}
        smoothedim = ia.boxcar(...)
        # do things (or not) with smoothedim
        ...
        # close the returned tool promptly upon finishing with it.
        smoothedim.done()
        end{verbatim}
        
        """
        schema = {'outfile': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'axis': {'type': 'cInt'}, 'width': {'type': 'cInt'}, 'drop': {'type': 'cBool'}, 'dmethod': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'region': region, 'mask': mask, 'axis': axis, 'width': width, 'drop': drop, 'dmethod': dmethod, 'overwrite': overwrite, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _boxcar_result = _wrap_image(swig_object=self._swigobj.boxcar(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['axis'], _pc.document['width'], _pc.document['drop'], _str_ec(_pc.document['dmethod']), _pc.document['overwrite'], _pc.document['stretch']))
        return _boxcar_result

    def brightnessunit(self):
        """This function gets the image brightness unit. Both float and complex
        valued images are supported.
        """
        _brightnessunit_result = _str_dc(self._swigobj.brightnessunit())
        return _brightnessunit_result

    def calc(self, pixels, verbose=True):
        """This function is used to evaluate a mathematical expression involving
        casa images, assigning the result to the current (already existing)
        image. Both float and complex valued images are supported, although the
        image which results from the calculation must have the same type of pixel
        values as the image already attached to the tool. That is, one cannot
        create a complex valued image using this method if the associated ia tool
        is currently attached to a float valued image.  It complements the imagecalc
        function which returns a newly constructed on-the-fly image tool.  See htmladdnormallink{note 223}{../../notes/223/223.html}
        which describes the the syntax and functionality in detail.
        
        If the expression, supplied via the {stfaf pixels} argument, is not a
        scalar, the shapes and coordinates of the image and expression must
        conform.
        
        If the image (that associated with the tool) has a pixelmask, then only
        pixels for which that mask is good will be changed.  See the function
        maskhandler for managing image pixelmasks.
        
        Note that when multiple image are used in the expression, there is no garauntee about which of
        those images will be used to create the header of the output image. Therefore, one may have
        to modify the output header as needed if the input headers differ.
        
        See the related functions set and
        putregion.
        """
        schema = {'pixels': {'type': 'cStr'}, 'verbose': {'type': 'cBool'}}
        doc = {'pixels': pixels, 'verbose': verbose}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _calc_result = self._swigobj.calc(_str_ec(_pc.document['pixels']), _pc.document['verbose'])
        return _calc_result

    def calcmask(self, mask='', name='', asdefault=True):
        """This method is used to create a new pixelmask via a Boolean LEL expression.
        This gives you much more scope than the simple
        set and
        putregion functions.
        Both float and complex valued images are supported.
        
        See http://casa.nrao.edu/aips2_docs/notes/223/index.shtml
        which describes the the syntax and functionality of LEL in detail. Also
        in this document is a description of ways to escape image names that
        contain certain non-alphanumeric characters so they are compatible
        with LEL syntax.
        
        If the expression is not a scalar, the shapes and coordinates of the
        image and expression must conform.    If the expression is a scalar
        then the entire pixelmask will be set to that value.
        
        By default (argument {stfaf name}) the name of a new pixelmask is made up
        for you.  However, if you specify a pixelmask name (use function
        summary or
        maskhandler to see the mask names)
        then it is used.  If the pixelmask already exists, it is overwritten.
        
        You can specify whether the new pixelmask should be the default mask or not.
        By default, it is made the default pixelmask !
        """
        schema = {'mask': {'type': 'cStr'}, 'name': {'type': 'cStr'}, 'asdefault': {'type': 'cBool'}}
        doc = {'mask': mask, 'name': name, 'asdefault': asdefault}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _calcmask_result = self._swigobj.calcmask(_str_ec(_pc.document['mask']), _str_ec(_pc.document['name']), _pc.document['asdefault'])
        return _calcmask_result

    def close(self):
        """This function closes the imagetool.  This means that it detaches the
        tool from its imagefile (flushing all the changes first).  The
        imagetool is ``null'' after this change (it is not destroyed) and
        calling any toolfunction other than open
        will result in an error.
        """
        _close_result = self._swigobj.close()
        return _close_result

    def continuumsub(self, outline='', outcont='continuumsub.im', region={ }, channels=[ int(-1) ], pol='', fitorder=int(0), overwrite=False):
        """This function packages the relevant image tool functionality for simple
        specification and application of image plane continuum subtraction.  All
        that is required of the input image is that it have a non-degenerate
        spectral axis.
        
        The user specifies region, the region of the input image over which
        continuum subtraction is desired (otherwise the whole image will be
        treated); channels, the subset of channels on the spectral axis to use
        in the continuum estimation, specified as a vector;
        fitorder, the polynomial order to use in the
        estimation.  Optionally, output line and continuum images may be written
        by specifying outline and outcont, respectively.  If outline is not
        specified, a virtual image tool is all that is produced.  If outcont is
        not specified, the output continuum image will be written in
        'continuumsub.im'. Note that the pol parameter is no longer supported; one
        should use the region parameter if polarization selection is desired, in
        conformance with other ia tool methods.
        """
        schema = {'outline': {'type': 'cStr'}, 'outcont': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'channels': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'pol': {'type': 'cStr'}, 'fitorder': {'type': 'cInt'}, 'overwrite': {'type': 'cBool'}}
        doc = {'outline': outline, 'outcont': outcont, 'region': region, 'channels': channels, 'pol': pol, 'fitorder': fitorder, 'overwrite': overwrite}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _continuumsub_result = _wrap_image(swig_object=self._swigobj.continuumsub(_str_ec(_pc.document['outline']), _str_ec(_pc.document['outcont']), _any_ec(_pc.document['region']), _pc.document['channels'], _str_ec(_pc.document['pol']), _pc.document['fitorder'], _pc.document['overwrite']))
        return _continuumsub_result

    def convertflux(self, value=[ ], major=[ ], minor=[ ], type='Gaussian', topeak=True, channel=int(-1), polarization=int(-1)):
        """This function interconverts between peak intensity and flux density for a
        Gaussian component.  The image must hold a restoring beam.
        """
        schema = {'value': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'major': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'minor': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'type': {'type': 'cStr'}, 'topeak': {'type': 'cBool'}, 'channel': {'type': 'cInt'}, 'polarization': {'type': 'cInt'}}
        doc = {'value': value, 'major': major, 'minor': minor, 'type': type, 'topeak': topeak, 'channel': channel, 'polarization': polarization}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _convertflux_result = _dict_dc(self._swigobj.convertflux(_any_ec(_pc.document['value']), _any_ec(_pc.document['major']), _any_ec(_pc.document['minor']), _str_ec(_pc.document['type']), _pc.document['topeak'], _pc.document['channel'], _pc.document['polarization']))
        return _convertflux_result

    def convolve2d(self, outfile='', axes=[ int(0),int(1) ], type='gaussian', major='0deg', minor='0deg', pa='0deg', scale=float(-1), region={ }, mask='', overwrite=False, stretch=False, targetres=False, beam={ }):
        """This function performs Fourier-based convolution of an imagefile
        using the provided 2D kernel.
        
        If {stfaf outfile} is left unset, the image is written to the specified
        disk file.  If {stfaf outfile} is not given, the newly constructed
        on-the-fly Image tool is associated with a temporary image.  This
        temporary image may be stored in memory or on disk, depending on its size.
        When the user destroys the on-the-fly Image tool (with the done function) this
        temporary image is deleted.
        
        The user specifies which 2 pixel axes of the image are to be convolved
        via the {stfaf axes} argument. The pixels must be square or an error will result.
        
        The user specifies the type of convolution kernel with {stfaf type} (minimum
        match is supported); currently only {cf 'gaussian'}  is available.
        
        The user specifies the parameters of the convolution kernel via the arguments
        {stfaf major}, {stfaf minor}, and {stfaf pa}.   These arguments can
        be specified in one of three ways:
        
        begin{itemize}
        
        item Quantity - for example {stfaf major=qa.quantity(1, 'arcsec')}
        Note that you pixel units can be used, viz. {stfaf major=qa.quantity(1, 'pix')},
        see below.
        
        item String - for example {stfaf minor='1km'} (i.e. one that the
        Quanta quantity function accepts).
        
        item Numeric - for example {stfaf major=10}.  In this case, the units
        of {stfaf major} and {stfaf minor} are assumed to be in pixels.  Using
        pixel units allows the user to convolve unlike axes (see one of the provided
        example for this use case). For the position angle, units of degrees are assumed.
        
        end{itemize}
        
        The interpretation of {stfaf major} and {stfaf minor} depends upon the
        kernel type.
        
        begin{itemize}
        
        item Gaussian - {stfaf major} and {stfaf minor} are
        the Full Width at Half Maximum (FWHM) of the major and minor
        axes of the Gaussian.
        
        end{itemize}
        
        The position angle is measured North through East when a
        plane holding a celestial coordinate (the usual astronomical
        convention) is convolved.  For other axis/coordinate combinations,
        a positive position angle is measured from +x to +y in the
        absolute pixel coordinate frame  (x is the first axis that is
        specified, with argument {stfaf axes}).
        
        In the case of a Gaussian, the {stfaf beam} parameter offers an alternate way of
        describing the convolving Gaussian. If used, neither {stfaf major}, {stfaf minor},
        nor {stfaf pa} can be specified. The {stfaf beam} parameter must have exactly three
        fields: "major", "minor", and "pa" (or "positionangle"). This is, not coincidentally,
        the record format for the output of ia.restoringbeam().
        
        The scaling of the output image is determined by the argument {stfaf scale}.
        If this is left unset then autoscaling will be invoked.
        
        If the user is not convolving the sky, then autoscaling means that the convolution
        kernel will be normalized to have unit volume so as to conserve flux.
        
        If the user is convolving the sky, then there are two cases
        for which autoscaling is useful:
        
        Firstly, if the input image units are Jy/pixel, then the output image
        will have units of Jy/beam and be appropriately scaled.  In addition,
        the restoring beam of the output image will be the same as the
        convolution kernel.
        
        Secondly,if the input image units are Jy/beam, then the output
        image will also have units of Jy/beam and be appropriately
        scaled.  In addition, the restoring beam of the output image
        will be the convolution of the input image restoring beam and the
        convolution kernel. In the case of an image with per-plane beams, for
        each plane, the kernel is convolved with the appropriate beam and the
        result is associated with that plane in the output image.
        
        If the user sets a value for {stfaf scale}, then the convolution kernel
        will be scaled by this value. Note that it has peak of unity before the
        application of this scale factor.
        
        If the units on the original image include Jy/beam, the units on the
        output image will be rescaled by the ratio of the input and output
        beams as well as rescaling by the area of convolution kernel.
        
        If the units on the original image include K, then only the image
        convolution kernel rescaling is done.
        
        If targetres=True and type="gaussian" and the input image has a restoring beam,
        this method will interpret the values of major, minor, and pa as the resolution
        of the final image and will calculate the parameters of the Gaussian to use
        in the convolution so that this target resolution is achieved.
        
        Masked pixels will be assigned the value 0.0 before convolution.
        The output mask is the combination (logical OR) of the default input
        pixelmask (if any) and the OTF mask.  Any other input pixelmasks
        will not be copied.  The function
        maskhandler
        can be used if there is a need to copy other masks too.
        
        See also the other convolution functions:
        
        convolve,
        hanning, and
        sepconvolve.
        """
        schema = {'outfile': {'type': 'cStr'}, 'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'type': {'type': 'cStr'}, 'major': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'minor': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'pa': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'scale': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}, 'targetres': {'type': 'cBool'}, 'beam': {'type': 'cDict'}}
        doc = {'outfile': outfile, 'axes': axes, 'type': type, 'major': major, 'minor': minor, 'pa': pa, 'scale': scale, 'region': region, 'mask': mask, 'overwrite': overwrite, 'stretch': stretch, 'targetres': targetres, 'beam': beam}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _convolve2d_result = _wrap_image(swig_object=self._swigobj.convolve2d(_str_ec(_pc.document['outfile']), _pc.document['axes'], _str_ec(_pc.document['type']), _any_ec(_pc.document['major']), _any_ec(_pc.document['minor']), _any_ec(_pc.document['pa']), _pc.document['scale'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['overwrite'], _pc.document['stretch'], _pc.document['targetres'], _dict_ec(_pc.document['beam'])))
        return _convolve2d_result

    def coordsys(self, axes=[ int(-1) ]):
        """This function returns the Coordinate System of an image in a {stf
        Coordsys} tool. Both float and complex valued images are supported.
        
        By default, the Coordinate System describes all of the axes in the
        image.  If you desire, you can select a subset of the axes, thus
        reducing the dimensionality of the Coordinate System.   This may be
        useful if you are supplying a Coordinate System to the
        functions fromarray or
        fromshape.
        """
        schema = {'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'axes': axes}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _coordsys_result = _wrap_coordsys(swig_object=self._swigobj.coordsys(_pc.document['axes']))
        return _coordsys_result

    def coordmeasures(self, pixel=[ float(-1) ], dframe='cl', sframe='cl'):
        """You can use this function to get the world coordinates for a specified
        absolute pixel coordinate in the image.  You specify a pixel coordinate
        (0-rel) for each axis in the image.
        
        If you supply fewer pixel values then there are axes in the image, your
        value will be padded out with the reference pixel for the missing axes.
        Excess values will be ignored.
        
        The parameters dframe and sframe allow one to specify to which reference frame
        the direction and spectral measures, respectively, should be converted. These
        values are case-insensitive. "native" means use the native reference frame of
        the coordinate in question. "cl" means use the conversion layer frame if one
        exists (if not, the native frame will be used).
        
        The world coordinate is returned as a record of measures.  This
        function is just a wrapper for the Coordsys tool toworld function
        (invoked with argument {stfaf format='m'}).  Please see its
        documentation for discussion about the formatting and meaning of the
        measures.
        
        This Image tool function adds two additional fields to the return record.
        
        The {cf mask} field contains the value of the image pixelmask at the
        specified position. It is either T (pixel is good) or F (pixel is masked
        as bad or the specified position was off the image).
        
        The {cf intensity} field contains the value of the image (at the
        nearest pixel to that given) and its units.  This is actually stored
        as a Quantity. This field does not exist
        if the specified pixel coordinate is off the image.
        """
        schema = {'pixel': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'dframe': {'type': 'cStr'}, 'sframe': {'type': 'cStr'}}
        doc = {'pixel': pixel, 'dframe': dframe, 'sframe': sframe}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _coordmeasures_result = _dict_dc(self._swigobj.coordmeasures(_pc.document['pixel'], _str_ec(_pc.document['dframe']), _str_ec(_pc.document['sframe'])))
        return _coordmeasures_result

    def decompose(self, region={ }, mask='', simple=False, threshold=float(-1), ncontour=int(11), minrange=int(1), naxis=int(2), fit=True, maxrms=float(-1), maxretry=int(-1), maxiter=int(256), convcriteria=float(0.0001), stretch=False):
        """This function is an image decomposition tool that performs several tasks,
        with the end result being that a strongly blended image is separated into
        components - both in the sense that it determines the parameters for each
        component (assuming a Gaussian model) and that it physically assigns each
        pixel in the image to an individual object.  The products of these two
        operations are called the component list and the component map,
        respectively.  The fitting process (which determines the component list) and
        the pixel-decomposition process (which determines the component map) are
        designed to work cooperatively to increase the efficiency and accuracy of
        both.
        
        The algorithm behind the decomposition is based on the function clfind,
        described in Williams et al 1994, which uses a contouring procedure whereby
        a closed contour designates a separate component.  The program first
        separates the image into clearly distint 'regions' of blended emission, then
        contours each region to determine the areas constituting each component and
        passes this information on to the fitter, which determines the component
        list.
        
        The contour deblending can optionally be replaced with a simpler local maximum
        scan, and the fitting can be replaced with a moment-based estimation method to
        speed up calculations on very large images or if either primary method causes
        trouble, but in general this will impede the accuracy of the fit.
        
        The function works with both two and three dimensional images.
        
        The return value is a record (or dictionary) that has 3 keys: {tt 'components', 'blc', 'trc'}.
        The {tt 'components'} element is a matrix each row of which contains the gaussian parameters of the component fitted.
        The {tt 'blc'} element is a matrix of the bottom left corners (blc) of the regions found. Each row correspond to a region blc.
        The {tt 'trc'} element is a matrix of the top right corners (trc) of the regions found. Each row correspond to a region trc.
        {bf Please Note} that the returned blc's and trc's are relative to {tt region} defined by the user. A {tt blc } of  [0,0] implies the bottom left of the region selected and not  the bottom left of the image. Obviously if no region is defined then it is the bottom left of the image.
        
        """
        schema = {'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'simple': {'type': 'cBool'}, 'threshold': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'ncontour': {'type': 'cInt'}, 'minrange': {'type': 'cInt'}, 'naxis': {'type': 'cInt'}, 'fit': {'type': 'cBool'}, 'maxrms': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'maxretry': {'type': 'cInt'}, 'maxiter': {'type': 'cInt'}, 'convcriteria': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'stretch': {'type': 'cBool'}}
        doc = {'region': region, 'mask': mask, 'simple': simple, 'threshold': threshold, 'ncontour': ncontour, 'minrange': minrange, 'naxis': naxis, 'fit': fit, 'maxrms': maxrms, 'maxretry': maxretry, 'maxiter': maxiter, 'convcriteria': convcriteria, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _decompose_result = _dict_dc(self._swigobj.decompose(_any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['simple'], _pc.document['threshold'], _pc.document['ncontour'], _pc.document['minrange'], _pc.document['naxis'], _pc.document['fit'], _pc.document['maxrms'], _pc.document['maxretry'], _pc.document['maxiter'], _pc.document['convcriteria'], _pc.document['stretch']))
        return _decompose_result

    def deconvolvecomponentlist(self, complist, channel=int(-1), polarization=int(-1)):
        """This method deconvolves (a
        record representation of) a Componentlist tool from the restoring
        beam, returning (a record representation of) a new Componentlist tool.
        If there is no restoring beam, a fail is generated.
        
        Currently, only deconvolution of Gaussian components is supported.
        
        For images with per-plane beam, the user must choose which beam is used for
        the deconvolution by setting channel and/or polarization. Only a single beam
        is used to deconvolve all components.
        
        See also functions setrestoringbeam and
        restoringbeam.
        """
        schema = {'complist': {'type': 'cDict'}, 'channel': {'type': 'cInt'}, 'polarization': {'type': 'cInt'}}
        doc = {'complist': complist, 'channel': channel, 'polarization': polarization}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _deconvolvecomponentlist_result = _dict_dc(self._swigobj.deconvolvecomponentlist(_dict_ec(_pc.document['complist']), _pc.document['channel'], _pc.document['polarization']))
        return _deconvolvecomponentlist_result

    def deconvolvefrombeam(self, source=[ ], beam=[ ]):
        """This is a helper function. It is to provide a way to deconvolve gaussians from other gaussians if that is what is needed for example removing a beam Gaussian from a Gaussian source. To run this function the tool need not be attached to an image.
        
        The return value is a record that contains the fit param and the return value is a boolean which is set to true if fit model is a point source
        """
        schema = {'source': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'beam': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'source': source, 'beam': beam}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _deconvolvefrombeam_result = _dict_dc(self._swigobj.deconvolvefrombeam(_any_ec(_pc.document['source']), _any_ec(_pc.document['beam'])))
        return _deconvolvefrombeam_result

    def beamforconvolvedsize(self, source=[ ], convolved=[ ]):
        """Determine the size of the beam necessary to convolve with the given source to reach the
        given convolved (source+beam) size. Because the problem is completely specified by the
        input parameters, no image needs to be attached to the associated tool; eg ia.open() need
        not be called prior to calling this method.
        """
        schema = {'source': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'convolved': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'source': source, 'convolved': convolved}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _beamforconvolvedsize_result = _dict_dc(self._swigobj.beamforconvolvedsize(_any_ec(_pc.document['source']), _any_ec(_pc.document['convolved'])))
        return _beamforconvolvedsize_result

    def commonbeam(self):
        """Determine a beam to which all beams in an image can be convolved.
        If the image does not have a beam, an exception will be thrown.
        If the image has a single beam, that beam will be returned.
        If the image has multiple beams, this will be the beam with the largest area in the image
        beam set if all the other beams can be convolved to that beam. If not, this is guaranteed to be the minimum area beam to which
        all beams in the set can be convolved if all but one of the beams in the set can be convolved to the beam in the set with the
        largest area. Otherwise, the returned beam may or may not be the smallest possible beam to which all the beams in the set
        can be convolved.
        
        """
        _commonbeam_result = _dict_dc(self._swigobj.commonbeam())
        return _commonbeam_result

    def remove(self, done=False, verbose=True):
        """This function first closes the
        imagetool which detaches it from its underlying imagefile.  It then
        deletes that imagefile.  If {stfaf done=False}, the imagetool is still
        viable, and can be used with function open
        to open a new imagefile.  Otherwise the imagetool is destroyed.  If {stfaf verbose=True}, the logger will receive a progress report.
        """
        schema = {'done': {'type': 'cBool'}, 'verbose': {'type': 'cBool'}}
        doc = {'done': done, 'verbose': verbose}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _remove_result = self._swigobj.remove(_pc.document['done'], _pc.document['verbose'])
        return _remove_result

    def removefile(self, file):
        """This function deletes the specified image file.
        """
        schema = {'file': {'type': 'cStr'}}
        doc = {'file': file}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _removefile_result = self._swigobj.removefile(_str_ec(_pc.document['file']))
        return _removefile_result

    def done(self, remove=False, verbose=True):
        """When the user no longer needs to use an imagetool, calling this function
        will free up its resources.  That is, it destroys the tool.  This means
        that the user can no longer call any functions on the tool after it
        has been {stff done}.
        
        If the Image tool is associated with a disk file, then (unlike the
        {stff close} function, the user can also choose to delete that by
        setting {stfaf remove=true}.  By default, any associated disk file is
        not deleted.
        
        Note that this function is different from the {stff close} function
        because the latter does not destroy the imagetool.  For example, the
        user can use the {stff open} function straight after the {stff close}
        function on the same tool.
        """
        schema = {'remove': {'type': 'cBool'}, 'verbose': {'type': 'cBool'}}
        doc = {'remove': remove, 'verbose': verbose}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _done_result = self._swigobj.done(_pc.document['remove'], _pc.document['verbose'])
        return _done_result

    def fft(self, real='', imag='', amp='', phase='', axes=[ int(-1) ], region={ }, mask='', stretch=False, complex=''):
        """This function fast Fourier Transforms the supplied image to the Fourier plane.
        Both float valued and complex valued images are supported.
        If the {stfaf axes} parameter is left unset, then the sky plane of the image (if
        there is one) is transformed.  Otherwise, the user can specify which axes are
        to be transformed.  Note that if a sky axis is to be transformed, both of them
        must be specified.
        
        The user specifies which form is desired in the result by specifying the
        desired output image file name(s).
        
        Before the FFT is performed, any masked pixels are set to values of zero.
        The output mask is the combination (logical OR) of the default input
        pixelmask (if any) and the OTF mask.  Any other input pixelmasks
        will not be copied.  The function
        maskhandler can be
        used if there is a need to copy other masks too.
        """
        schema = {'real': {'type': 'cStr'}, 'imag': {'type': 'cStr'}, 'amp': {'type': 'cStr'}, 'phase': {'type': 'cStr'}, 'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'stretch': {'type': 'cBool'}, 'complex': {'type': 'cStr'}}
        doc = {'real': real, 'imag': imag, 'amp': amp, 'phase': phase, 'axes': axes, 'region': region, 'mask': mask, 'stretch': stretch, 'complex': complex}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fft_result = self._swigobj.fft(_str_ec(_pc.document['real']), _str_ec(_pc.document['imag']), _str_ec(_pc.document['amp']), _str_ec(_pc.document['phase']), _pc.document['axes'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['stretch'], _str_ec(_pc.document['complex']))
        return _fft_result

    def findsources(self, nmax=int(20), cutoff=float(0.1), region={ }, mask='', point=True, width=int(5), negfind=False):
        """This function  finds strong point sources in
        the image.  The sources are returned in a record that can be used by a
        Componentlist tool.
        
        An efficient method is used to locate sources under the assumption that
        they are point-like and not too close to the noise.  Only sources with a
        peak greater than the {stfaf cutoff} fraction of the strongest source
        will be found.  Only positive sources will be found, unless the {stfaf
        negfind=T} whereupon positive and negative sources will be found.
        
        After the list of point sources has been made, you may choose to make a
        Gaussian fit for each one ({stfaf point=F}) so that shape information
        can be recovered as well.    You can specify the half-width of the
        fitting grid with argument {stfaf width} which defaults to 5 (fitting
        grid would then be [11,11] pixels). If you set {stfaf width=0}, this is
        a signal that you would still like Gaussian components returned, but a
        default  width should be used for the Gaussian shapes.  The default is
        such that the component is circular with a FWHM of {stfaf width}
        pixels.
        
        Thus, if {stfaf point=T}, the components in the returned Componentlist
        are Point components.  If {stfaf point=F}  then Gaussian components are
        returned.
        
        The region must be 2-dimensional and it must hold a region of the sky.
        Any degenerate trailing dimensions in the region are discarded.
        
        See also the function fitcomponents (for which {stff
        findsources} can provide an initial estimate).
        """
        schema = {'nmax': {'type': 'cInt'}, 'cutoff': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'point': {'type': 'cBool'}, 'width': {'type': 'cInt'}, 'negfind': {'type': 'cBool'}}
        doc = {'nmax': nmax, 'cutoff': cutoff, 'region': region, 'mask': mask, 'point': point, 'width': width, 'negfind': negfind}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _findsources_result = _dict_dc(self._swigobj.findsources(_pc.document['nmax'], _pc.document['cutoff'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['point'], _pc.document['width'], _pc.document['negfind']))
        return _findsources_result

    def fitprofile(self, box='', region='', chans='', stokes='', axis=int(-1), mask='', ngauss=int(1), poly=int(-1), estimates='', minpts=int(1), multifit=False, model='', residual='', amp='', amperr='', center='', centererr='', fwhm='', fwhmerr='', integral='', integralerr='', stretch=False, logresults=True, pampest=[  ], pcenterest=[  ], pfwhmest=[  ], pfix='', gmncomps=int(0), gmampcon=[  ], gmcentercon=[  ], gmfwhmcon=[  ], gmampest=[ float(0.0) ], gmcenterest=[ float(0.0) ], gmfwhmest=[ float(0.0) ], gmfix='', spxtype='', spxest=[  ], spxfix=[  ], div=[ ], spxsol='', spxerr='', logfile='', append=True, pfunc='', goodamprange=[ float(0.0) ], goodcenterrange=[ float(0.0) ], goodfwhmrange=[ float(0.0) ], sigma='', outsigma='', planes=[  ]):
        """This application simultaneously fits any number of gaussian singlets, any number of lorentzian singlets, and any number of gaussian multiplets,
        and/or a polynomial to one dimensional profiles using the non-linear, least squares Levenberg-Marquardt algorithm. A description of the
        fitting algorithm may be found in AIPS++ Note 224 (http://www.astron.nl/casacore/trunk/casacore/doc/notes/224.html) and in Numerical Recipes
        by W.H. Press et al., Cambridge University Press. A gaussian/lorentzian singlet is a gaussian/lorentzian whose parameters (amplitude,
        center position, and width) are all independent from any other feature that may be simultaneously fit. A gaussian multiplet is a set of two or
        more gaussian lines in which at least one (and possibly two or three) parameter of each line is dependent on the parameter of another,
        single (reference) profile in the multiplet. For example, one can specify a doublet in which the amplitude of the first line is 0.6 times the
        amplitude of the zeroth line and/or the center of the first line is 20 pixels from the center of the zeroth line, and/or the fwhm of the first
        line is identical (in pixels) to that of the zeroth line. There is no limit to the number of components one can specify in a multiplet
        (except of course that the number of parameters to be fit should be significantly less than the number of data points), but there can be only
        a single reference profile in a multiplet to which to tie constraints of parameters of the other profiles in the set.
        
        Additionally, a power logarithmic polynomial (plp) or a logarithmic tranformed polynomial (ltp) can be fit. In this case, each of these functions
        cannot be fit simultaneously with any other supported function. These functions are most often used for fitting the spectral index and
        higher order terms of a spectrum. A power logarithmic polynomial has the form
        
        y = c0*x/div**(c1 + c2*ln(x/div) + c3*ln(x/div)**2 + ... + cn*ln(x/div)**(n - 1))
        
        and a logarithmic transformed polynomial is simply the result of this equation after taking the natural log of both sides so that it has the form
        
        ln(y) = c0 + c1*ln(x/div) + c2*ln(x/div)**2 +  ... + cn*ln(x/div)**n
        
        The coefficients of the two forms correspond with each other except that c0 in the second equation is equal to
        ln(c0) of the first. In the case of fitting a spectral index, the spectral index, traditionally represented as alpha, is
        equal to c1.
        
        In both cases, div is a numerical value used to scale abscissa values so they are closer to unity when they are sent to the fitter. This generally
        improves the probability that the fit will converge. This parameter may be specified via the div parameter. A value of 0
        (the default) indicates that the application should determine a reasonable value for div, which is determined via
        
        div = 10**int(log10(sqrt(min(x)*max(x))))
        
        where min(x) and max(x) are the minimum and maximum abscissa values, respectively.
        
        So, for example, if S(nu) is proportional to nu**alpha and you expect alpha to be near -0.8 and the value of S(nu) is 1.5 at
        1e9 Hz and your image(s) have spectral units of Hz, you would specify spxest=[1.5, -0.8] and div=1e9 when fitting a plp function,
        or spxest=[0.405, -0.8] and div=1e9 if fitting an ltp function.
        
        More details of fitting all of these functions are described in following sections.
        
        A CAUTIONARY NOTE
        Note that the likelihood of getting a reliable solution increases with the number of good data points as well as the goodness
        of the initial estimate. It is possible that the first solution found might not be the best one, and
        so, if a solution is found, it is recommended that the fit be repeated using the solution of the previous fit as the
        initial estimatE for the new fit. This process should be repeated until the solutions from one fit to the next differ only insignificantly.
        The convergent solution is very likely the best solution.
        
        AXIS
        The axis parameter indicates on which axis profiles should be fit; a value <0 indicates the spectral axis should be used, or if one does not exist,
        that the zeroth axis should be used.
        
        MINIMUM NUMBER OF PIXELS
        The minpts parameter indicates the minimum number of unmasked pixels that must be present in order for a fit
        to be attempted. When multifit=True, positions with too few good points will be masked in any output images.
        
        ONE FIT OF REGION AVERAGE OR PIXEL BY PIXEL FIT
        The multifit parameter indicates if profiles should be fit at each pixel in the selected region (true), or if the profiles in that region should be
        averaged and the fit done to that average profile (false).
        
        POLYNOMIAL FITTING
        The order of the polynomial to fit is specified only via the poly parameter. If poly<0, no polynomial will be fit. No initial estimates of
        coefficients can be specified; these are determined automatically.
        
        GAUSSIAN SINGLET FITTING
        In the absence of an estimates file and no estimates being specified by the p*est parameters, and gmncomps=0 or is empty, the ngauss parameter
        indicates the maximum number of gaussian singlets that should be fit. The initial estimates of the parameters for these gaussians will be attempted
        automatically in this case. If it deems appropriate, the fitter will fit fewer than this number. In the case where an estimates file is supplied,
        ngauss is ignored (see below). ngauss is also ignored if the p*est parameters are specified or if gmncomps is not an empty array or, if an integer,
        is greater than zero. If estimates is not specified or the p*est parameters are not specified and ngauss=0, gmncomps is empty or 0, and poly<0,
        an error will occur as this indicates there is nothing to fit.
        
        One can specify initial estimates of gaussian singlet parameters via an estimates file or the pampest, pcenterest, pfwhmest, and optionally, the
        pfix parameters. The latter is the recommended way to specify these estimates as support for estimates files may be deprecated in the future. No matter
        which option is used, an amplitude initial estimate must always be nonzero.  A negative fwhm estimate will be silently changed to positve.
        
        SPECIFYING INITIAL ESTIMATES FOR GAUSSIAN AND LORENTZIAN SINGLETS (RECOMMENDED METHOD)
        One may specify initial estimates via the pampest, pcenterest, and pfwhmest parameters. In the case of a single gaussian or lorentzian singlet,
        these parameters can be numbers. pampest must be specified in image brightness units, pcenterest must be given in the number of pixels from the
        zeroth pixel, and pfwhmest must be given in pixels. Optionally pfix can be specified and in the case of a single gaussian or lorentzian singlet
        can be a string. In it is coded which parameters should be held constant during the fix. Any combination of "p" (amplitude), "c" (center), or "f"
        (fwhm) is allowed; eg pfix="pc" means fix both the amplitude and center during the fit. In the case of more than one gaussian and/or lorentzian
        singlets, these parameters must be specified as arrays of numbers. The length of the arrays indicates the number of singlets to fit and must be
        the same for all the p*est parameters.
        
        If no parameters are to be fixed for any of the singlets, pfix can be set to the empty string. However, if at least one parameter of one singlet
        is to be fixed, pfix must be an array of strings and have a length equal to the p*est arrays. Singlets which are not to have any parameters fixed
        should be represented as an empty string in the pfix array. So, for example, if one desires to fit three singlets and fix the fwhm of the middle
        one, one must specify pfix=["", "f", ""], the empty strings indicating no parameters of the zeroth and second singlet should be held constant.
        
        In the case of multifit=True, the initial estimates, whether from the p*est parameters or from a file (see below), will be applied to the location
        of the first fit. This is normally the bottom left corner of the region selected. If masked, not enough good points to perform a fit, or the
        attempted fit fails, the fitting proceeds to the next pixel with the pixel value of the lowest numbered axis changing the fastest. Once a
        successful fit has been performed, subsequent fits will use the results of a fit for a nearest pixel for which a previous fit was successful as the
        initial estimate for the parameters at the current location. The fixed parameter string will be honored for every fit performed when multifit=True.
        
        One specifies what type of PCF profile to fit via the pfunc parameter. A PCF function is one that can be parameterized by a peak, center, and FWHM,
        as both gaussian and lorentzian singlets can. If all singlets to be fit are gaussians, one can set pfunc equal to the empty string and all snglets
        will be assumed to be gaussians. If at least one lorentzian is to be fit, pfunc must be specified as a string (in the case of a single singlet) or
        an array of strings (in the case of multiple singlets). The position of each string corresponds to the positions of the initial estimates in the
        p*est and pfix arrays. Minimal match ("g", "G", "l", or "L") is supported. So, if one wanted to simultaneously fit two gaussian and two lorentzian
        singlets, the zeroth and last of which were lorentzians, one would specify pfunc=["L", "G", "G", "L"].
        
        ESTIMATES FILE FOR GAUSSIAN SINGLETS (NONRECOMMENDED METHOD)
        Initial estimates for gaussian singlets can be specified in an estimates file. Estimates files may be deprecated in the future in favor of the
        p*est parameters, so it is recommended users use those parameters instead. If an estimates file is desired to be used, the p*est parameters
        must be 0 or empty and mgncomps must be 0 or empty. Only gaussian singlets can be specified in an estimates file. If one desires to fit one or
        more gaussian multiplets and/or one or more lorentzian singlets simultaneously, the p*est parameters must be used to specify the initial parameters
        of all gaussian singlets to fit; one cannot use an estimates file in this case. If an estimates file is specified, a polynomial
        can be fit simultaneously by specifying the poly parameter. The estimates file must contain initial estimates of parameters
        for all gaussian singlets to be fit. The number of gaussian singlets to fit is gotten from the number of estimates in the file. The file can contain
        comments which are indicated by a "#" at the beginning of a line. All non-comment lines will be interpreted as initial estimates. The
        format of such a line is
        
        [peak intensity], [center], [fwhm], [optional fixed parameter string]
        
        The first three values are required and must be numerical values. The peak intensity must be expressed in image brightness units, while the
        center must be specified in pixels offset from the zeroth pixel, and fwhm must be specified in pixels. The fourth value is optional and if present,
        represents the parameter(s) that should be held constant during the fit. Any combination of the characters 'p' (peak), 'c' (center), and 'f' (fwhm) are
        permitted, eg "fc" means hold the fwhm and the center constant during the fit. Fixed parameters will have no error associated with them. Here is an
        example file:
        
        begin{verbatim}
        # estimates file indicating that two gaussians should be fit
        # first guassian estimate, peak=40, center at pixel number 10.5, fwhm = 5.8 pixels, all parameters allowed to vary during
        # fit
        40, 10.5, 5.8
        # second gaussian, peak = 4, center at pixel number 90.2, fwhm = 7.2 pixels, hold fwhm constant
        4, 90.2, 7.2, f
        # end file
        end{verbatim}
        
        GAUSSIAN MULTIPLET FITTING
        Any number of gaussian multiplets, each containing any number of two or more components, can be simultaneously fit, optionally with a
        polynomial and/or any number of gaussian and/or lorentzian singlets, the only caveat being that the number of parameters to be fit should be
        significantly less than the number of data points. The gmncomps parameter indicates the number of multiplets to fit and the number of
        components in each multiplet. In the case of a single multiplet, an integer (>1) can be specified. For example, mgncomps=4 means fit a
        single quadruplet of gaussians. In the case of 2 or more multiplets, and array of integers (all >1) must be specified. For example,
        gmncomps=[2, 4, 3] means 3 seperate multiples are to be fit, the zeroth being a doublet, the first being a quadruplet, and the second
        being a triplet.
        
        Initial estimates of all gaussians in all multiplets are specified via the gm*est parameters which must be arrays of numbers. The order
        starts with the zeroth component of the zeroth multiplet to the last component of the zeroth multiplet, then the zeroth component of
        the first multiplet to the last compoenent of the first multiplet, etc to the zeroth component of the last multiplet to the last
        element of the last multiplet. The zeroth element of a multiplet is defined as the reference component of that multiplet and has the special
        significance that it is the profile to which all constraints of all other profiles in that multiplet are referenced (see below). So,
        in our example of gmncomps=[2, 4, 3], gmampest, gmcenterest, and gmfwhmest must each be nine (the total number of individual gaussian
        profiles summed over all multiplets) element arrays. The zeroth, second, and sixth elements represent parameters of the reference profiles
        in the zeroth, first, and second multiplet, respectively.
        
        The fixed relationships between the non-reference profile(s) and the reference profile of a multiplet are specified via the gmampcon,
        gmcentercon, and gmfwhmcon parameters. At least one, and any combination, of constraints can be specified for any non-reference
        component of a multiplet. The amplitude ratio of a non-reference line to that of the reference line is set in gmampcon. The ratio of
        the fwhm of a non-reference line to that of the reference line is set in gmfwhmcon. The offset in pixels of the center position of
        a non-reference line to that of the reference line is set in gmcentercon. In the case where a parameter is not constrained for any
        non-reference line of any multiplet, the value of the associated parameter must be 0. In the case of
        a single doublet, a constraint may be specified as a number or an array of a single number. For example, mgncomps=2 and gmampcon=0.65
        and gmcentercon=[32.4] means there is a single doublet to fit where the amplitude ratio of the first to the zeroth line is constained
        to be 0.65 and the center of the first line is constrained to be offset by 32.4 pixels from the center of the zeroth line. In cases
        of a total of three or more gaussians, the constraints parameters must be specified as arrays with lengths equal to the total number
        of gaussians summed over all multiplets minus the number of reference lines (one per multiplet, or just number of multiplets, since
        reference lines cannot be constrained by themselves). In the cases where an array must be specified but a component in that array
        does not have that constraint, 0 should be specified. Here's an example
        
        gmncomps=[2, 4, 3]
        gmampcon=  [ 0  ,  0.2,  0  , 0.1,   4.5,   0  ]
        gcentercon=[24.2, 45.6, 92.7, 0  , -22.8, -33.5]
        gfwhmcon=""
        
        In this case we have our previous example of one doublet, one quadruplet, and one triplet. The first component of the doublet has the constraint
        that its center is offset by 24.2 pixels from the zeroth (reference) component. The first component of the quadruplet is constrained to have
        an amplitude of 0.2 times that of the quadruplet's zeroth component and its center is constrained to be offset by 45.6 pixels from the
        reference component. The second component of the quadruplet is constained to have its center offset by 92.7 pixels from the associated
        reference component and the third component is constrained to have an amplitude of 0.1 times that of the associated reference component.
        The first component of the triplet is constrained to have an amplitude of 4.5 times that of its associated reference component and its center
        is constrained to be offset by -22.8 pixels from the reference component's center. The second component of the triplet is constrained to have
        its center offset by -33.5 pixels from the center of the reference component. No lines have FWHM constraints, so the empty string can be given
        for that parameter. Note that using 0 to indicate no constraint for line center means that one cannot specify a line centered at the same
        position as the reference component but having a different FWHM from the reference component. If you must specify this very unusual case,
        try using a very small positive (or even negative) value for the center constraint.
        
        Note that when a parameter for a line is constrained, the corresponding value for that component in the corresponding gm*est array is
        ignored and the value of the constrained parameter is automatically used instead. So let's say, for our example above, we had specified
        the following estimates:
        
        gmampest =     [ 1,   .2,  2,   .1,    .1,   .5,  3,    2, 5]
        gmcenterest =  [20, 10  , 30, 45.2, 609  , -233, 30, -859, 1]
        
        Before any fitting is done, the constraints would be taken into account and these arrays would be implicitly rewritten as:
        
        gmampest =     [ 1,   .2,  2,   .4,    .1,   .2,  3, 13.5,  5  ]
        gmcenterest =  [20, 44.2, 30, 75.6, 127.7, -233, 30,  7.2, -3.5]
        
        The value of gmfwhmest would be unchanged since there are no FWHM constraints in this example.
        
        In addition to be constrained by values of the reference component, parameters of individual components can be fixed. Fixed parameters
        are specified via the gmfix parameter. If no parameters are to be fixed, gmfix can be specified as the empty string or a zero element
        array. In the case where any parameter is to be fixed, gmfix must be specified as an array of strings with length equal to the total number of
        components summed over all multiplets. These strings encode which parameters to be fixed for the corresponding components. If
        a component is to have no parameters fixed, an empty string is used. In other cases one or more of any combination of parameters can
        be fixed using "p", "c", and/or "f" described above for fixing singlet parameters. There are a couople of special cases
        to be aware of. In the case where a non-reference component parameter is constrained and the corresponding reference component parameter is
        set as fixed, that parameter in the non-reference parameter will automatically be fixed even if it was specified not to be fixed in
        the gmfix array. This is the only way the constraint can be honored afterall. In the converse case of when a constrained parameter of a
        non-reference component is specified as fixed, but the corresponding parameter in the reference component is not specified to be fixed,
        an error will occur. Fixing an unconstrained parameter in a non-reference component is always legal as is fixing any combination of
        parameters in a reference component (with the above caveat that corresponding constrained parameters in non-reference components will
        be silently held fixed as well).
        
        The same rules that apply to singlets when multifit=True apply to multiplets.
        
        LIMITING RANGES FOR SOLUTION PARAMETERS
        In cases of low (or no) signal to noise spectra, it is still possible for the fit to converge, but often to a
        nonsensical solution. The astronomer can use her knowledge of the source to filter out obviously bogus solutions.
        Any solution which contains a NaN value as a value or error in any one of its parameters is automatically marked as
        invalid.
        
        One can also limit the ranges of solution parameters to known "good" values via the goodamprange, goodcenterrange, and goodfwhmrange
        parameters. Any combination can be specified and the limit constraints will be ANDed together. The ranges apply to all PCF components
        that might be fit; choosing ranges on a component by component basis is not supported. If specified,
        an array of exactly two numerical values must be given to indicate the range of acceptable solution values for
        that parameter.  goodamprange is expressed in terms of image brightness units. goodcenterrange is expressed in terms of pixels
        from the zeroth pixel in the specified region. goodfwhmrange is expressed in terms of pixels (only non-negative values should be
        given for FWHM range endpoints). In the case of a multiple-PCF fit, if any of the corresponding solutions are outside the specified
        ranges, the entire solution is considered to be invalid.
        
        In addition, solutions for which the absolute value of the ratio of the amplitude error to the amplitude exceeds 100 or the
        ratio of the FWHM error to the FWHM exceeds 100 are automatically marked as invalid.
        
        POWER LOGARITHMIC POLYNOMIAL  AND LOGARITHMIC TRANSFORMED POLYNOMIAL FITTING
        Fitting of a sngle power logarithmic polynomial or a single logarithmic transformed polynomial function is supported.
        No other functions may be fit simultaneously with either of these; if parameters relating to other functions are supplied
        simultaneously with parameters relating
        to these functions, an exception will occur. For details of the functional forms, see the introduction of this
        document.
        
        The set of c0 ... cn coefficients (as defined previously) can
        be solved for. Initial estimates for the c values should be supplied via the plpest or ltpest parameters, depending on which
        form is being fit. The number of values given
        in this array will be the number of coeffecients that are solved for. One may specify which coefficients should be held
        fixed during the fit in the plpfix or ltpfix array. If supplied, this array should have the same number of elements as its respective
        initial estimates array. A value
        of True means the corresponding coefficient will be held fixed during the fit. An empty array indicates that no
        parameters will be held fixed. This is the default.
        
        Because the logarithm of the ordinate values must be taken before fitting a logarithmic transformed polynomial,
        all non-positive pixel values are effectively masked for the purposes of fitting.
        
        INCLUDING STANDARD DEVIATIONS OF PIXEL VALUES
        If the standard deviations of the pixel values in the input image are known and they vary in the image (eg they are higher for pixels
        near the edge of the band), they can be included in the sigma parameter. This parameter takes either an array or an image name. The
        array or image must have one of three shapes: 1. the shape of the input image, 2. the same dimensions as the input image with the lengths
        of all axes being one except for the fit axis which must have length corresponding to its length in the input image, or 3. be one
        dimensional with lenght equal the the length of the fit axis in the input image. In cases 2 and 3, the array or pixels in sigma will
        be replicated such that the image that is ultimately used is the same shape as the input image. The values of sigma must be non-negative.
        It is only the relative values that are important. A value of 0 means that pixel should not be used in the fit. Other than that, if pixel
        A has a higher standard deviation than pixel B, then pixel A is noisier than pixel B and will receive a lower weight when the fit is done.
        The weight of a pixel is the usual
        
        weight = 1/(sigma*sigma)
        
        In the case of multifit=False, the sigma values at each pixel along the fit axis in the hyperplane perpendicular to the fit axis which includes
        that pixel are averaged and the resultant averaged standard deviation spectrum is the one used in the fit. Internally, sigma values are normalized
        such that the maximum value is 1. This mitigates a known overflow issue.
        
        One can write the normalized standard deviation image used in the fit but specifying its name in outsigma. This image can then be
        used as sigma for subsequent runs.
        
        
        RETURNED DICTIONARY STRUCTURE
        The returned dictionary has a (necessarily) complex structure. First, there are keys "xUnit" and "yUnit" whose values are
        the abscissa unit and the ordinate unit described by simple strings. Next there are arrays giving a broad overview of the
        fit quality. These arrays have the shape of the specified region collapsed along the fit axis with the axis corresponding to the fit
        axis having length of 1:
        
        attempted: a boolean array indicating which fits were attempted (eg if too few unmasked points, a fit will not be attempted).
        converged: a boolean array indicating which fits converged. False if the fit was not attempted.
        valid:     a boolean array indicating which solutions fall within the specified valid ranges of parameter space (see
        section LIMITING RANGES FOR SOLUTION PARAMETERS for details).
        niter:     an int array indicating the number of iterations for each profile, <0 if the fit did not converge
        ncomps:    the number of components (gaussian singlets + lorentzian singlets + gaussian multiplets + polynomial) fit for the profile,
        <0 if the fit did not converge
        direction: a string array containing the world direction coordinate for each profile
        
        There is a "type" array having number of dimensions equal to the number of dimensions in the above arrays plus one. The shape of
        the first n-1 dimensions is the same as the shape of the above arrays. The length of the last dimension is equal to the number of
        components fit. The values of this array are strings describing the components that were fit at each possition ("POLYNOMIAL",
        "GAUSSIAN" in the case of gaussian singlets, "LORENTZIAN" in the case of lorentzian singlets, and ""GAUSSIAN MULTPLET").
        
        If any gaussian singlets were fit, there will be a subdictionary accessible via the "gs" key which will have subkeys "amp", "ampErr", "center",
        "centerErr", "fwhm", "fwhmErr, "integral", and "integralErr". Each of these arrays will have one more dimension than the overview arrays described
        above. The shape of the first n-1 dimensions will be the same as the shape of the arrays described above, while the final dimension will
        have length equal to the maximum number of gaussian singlets that were fit. Along this axis will be the
        corresponding fit result or associated error (depending on the array's associated key) of the fit for that singlet component number. In cases where
        the fit did not converge, or that particular component was excluded from the fit, a value of NAN will be present.
        
        If any lorentzian singlets were fit, their solutions will be accessible via the "ls" key. These arrays follow the same rules
        as the "gs" arrays described above.
        
        If any gaussian multiplets were fit, there will be subdictionaries accessible by keys "gm0", "gm1", ..., "gm{n-1}" where n is the number of gaussian
        muliplets that were fit. Each of these dictionaries will have the same arrays described above for gaussian singlets. The last dimension
        will have length equal to the number of components in that particular multiplet. Each pixel along the last axis will be the parameter solution
        value or error for that component number in the multiplet, eg the zeroth pixel along that axis contains
        the parameter solution or error for the reference component of the multiplet.
        
        The polynomial coefficient solutions and errors are not returned, although they are logged.
        
        If a power logarithmic polynomial was fit, there will be a subdictionary accessible via the "plp" key which will have
        subkeys "soltuion" and "error" which will each have an array value. Each of these arrays will have one more dimension than the overview arrays
        described above. The shape of the first n-1 dimensions will be the same as the shape of the overview arrays described above, while the
        final dimension will have length equal to the number of parameters that were fit. Along this axis will be the
        corresponding fit result or associated error (depending on the array's associated key) of the fit. In cases where
        the fit was not attempted or did not converge, a value of NAN will be present.
        
        OUTPUT IMAGES
        In addition to the returned dictionary, optionally one or more of any combination of output images can be written.
        The model and residual parameters indicate the names of the model and residual images to be written; blank values inidcate that these images
        should not be written.
        
        One can also write none, any or all of the solution and error images for gaussian singlet, lorentzian singlet,  and gaussian multiplet fits
        via the parameters amp, amperr, center, centererr, fwhm, fwhmerr, integral, integralerr when doing multi-pixel fits. For a power logarithmic
        polynomial or a logarithmic transformed polynomial fit, plpsol or ltpsol and plperr or ltpsol are the names of the solution and error
        images to write, respectively.
        
        These images contain the arrays described for the associated parameter solutions or errors described in previous sections. Each
        component is written to a different image, and each image is distiguished by the component it represents by its name ending
        in an uderscore and the relevant component number ("_0", "_1", etc). In the case of Gaussian multiplets, the image name ends
        with the number of the mulitplet group followed by the number of the component in that group (eg "_3_4" represents component
        4 in multiplet group 3). In the case of lorentzian singlets, "_ls" is appended to the image names (but before the
        identifying component number), in the case of gaussian multiplets. Similarly "_gm" is included in the name of Gaussian multiplet
        images. Pixels for which fits were not attempted, did not converge, or converged but have values of NaN (not a number) or
        INF (infinity) will be masked as bad.
        
        Writing analogous images for polynomial coefficients is not supported.
        
        
        """
        schema = {'box': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cPath', 'coerce': _coerce.expand_path}, {'type': 'cDict'}]}, 'chans': {'type': 'cStr'}, 'stokes': {'type': 'cStr'}, 'axis': {'type': 'cInt'}, 'mask': {'anyof': [{'type': 'cStr'}, {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}]}, 'ngauss': {'type': 'cInt'}, 'poly': {'type': 'cInt'}, 'estimates': {'type': 'cPath', 'coerce': _coerce.expand_path}, 'minpts': {'type': 'cInt'}, 'multifit': {'type': 'cBool'}, 'model': {'type': 'cStr'}, 'residual': {'type': 'cStr'}, 'amp': {'type': 'cStr'}, 'amperr': {'type': 'cStr'}, 'center': {'type': 'cStr'}, 'centererr': {'type': 'cStr'}, 'fwhm': {'type': 'cStr'}, 'fwhmerr': {'type': 'cStr'}, 'integral': {'type': 'cStr'}, 'integralerr': {'type': 'cStr'}, 'stretch': {'type': 'cBool'}, 'logresults': {'type': 'cBool'}, 'pampest': {'anyof': [{'type': 'cFloat', 'coerce': _coerce.to_float}, {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}]}, 'pcenterest': {'anyof': [{'type': 'cFloat', 'coerce': _coerce.to_float}, {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}]}, 'pfwhmest': {'anyof': [{'type': 'cFloat', 'coerce': _coerce.to_float}, {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}]}, 'pfix': {'anyof': [{'type': 'cStr'}, {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}]}, 'gmncomps': {'anyof': [{'type': 'cInt'}, {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}]}, 'gmampcon': {'anyof': [{'type': 'cFloat', 'coerce': _coerce.to_float}, {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}]}, 'gmcentercon': {'anyof': [{'type': 'cFloat', 'coerce': _coerce.to_float}, {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}]}, 'gmfwhmcon': {'anyof': [{'type': 'cFloat', 'coerce': _coerce.to_float}, {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}]}, 'gmampest': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'gmcenterest': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'gmfwhmest': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'gmfix': {'anyof': [{'type': 'cStr'}, {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}]}, 'spxtype': {'type': 'cStr'}, 'spxest': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'spxfix': {'type': 'cBoolVec'}, 'div': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'spxsol': {'type': 'cStr'}, 'spxerr': {'type': 'cStr'}, 'logfile': {'type': 'cStr'}, 'append': {'type': 'cBool'}, 'pfunc': {'anyof': [{'type': 'cStr'}, {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}]}, 'goodamprange': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'goodcenterrange': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'goodfwhmrange': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'sigma': {'anyof': [{'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, {'type': 'cStr'}, {'type': 'cIntArray', 'coerce': [_coerce.to_intarray]}, {'type': 'cFloatArray', 'coerce': [_coerce.to_floatarray]}, {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}]}, 'outsigma': {'type': 'cStr'}, 'planes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'box': box, 'region': region, 'chans': chans, 'stokes': stokes, 'axis': axis, 'mask': mask, 'ngauss': ngauss, 'poly': poly, 'estimates': estimates, 'minpts': minpts, 'multifit': multifit, 'model': model, 'residual': residual, 'amp': amp, 'amperr': amperr, 'center': center, 'centererr': centererr, 'fwhm': fwhm, 'fwhmerr': fwhmerr, 'integral': integral, 'integralerr': integralerr, 'stretch': stretch, 'logresults': logresults, 'pampest': pampest, 'pcenterest': pcenterest, 'pfwhmest': pfwhmest, 'pfix': pfix, 'gmncomps': gmncomps, 'gmampcon': gmampcon, 'gmcentercon': gmcentercon, 'gmfwhmcon': gmfwhmcon, 'gmampest': gmampest, 'gmcenterest': gmcenterest, 'gmfwhmest': gmfwhmest, 'gmfix': gmfix, 'spxtype': spxtype, 'spxest': spxest, 'spxfix': spxfix, 'div': div, 'spxsol': spxsol, 'spxerr': spxerr, 'logfile': logfile, 'append': append, 'pfunc': pfunc, 'goodamprange': goodamprange, 'goodcenterrange': goodcenterrange, 'goodfwhmrange': goodfwhmrange, 'sigma': sigma, 'outsigma': outsigma, 'planes': planes}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fitprofile_result = _dict_dc(self._swigobj.fitprofile(_str_ec(_pc.document['box']), _any_ec(_pc.document['region']), _str_ec(_pc.document['chans']), _str_ec(_pc.document['stokes']), _pc.document['axis'], _any_ec(_pc.document['mask']), _pc.document['ngauss'], _pc.document['poly'], _str_ec(_pc.document['estimates']), _pc.document['minpts'], _pc.document['multifit'], _str_ec(_pc.document['model']), _str_ec(_pc.document['residual']), _str_ec(_pc.document['amp']), _str_ec(_pc.document['amperr']), _str_ec(_pc.document['center']), _str_ec(_pc.document['centererr']), _str_ec(_pc.document['fwhm']), _str_ec(_pc.document['fwhmerr']), _str_ec(_pc.document['integral']), _str_ec(_pc.document['integralerr']), _pc.document['stretch'], _pc.document['logresults'], _any_ec(_pc.document['pampest']), _any_ec(_pc.document['pcenterest']), _any_ec(_pc.document['pfwhmest']), _any_ec(_pc.document['pfix']), _any_ec(_pc.document['gmncomps']), _any_ec(_pc.document['gmampcon']), _any_ec(_pc.document['gmcentercon']), _any_ec(_pc.document['gmfwhmcon']), _pc.document['gmampest'], _pc.document['gmcenterest'], _pc.document['gmfwhmest'], _any_ec(_pc.document['gmfix']), _str_ec(_pc.document['spxtype']), _pc.document['spxest'], _pc.document['spxfix'], _any_ec(_pc.document['div']), _str_ec(_pc.document['spxsol']), _str_ec(_pc.document['spxerr']), _str_ec(_pc.document['logfile']), _pc.document['append'], _any_ec(_pc.document['pfunc']), _pc.document['goodamprange'], _pc.document['goodcenterrange'], _pc.document['goodfwhmrange'], _any_ec(_pc.document['sigma']), _str_ec(_pc.document['outsigma']), _pc.document['planes']))
        return _fitprofile_result

    def fitcomponents(self, box='', region=[ ], chans=[ ], stokes='', mask='', includepix=[ float(-1) ], excludepix=[ float(-1) ], residual='', model='', estimates='', logfile='', append=True, newestimates='', complist='', overwrite=False, dooff=False, offset=float(0.0), fixoffset=False, stretch=False, rms='', noisefwhm='', summary=''):
        """OVERVIEW
        
        This application is used to fit one or more two dimensional gaussians to sources in an image as
        well as an optional zero-level offset. Fitting is limited to a single polarization
        but can be performed over several contiguous spectral channels.
        If the image has a clean beam, the report and returned dictionary will contain both the convolved
        and the deconvolved fit results.
        
        When dooff is False, the method returns a dictionary with keys named 'converged', 'pixelsperarcsec',
        'results', and 'deconvolved'. The value of 'converged' is a boolean array which indicates if the
        fit converged on a channel by channel basis. The value of 'pixelsperarcsec' is a two element double
        array with the absolute values of the direction coordinate pixel increments (longitude-like and
        latitude-like coordinate, respectively) in arcsec. The value of 'results' is a dictionary
        representing a component list reflecting the fit results. In the case of an image containing beam
        information, the sizes and position angles in the 'results' dictionary are those of the source(s)
        convolved with the restoring beam, while the same parameters in the 'deconvolved' dictionary
        represent the source sizes deconvolved from the beam. In the case where the image does not
        contain a beam, 'deconvolved' will be absent. Both the 'results' and 'deconvolved' dictionaries can
        be read into a component list tool (default tool is named cl) using the fromrecord() method for
        easier inspection using tool methods, eg
        
        cl.fromrecord(res['results'])
        
        although this only works if the flux density units are conformant with Jy.
        
        There are also values in each component subdictionary not used by cl.fromrecord() but meant to
        supply additional information. There is a 'peak' subdictionary for each component that provides the
        peak intensity of the component. It is present for both 'results' and 'deconvolved' components.
        There is also a 'sum' subdictionary for each component indicated the simple sum of pixel values in
        the the original image enclosed by the fitted ellipse. There is a 'channel' entry in the 'spectrum'
        subdictionary which provides the zero-based channel number in the input image for which the solution
        applies. In addtion, if the image has a beam(s), then there will be a 'beam' subdictionary associated
        with each component in both the 'results' and 'deconvolved' dictionaries. This subdictionary will
        have three keys: 'beamarcsec' will be a subdictionary giving the beam dimensions in arcsec,
        'beampixels' will have the value of the beam area expressed in pixels, and 'beamster' will have the
        value of the beam area epressed in steradians. Also, if the image has a beam(s), in the component level
        dictionaries will be an 'ispoint' entry with an associated boolean value describing if the component
        is consistent with a point source. Each component level dictionary will have a 'pixelcoords' entry
        which has the value of a two element numeric array which provides the direction pixel coordinates
        of the fitted position.
        
        If dooff is True, in addtion to the specified number of
        gaussians, a zero-level offset will also be fit. The initial estimate for this
        offset is specified using the offset parameter. Units are assumed to be the
        same as the image brightness units. The zero level offset can be held constant during
        the fit by specifying fixoffset=True. In the case of dooff=True, the returned
        dictionary contains two additional keys, 'zerooff' and 'zeroofferr', which are both
        dictionaries containing 'unit' and 'value' keys. The values associated with the 'value'
        keys are arrays containing the the fitted zero level offset value and its error, respectively,
        for each channel. In cases where the fit did not converge, these values are set to NaN.
        The value associated with 'unit' is just the image brightness unit.
        
        The region can either be specified by a box(es) or a region.
        Ranges of pixel values can be included or excluded from the fit. If specified using
        the box parameter, multiple boxes can be given using the format
        box="blcx1, blcy1, trcx1, trcy1, blcx2, blcy2, trcx2, trcy2, ... , blcxN, blcyN, trcxN, trcyN"
        where N is the number of boxes. In this case, the union of the specified boxes will be used.
        
        If specified, the residual and/or model images for successful fits will be written.
        
        If an estimates file is not specified, an attempt is made to estimate
        initial parameters and fit a single Gaussian. If a multiple Gaussian fit
        is desired, the user must specify initial estimates via a text file
        (see below for details).
        
        The user has the option of writing the result of the fit to a log file,
        and has the option of either appending to or overwriting an existing file.
        
        The user has the option of writing the (convolved) parameters of a successful
        fit to a file which can be fed back to fitcomponents() as the estimates file for a
        subsequent run.
        
        The user has the option of writing the fit results in tabular format to a file whose
        name is specified using the summary parameter.
        
        If specified and positive, the value of rms is used to calculate the parameter uncertainties,
        otherwise, the rms in the selected region in the relevant channel is used for these calculations.
        
        The noisefwhm parameter represents the noise-correlation beam FWHM. If specified as a quantity,
        it should have angular units. If specified as a numerical value, it is set equal to that number
        of pixels. If specified and greater than or equal to the pixel size, it is used to calculate
        parameter uncertainties using the correlated noise equations (see below). If it is specified but
        less than a pixel width, the the uncorrelated noise equations (see below) are used to
        compute the parameter uncertainties. If it is not specified and the image has a restoring beam(s),
        the the correlated noise equations are used to compute parameter uncertainties using the
        geometric mean of the relevant beam major and minor axes as the noise-correlation beam FWHM. If
        noisefwhm is not specified and the image does not have a restoring beam, then the uncorrelated
        noise equations are used to compute the parameter uncertainties.
        
        SUPPORTED UNITS
        
        Currently only images with brightness units conformant with Jy/beam, Jy.km/s/beam, and K are fully
        supported for fitting. If your image has some other base brightness unit, that unit will be assumed
        to be equivalent to Jy/pixel and results will be calculated accordingly. In particular,
        the flux density (reported as Integrated Flux in the logger and associated with the "flux" key
        in the returned component subdictionary(ies)) for such a case represents the sum of pixel values.
        
        Note also that converting the returned results subdictionary to a component list via cl.fromrecord() currently
        only works properly if the flux density units in the results dictionary are conformant with Jy.
        If you need to be able to run cl.fromrecord() on the resulting dictionary you can first modify the
        flux density units by hand to be (some prefix)Jy and then run cl.fromrecord() on that dictionary,
        bearing in mind your unit conversion.
        
        If the input image has units of K, the flux density of components will be reported in units
        of [prefix]K*rad*rad, where prefix is an SI prefix used so that the numerical value is between
        1 and 1000. To convert to units of K*beam, determine the area of the appropriate beam,
        which is given by pi/(4*ln(2))*bmaj*bmin, where bmaj and bmin are the major and minor axes
        of the beam, and convert to steradians (=rad*rad). This value is included in the beam portion
        of the component subdictionary (key 'beamster'). Then divide the numerical value of the
        logged flux density by the beam area in steradians. So, for example
        
        begin{verbatim}
        # run on an image with K brightness units
        res = imfit(...)
        # get the I flux density in K*beam of component 0
        comp = res['results']['component0']
        flux_density_kbeam = comp['flux']['value'][0]/comp['beam']['beamster']
        end{verbatim}
        
        FITTING OVER MULTIPLE CHANNELS
        
        For fitting over multiple channels, the result of the previous successful fit is used as
        the estimate for the next channel. The number of gaussians fit cannot be varied on a channel
        by channel basis. Thus the variation of source structure should be reasonably smooth in
        frequency to produce reliable fit results.
        
        MASK SPECIFICATION
        
        Mask specification can be done using an LEL expression. For example
        
        mask = '"myimage">5' will use only pixels with values greater than 5.
        
        INCLUDING AND EXCLUDING PIXELS
        
        Pixels can be included or excluded from the fit based on their values
        using these parameters. Note that specifying both is not permitted and
        will cause an error. If specified, both take an array of two numeric
        values.
        
        ESTIMATES
        
        Initial estimates of fit parameters may be specified via an estimates
        text file. Each line of this file should contain a set of parameters for
        a single gaussian. Optionally, some of these parameters can be fixed during
        the fit. The format of each line is
        
        peak intensity, peak x-pixel value, peak y-pixel value, major axis, minor axis, position angle, fixed
        
        The fixed parameter is optional. The peak intensity is assumed to be in the
        same units as the image pixel values (eg Jy/beam). The peak coordinates are specified
        in pixel coordinates. The major and minor axes and the position angle are the convolved
        parameters if the image has been convolved with a clean beam and are specified as quantities.
        The fixed parameter is optional and is a string. It may contain any combination of the
        following characters 'f' (peak intensity), 'x' (peak x position), 'y' (peak y position),
        'a' (major axis), 'b' (axial ratio, R = (major axis FWHM)/(minor axis FWHM)),
        'p' (position angle). NOTE: One cannot hold the minor axis fixed without holding the major
        axis fixed. If the major axis is not fixed, specifying "b" in the fixed string will hold
        the axial ratio fixed during the fit.
        
        In addition, lines in the file starting with a # are considered comments.
        
        An example of such a file is:
        
        begin{verbatim}
        # peak intensity must be in map units
        120, 150, 110, 23.5arcsec, 18.9arcsec, 120deg
        90, 60, 200, 46arcsec, 23arcsec, 140deg, fxp
        end{verbatim}
        
        This is a file which specifies that two gaussians are to be simultaneously fit,
        and for the second gaussian the specified peak intensity, x position, and position angle
        are to be held fixed during the fit.
        
        ERROR ESTIMATES
        
        Error estimates are based on the work of Condon 1997, PASP, 109, 166. Key assumptions made are:
        * The given model (elliptical Gaussian, or elliptical Gaussian plus constant offset) is an
        adequate representation of the data
        * An accurate estimate of the pixel noise is provided or can be derived (see above). For the
        case of correlated noise (e.g., a CLEAN map), the fit region should contain many "beams" or
        an independent value of rms should be provided.
        * The signal-to-noise ratio (SNR) or the Gaussian component is large. This is necessary because
        a Taylor series is used to linearize the problem. Condon (1997) states that the fractional
        bias in the fitted amplitude due to this assumption is of order 1/(S*S), where S is the overall
        SNR of the Gaussian with respect to the given data set (defined more precisely below). For a 5
        sigma "detection" of the Gaussian, this is a 4% effect.
        * All (or practically all) of the flux in the component being fit falls within the selected region.
        If a constant offset term is simultaneously fit and not fixed, the region of interest should be
        even larger. The derivations of the expressions summarized in this note assume an effectively
        infinite region.
        
        Two sets of equations are used to calculate the parameter uncertainties, based on if
        the noise is correlated or uncorrelated. The rules governing which set of equations are
        used have been described above in the description of the noisefwhm parameter.
        
        In the case of uncorrelated noise, the equations used are
        
        f(A) = f(I) = f(M) = f(m) = k*s(x)/M = k*s(y)/m = (s(p)/sqrt(2))*((M*M - m*m)/(M*m))
        = sqrt(2)/S
        
        where s(z) is the uncertainty associated with parameter z, f(z) = s(z)/abs(z) is the
        fractional uncertainty associated with parameter z, A is the peak intensity, I is the flux
        density, M  and m are the FWHM major and minor axes, p is the position angle of the
        component, and k = sqrt(8*ln(2)). s(x) and s(y) are the direction
        uncertainties of the component measured along the major and minor axes; the resulting
        uncertainties measured along the principle axes of the image direction coordinate are
        calculated by propagation of errors using the 2D rotation matrix which enacts the rotation through
        the position angle plus 90 degrees. S is the overall signal to noise ratio of the component,
        which, for the uncorrelated noise case is given by
        
        S = (A/(k*h*r))*sqrt(pi*M*m)
        
        where h is the pixel width of the direction coordinate and r is the rms noise (see the
        discussion above for the rules governing how the value of r is determined).
        
        For the correlated noise case, the same equations are used to determine the uncertainties
        as in the uncorrelated noise case, except for the uncertainty in I (see below). However,
        S is given by
        
        S = (A/(2*r*N)) * sqrt(M*m) * (1 + ((N*N/(M*M)))**(a/2)) * (1 + ((N*N/(m*m)))**(b/2))
        
        where N is the noise-correlation beam FWHM (see discussion of the noisefwhm parameter for
        rules governing how this value is determined). "**" indicates exponentiation and a and b
        depend on which uncertainty is being calculated. For sigma(A), a = b = 3/2. For M and x,
        a = 5/2 and b = 1/2. For m, y, and p, a = 1/2 and b = 5/2. f(I) is calculated in the
        correlated noise case according to
        
        f(I) = sqrt( f(A)*f(A) + (N*N/(M*m))*(f(M*f(M) + f(m)*f(m))) )
        
        Note well the following caveats:
        * Fixing Gaussian component parameters will tend to cause the parameter uncertainties reported for free
        parameters to be overestimated.
        * Fitting a zero level offset that is not fixed will tend to cause the reported parameter
        uncertainties to be slightly underestimated.
        * The parameter uncertainties will be inaccurate at low SNR (a ~10% for SNR = 3).
        * If the fitted region is not considerably larger than the largest component that is fit,
        parameter uncertainties may be mis-estimated.
        * An accurate rms noise measurement, r, for the region in question must be supplied.
        Alternatively, a sufficiently large signal-free region must be present in the selected region
        (at least about 25 noise beams in area) to auto-derive such an estimate.
        * If the image noise is not statistically independent from pixel to pixel, a reasonably accurate noise
        correlation scale, N, must be provided. If the noise correlation function is not approximately Gaussian,
        the correlation length can be estimated using
        
        N = sqrt(2*ln(2)/pi)* double-integral(dx dy C(x,y))/sqrt(double-integral(dx dy C(x, y) * C(x,y)))
        
        where C(x,y) is the associated noise-smoothing function
        * If fitted model components have significan spatial overlap, the parameter uncertainties are likely to
        be mis-estimated (i.e., correlations between the parameters of separate components are not accounted
        for).
        * If the image being analyzed is an interferometric image with poor uv sampling, the parameter
        uncertainties may be significantly underestimated.
        
        The deconvolved size and position angle errors are computed by taking the maximum of the absolute values of the
        differences of the best fit deconvolved value of the given parameter and the deconvolved size of the eight
        possible combinations of (FWHM major axis +/- major axis error), (FWHM minor axis +/- minor axis error),
        and (position andle +/- position angle error). If the source cannot be deconvolved from the beam (if the best
        fit convolved source size cannot be deconvolved from the beam), upper limits on the deconvolved source size
        are sometimes reported. These limits simply come from the maximum major and minor axes of the deconvolved
        gaussians taken from trying all eight of the aforementioned combinations. In the case none of these combinations
        produces a deconvolved size, no upper limit is reported.
        
        EXAMPLE:
        
        Here is how one might fit two gaussians to multiple channels of a cube using the fit
        from the previous channel as the initial estimate for the next. It also illustrates
        how one can specify a region in the associated continuum image as the region to use
        as the fit for the channel.
        
        begin{verbatim}
        imagename = "co_cube.im"
        # specify region using region from continuum
        region = "continuum.im:source.rgn"
        chans = "2~20"
        # only use pixels with positive values in the fit
        excludepix = [-1e10,0]
        # estimates file contains initial parameters for two Gaussians in channel 2
        estimates = "initial_estimates.txt"
        logfile = "co_fit.log"
        # append results to the log file for all the channels
        append = "True"
        ia.open(imagename)
        ia.fitcomponents(region=region, chans=chans, excludepix=excludepix, estimates=estimates, logfile=logfile, append=append)
        end{verbatim}
        """
        schema = {'box': {'type': 'cStr'}, 'region': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'chans': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'stokes': {'type': 'cStr'}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'includepix': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'excludepix': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'residual': {'type': 'cStr'}, 'model': {'type': 'cStr'}, 'estimates': {'type': 'cStr'}, 'logfile': {'type': 'cStr'}, 'append': {'type': 'cBool'}, 'newestimates': {'type': 'cStr'}, 'complist': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'dooff': {'type': 'cBool'}, 'offset': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'fixoffset': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}, 'rms': {'anyof': [{'type': 'cInt'}, {'type': 'cFloat', 'coerce': _coerce.to_float}, {'type': 'cDict'}, {'type': 'cStr'}]}, 'noisefwhm': {'anyof': [{'type': 'cInt'}, {'type': 'cFloat', 'coerce': _coerce.to_float}, {'type': 'cDict'}, {'type': 'cStr'}]}, 'summary': {'type': 'cStr'}}
        doc = {'box': box, 'region': region, 'chans': chans, 'stokes': stokes, 'mask': mask, 'includepix': includepix, 'excludepix': excludepix, 'residual': residual, 'model': model, 'estimates': estimates, 'logfile': logfile, 'append': append, 'newestimates': newestimates, 'complist': complist, 'overwrite': overwrite, 'dooff': dooff, 'offset': offset, 'fixoffset': fixoffset, 'stretch': stretch, 'rms': rms, 'noisefwhm': noisefwhm, 'summary': summary}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fitcomponents_result = _dict_dc(self._swigobj.fitcomponents(_str_ec(_pc.document['box']), _any_ec(_pc.document['region']), _any_ec(_pc.document['chans']), _str_ec(_pc.document['stokes']), _any_ec(_pc.document['mask']), _pc.document['includepix'], _pc.document['excludepix'], _str_ec(_pc.document['residual']), _str_ec(_pc.document['model']), _str_ec(_pc.document['estimates']), _str_ec(_pc.document['logfile']), _pc.document['append'], _str_ec(_pc.document['newestimates']), _str_ec(_pc.document['complist']), _pc.document['overwrite'], _pc.document['dooff'], _pc.document['offset'], _pc.document['fixoffset'], _pc.document['stretch'], _any_ec(_pc.document['rms']), _any_ec(_pc.document['noisefwhm']), _str_ec(_pc.document['summary'])))
        return _fitcomponents_result

    def fromrecord(self, record, outfile=''):
        """You can convert an associated image to a record
        (torecord) or  imagepol tool functions  will sometimes give you a record.  This function
        (fromrecord) allows you to set the contents of an image tool to the content of the record.
        This and torecord are used for deserialization and serialization.
        """
        schema = {'record': {'type': 'cDict'}, 'outfile': {'type': 'cStr'}}
        doc = {'record': record, 'outfile': outfile}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromrecord_result = self._swigobj.fromrecord(_dict_ec(_pc.document['record']), _str_ec(_pc.document['outfile']))
        return _fromrecord_result

    def getchunk(self, blc=[ int(-1) ], trc=[ int(-1) ], inc=[ int(1) ], axes=[ int(-1) ], list=False, dropdeg=False, getmask=False):
        """This function returns the pixels (or optionally the pixel mask) from the
        imagefile between {stfaf blc} and {stfaf trc} inclusively. Both float
        and complex valued images are supported. An increment may be specified
        with {stfaf inc}. Note that if you retrieve too many pixels, you might
        cause swapping since the pixels are kept in memory.
        
        Any illegal {stfaf blc} values are set to zero.  Any illegal {stfaf
        trc} values are set to the end of the image.  If any {stfaf trc $<$
        blc}, you get the whole image for that axis.  Any illegal {stfaf inc}
        values are set to unity.
        
        The argument {stfaf axes} can be used to reduce the dimensionality of
        the output array. It specifies which pixel axes of the image to
        {bf average} the data over.  For example, consider a 3-D image.
        With {stfaf axes=[0,1]} and all other arguments left at their defaults,
        the result would be a 1-D vector, a profile along the third axis,
        with the data averaged over the first two axes.
        
        A related function is getregion which
        retrieves the pixels or pixelmask from a potentially more complex
        region.  Function {stff getchunk} is retained because it is faster
        and therefore preferable for repeated operation in loops if the
        pixelmask is not required and the region is a simple box.
        
        If you set getmask=True, the return value is the 'pixelmask' rather than
        the 'pixel' image.
        """
        schema = {'blc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'trc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'inc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'list': {'type': 'cBool'}, 'dropdeg': {'type': 'cBool'}, 'getmask': {'type': 'cBool'}}
        doc = {'blc': blc, 'trc': trc, 'inc': inc, 'axes': axes, 'list': list, 'dropdeg': dropdeg, 'getmask': getmask}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getchunk_result = _any_dc(self._swigobj.getchunk(_pc.document['blc'], _pc.document['trc'], _pc.document['inc'], _pc.document['axes'], _pc.document['list'], _pc.document['dropdeg'], _pc.document['getmask']))
        return _getchunk_result

    def getregion(self, region={ }, axes=[ int(-1) ], mask='', list=False, dropdeg=False, getmask=False, stretch=False):
        """This function recovers the image pixel or pixelmask values in the
        given region-of-interest.
        Regardless of the shape of the {stfaf region} you have specified, the
        shape of the {stfaf pixels} and {stfaf pixelmask} arrays must
        necessarily be the bounding box of the specified region.  If the region
        extends beyond the image, it is truncated.
        
        Recall that the recovered pixelmask will reflect both the pixelmask
        stored in the image, and the region (their masks are `anded') -- see
        the htmlref{discussion}{IMAGE:MASKSANDREGIONS} in the introduction
        about this.
        
        The argument {stfaf axes} can be used to reduce the dimensionality of
        the output array. It specifies which pixel axes of the image to
        average the data over.  For example, consider a 3-D image.  With
        {stfaf axes=[0,1]} and all other arguments left at their defaults,
        the result would be a 1-D vector, a profile along the third axis, with
        the data averaged over the first two axes.
        
        This function differs in three ways from {stff getchunk}.  First, the
        region can be much more complex (e.g.  a union of polygons) than the
        simple {stfaf blc}, {stfaf trc}, and {stfaf inc} of {stff
        getchunk} (although such a region can be created of course).  Second,
        it can be used to recover the pixelmask or the pixels.  Third, it is
        less efficient than {stff getchunk} for doing the same thing as
        {stff getchunk}.  So if you are interested in say, iterating through
        an image, getting a regular hyper-cube of pixels and doing something
        with them, then {stff getchunk} will be faster.  This would be
        especially noticeable if you iterated line by line through a large
        image.
        """
        schema = {'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'list': {'type': 'cBool'}, 'dropdeg': {'type': 'cBool'}, 'getmask': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'region': region, 'axes': axes, 'mask': mask, 'list': list, 'dropdeg': dropdeg, 'getmask': getmask, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getregion_result = _any_dc(self._swigobj.getregion(_any_ec(_pc.document['region']), _pc.document['axes'], _any_ec(_pc.document['mask']), _pc.document['list'], _pc.document['dropdeg'], _pc.document['getmask'], _pc.document['stretch']))
        return _getregion_result

    def getprofile(self, axis=int(-1), function='mean', region={ }, mask='', unit='', stretch=False, spectype='default', restfreq='', frame='', logfile=''):
        """This application returns information on a one-dimensional profile taken along a specified image axis.
        The region of interest is collapsed (a'la ia.collapse() along all axes orthogonal to the one specified, and)
        the specified aggregate function is applied to these pixels to generate the returned values.
        
        The aggregate function must be one of the functions supported by ia.collapse; ie, 'flux', 'madm', 'max', 'mean',
        'median', 'min', 'rms', 'stdev', 'sum', 'variance', and 'xmadm'. See the help for ia.collapse() for details regarding
        these functions. Minimum match and case insenstivity is supported. In addition, single binary (addition,
        subtraction, multiplication, and division) operations of these functions are supported, eg function='max*min'
        will return data that is the product of the maximum and the mininum for each plane along the specified
        axis.
        
        One may specify the unit of the returned coordinate values.  Unless axis is the spectral axis, unit must be
        conformant with the corresponding axis unit in the image coordinate system or it must be 'pixel' which signifies,
        pixel, rather than world, coordinate values should be calculated. If axis is the spectral axis, unit may be a
        velocity unit (assuming the coordinate system has a rest frequency or restfreq is specified) or a length unit.
        In these cases, the returned coordinate values will be converted to velocity or wavelength, respectively.
        
        The parameter spectype may be used to specify the velocity or wavelength type for the returned coordinate values
        if profile is taken along spectral axis. Supported (minimum match, case insensitive) values) are "relativistic
        velocity", "beta", "radio velocity", "optical velocity", "wavelength", "air wavelength", "default". The "default"
        value is equivalent to "relativistic" if unit is a velocity unit or "wavelength" if unit is a length unit.
        
        The restfreq parameter allows one to set the rest frequency for the coordinates to be returned if axis is the
        spectral axis and unit is a velocity unit. If blank, the rest frequency associated with the image coordinate
        system is used.
        
        The frame allows one to specify which kinematic reference frame that the returned coordinate values should be
        calculated in. It is only used if axis is the spectral axis and unit is unspecified or is specified and a
        frequency unit. If blank, the reference frame associated with the image coordinate system is used.
        
        The returned dictionary
        contains the keys:
        
        values:  one-dimensional array along the specified axis containing values resulting from applying the specified
        aggregate function to corresponding pixels at the same location along that axis.
        mask:    one-dimensional array of booleans of the resulting mask after applying the aggregate function, formed in the
        same way as that formed by ia.collapse.
        coords   One-dimensional array of corresponding coordinate values along the specified axis in the specified unit
        (or the unit associated with the axis in the image coordinate system if unspecified).
        xUnit    The unit used for calculating the values the coords array.
        """
        schema = {'axis': {'type': 'cInt'}, 'function': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cStr'}, 'unit': {'type': 'cStr'}, 'stretch': {'type': 'cBool'}, 'spectype': {'type': 'cStr'}, 'restfreq': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'frame': {'type': 'cStr'}, 'logfile': {'type': 'cStr'}}
        doc = {'axis': axis, 'function': function, 'region': region, 'mask': mask, 'unit': unit, 'stretch': stretch, 'spectype': spectype, 'restfreq': restfreq, 'frame': frame, 'logfile': logfile}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getprofile_result = _dict_dc(self._swigobj.getprofile(_pc.document['axis'], _str_ec(_pc.document['function']), _any_ec(_pc.document['region']), _str_ec(_pc.document['mask']), _str_ec(_pc.document['unit']), _pc.document['stretch'], _str_ec(_pc.document['spectype']), _any_ec(_pc.document['restfreq']), _str_ec(_pc.document['frame']), _str_ec(_pc.document['logfile'])))
        return _getprofile_result

    def getslice(self, x, y, axes=[ int(0),int(1) ], coord=[ int(-1) ], npts=int(0), method='linear'):
        """This function returns a 1-D slice (the pixels and opionally the pixel mask) from the
        imagefile.   The slice is constrained to lie in a plane of two  cardinal axes
        (e.g. XY or YZ).  At some point this constraint will be relaxed.
        A range of interpolation schemes are available.
        
        You specify the slice as a polyline giving the x ({stfaf x}) and y
        ({stfaf y}) coordinates and the axes of the plane holding that slice
        ({stfaf axes}).  As well, you must specify the absolute pixel
        coordinates of the other axes ({stfaf coord}).  This defaults to the
        first pixel (e.g. first plane).
        
        The return value is a record with fields 'pixels' (interpolated intensity),
        'mask' (interpolated mask), 'xpos' (x-location in absolute pixel coordinates),
        'ypos' (y-location in absolute pixel coordinates), 'distance' (distance along
        slice in pixels), 'axes' (the x and y axes of slice).
        """
        schema = {'x': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'y': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'coord': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'npts': {'type': 'cInt'}, 'method': {'type': 'cStr'}}
        doc = {'x': x, 'y': y, 'axes': axes, 'coord': coord, 'npts': npts, 'method': method}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getslice_result = _dict_dc(self._swigobj.getslice(_pc.document['x'], _pc.document['y'], _pc.document['axes'], _pc.document['coord'], _pc.document['npts'], _str_ec(_pc.document['method'])))
        return _getslice_result

    def hanning(self, outfile='', region={ }, mask='', axis=int(-10), drop=True, overwrite=False, async=False, stretch=False, dmethod='copy'):
        """This application performs Hanning convolution of one axis of an image defined by
        
        z[i] = 0.25*y[i-1] + 0.5*y[i] + 0.25*y[i+1]       (equation 1)
        
        where z[i] is the value at pixel i in the hanning smoothed image, and
        y[i-1], y[i], and y[i+1] are the values of the input image at pixels i-1,
        i, and i+1 respectively. It supports both float and complex valued images.
        The length of the axis along which the convolution is to occur must be at least
        three pixels in the selected region. Masked pixel values are set to zero prior to
        convolution. All nondefault pixel masks are ignored during the calculation.
        
        The convolution is done in the image domain (i.e., not with an FFT).
        
        If drop=False, the length of the output axis will be the same as that of the input
        axis. The output pixel values along the convolution axis will be related to those
        of the input values according to equation 1, except the first and last pixels. In that
        case,
        
        z[0] = 0.5*(y[0] + y[1])
        
        and,
        
        z[N-1] = 0.5*(y[N-2] + y[N-1])
        
        where N is the number of pixels along the convolution aixs.
        The pixel mask, ORed with the OTF mask if specified, is copied from the selected
        region of the input image to the output image. Thus for example, if the selected
        region in the input image has six planes along the convolution axis, and if the pixel
        values, which are all unmasked, on a slice along this axis are [1, 2, 5, 10, 17, 26],
        the corresponding output pixel values will be [1.5, 2.5, 5.5, 10.5, 17.5, 21.5].
        
        If drop=True and dmethod="copy", the output image is the image calculated if
        drop=True, except that only the odd-numbered planes are kept. Furthermore, if the
        number of planes along the convolution axis in the selected region of the input image
        is even, the last odd number plane is also discarded. Thus, if the selected region
        has N pixels along the convolution axis in the input image, along the convolution
        axis the output image will have (N-1)/2 planes if N is odd, or (N-2)/2 planes if N
        is even. In this case, the pixel and mask values are copied directly, without further
        processing. Thus for example, if the selected region in the input image has six planes
        along the convolution axis, and if the pixel values, which are all unmasked, on a slice
        along this axis are [1, 2, 5, 10, 17, 26], the corresponding output pixel values will be
        [2.5, 10.5].
        
        If drop=True and dmethod="mean", first the image described in the drop=False case
        is calculated. The first plane and last plane(s) of that image are then discarded as
        described in the drop=True, dmethod="copy" case. Then, the ith plane of the output
        image is calculated by averaging the (2*i)th and (2*i + 1)th planes of the intermediate
        image.Thus for example, if the selected region in the input image has six planes
        along the convolution axis, and if the pixel values, which are all unmasked, on a slice
        along this axis are [1, 2, 5, 10, 17, 26], the corresponding output pixel values will be
        [4.0, 14.0]. Masked values are taken into consideration when forming this average, so if
        one of the values is masked, it is not used in the average. If at least one of the values
        in the input pair is not masked, the corresponding output pixel will not be masked.
        
        The hanning smoothed image is written to disk with name {stfaf outfile}, if
        specified. If not, no image is written but the image is still accessible via
        the returned image analysis tool (see below).
        
        This method always returns an image analysis tool which is attached to the
        hanning smoothed image. This tool should always be captured and closed after
        any desired manipulations have been done. Closing the tool frees up system
        resources (eg memory), eg,
        
        hanning_image = ia.hanning(...)
        begin{verbatim}
        # do things (or not) with hanning_image
        ...
        # close the returned tool promptly upon finishing with it.
        end{verbatim}
        hanning_image.done()
        
        See also the other convolution functions
        convolve2d,
        sepconvolve and
        convolve.
        """
        schema = {'outfile': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'axis': {'type': 'cInt'}, 'drop': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'async': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}, 'dmethod': {'type': 'cStr'}}
        doc = {'outfile': outfile, 'region': region, 'mask': mask, 'axis': axis, 'drop': drop, 'overwrite': overwrite, 'async': async, 'stretch': stretch, 'dmethod': dmethod}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _hanning_result = _wrap_image(swig_object=self._swigobj.hanning(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['axis'], _pc.document['drop'], _pc.document['overwrite'], _pc.document['async'], _pc.document['stretch'], _str_ec(_pc.document['dmethod'])))
        return _hanning_result

    def haslock(self):
        """This function can be used to find out whether the image has a read or a
        write lock set.  It is not of general user interest.   It returns
        a vector of Booleans of length 2.  Position 1 says whether
        a read lock is set, position 2 says whether a write lock is set.
        
        In general locking is handled automatically, with a built in lock
        release cycle.  However, this function can be useful in scripts when a
        file is being shared between more than one process.  See also functions
        unlock and
        lock.
        """
        _haslock_result = self._swigobj.haslock()
        return _haslock_result

    def histograms(self, axes=[ int(-1) ], region={ }, mask='', nbins=int(25), includepix=[ float(-1) ], cumu=False, log=False, stretch=False):
        """This method computes histograms of the pixel values in the image.
        The values are returned in a dictionary.
        
        The chunk of the image over which you compute the histograms is
        specified by a vector of axis numbers (argument {stfaf axes}).  For
        example, consider a 3-dimensional image for which you specify {stfaf
        axes=[0,2]}.  The histograms would be computed for each XZ (axes 0 and
        2) plane in the image.  You could then examine those histograms as a
        function of the Y (axis 1) axis.  Or perhaps you set {stfaf axes=[2]},
        whereupon you could examine the histogram for each Z (axis 2) profile as
        a function of X and Y location in the image.
        
        You have control over the number of bins for each histogram ({stfaf
        nbins}).  The bin width is worked out automatically for each histogram
        and may vary from histogram to histogram (the range of pixel values is
        worked out for each chunk being histogrammed).
        
        You have control over which pixels are included in the histograms via
        the {stfaf includepix} argument.  This vector specifies a range of
        pixel values to be included in the histograms.  If you only give one
        value for this, say {stfaf includepix=[b]}, then this is interpreted as
        {stfaf includepix=[-abs(b),abs(b)]}.  If you specify an inclusion
        range, then the range of pixel intensities over which the histograms are
        binned is given by this range too.  This is a way to make the bin width
        the same for each histogram.
        
        You can control if the histogram is cumulative or non-cumulative via the
        cumu parameter.
        
        You have countrol over how the bin counts are returned. If log = false,
        the actual counts are returned. If true, the values returned are the log10
        values of the actual counts.
        
        The results are returned as a dictionary. The counts (field "counts") and
        the abscissa values (field "values") for all bins in each histogram are returned.
        The shape of the first dimension of those arrays contained in those fields is {stfaf nbins}.
        The number and shape of the remaining dimensions are those of the display axes(the
        axes in the image for which you did not compute the histograms).  For example, if one
        has a three dimensional image and sets {stfaf axes=[2]}, the display axes are 0 and 1,
        so the shape of each counts and values array is then [nbins,nx,ny], where nx and ny
        are the length of the zeroth and first axes, respectively.
        
        In addition, the mean (field "mean") and standard deviation (field "sigma") computed
        using the data in each histogram is returned. The shape of these arrays is equal to
        the shape of the display axes. So,
        """
        schema = {'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'nbins': {'type': 'cInt'}, 'includepix': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'cumu': {'type': 'cBool'}, 'log': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'axes': axes, 'region': region, 'mask': mask, 'nbins': nbins, 'includepix': includepix, 'cumu': cumu, 'log': log, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _histograms_result = _dict_dc(self._swigobj.histograms(_pc.document['axes'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['nbins'], _pc.document['includepix'], _pc.document['cumu'], _pc.document['log'], _pc.document['stretch']))
        return _histograms_result

    def history(self, list=True):
        """This function allows you to access the history file.
        
        
        
        If {stfaf browse=F} and {stfaf list=F}, the history is returned by
        the function as a vector of strings.  If {stfaf list=T}, the history
        is sent to the logger.
        
        casa tools that modify the MeasurementSet or an image file will save
        history information.  Also, you can directly annotate the history file
        with the function sethistory.  History
        from fits file conversions is also stored and listable here.
        """
        schema = {'list': {'type': 'cBool'}}
        doc = {'list': list}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _history_result = [_str_dc(_x) for _x in self._swigobj.history(_pc.document['list'])]
        return _history_result

    def insert(self, infile='', region={ }, locate=[ float(-1) ], verbose=False):
        """This function inserts the specified image (or part of it) into the image
        referenced by this tool.
        The specified image may be given via argument {stfaf infile}
        as a disk file name (it may be in native casa, fits, or Miriad
        format; Look htmlref{here}{IMAGES:FOREIGNIMAGES}  for more
        information on foreign images).
        
        If the {stfaf locate} vector is not given, then the images are
        aligned (to an integer pixel shift) by their reference pixels.
        
        If {stfaf locate} vector is given, then those values that are given,
        give the absolute pixel in the output (this) image of the bottom left
        corner of the input (sub)image.  For those values that are not given,
        the input image is symmetrically placed in the output image.
        
        The image referenced by this tool is modified in place; no new image
        is created. The method returns True if successful.
        """
        schema = {'infile': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'locate': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'verbose': {'type': 'cBool'}}
        doc = {'infile': infile, 'region': region, 'locate': locate, 'verbose': verbose}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _insert_result = self._swigobj.insert(_str_ec(_pc.document['infile']), _any_ec(_pc.document['region']), _pc.document['locate'], _pc.document['verbose'])
        return _insert_result

    def isopen(self):
        """This function can be used to find out whether the Image tool
        is associated with an image or not.
        """
        _isopen_result = self._swigobj.isopen()
        return _isopen_result

    def ispersistent(self):
        """This function can be used to find out whether the image is persistent on
        disk or not.  There is a subtle difference from the image being
        virtual.  For example, a virtual image which references another
        which is on disk is termed persistent.
        """
        _ispersistent_result = self._swigobj.ispersistent()
        return _ispersistent_result

    def lock(self, writelock=False, nattempts=int(0)):
        """This function can be used to acquire a Read or a Read/Write lock
        on the imagefile.   It is not of general user interest.
        
        In general locking is handled automatically, with a built in lock
        release cycle.  However, this function can be useful in scripts when a
        file is being shared between more than one process.  See also functions
        unlock and haslock.
        """
        schema = {'writelock': {'type': 'cBool'}, 'nattempts': {'type': 'cInt'}}
        doc = {'writelock': writelock, 'nattempts': nattempts}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _lock_result = self._swigobj.lock(_pc.document['writelock'], _pc.document['nattempts'])
        return _lock_result

    def makecomplex(self, outfile, imag, region={ }, overwrite=False):
        """This function combines the current image with another image to make
        a complex image.  The current image (i.e. that associated with this
        Image tool is assumed to be the Real image).  You supply
        the Imaginary image; it must be disk-based at this time.
        """
        schema = {'outfile': {'type': 'cStr'}, 'imag': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'overwrite': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'imag': imag, 'region': region, 'overwrite': overwrite}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _makecomplex_result = self._swigobj.makecomplex(_str_ec(_pc.document['outfile']), _str_ec(_pc.document['imag']), _any_ec(_pc.document['region']), _pc.document['overwrite'])
        return _makecomplex_result

    def maskhandler(self, op='default', name=[  ]):
        """This function  is used to manage
        or handle pixelmasks .  A casa image may contain zero, one or more
        pixelmasks.  Any of these masks can be designated the default
        pixelmask.  The default mask is acted upon by casa applications.
        For example, if you ask for statistics from an image, pixels which are
        masked as bad (F) will be excluded from the calculations.
        
        This function has an argument ({stfaf op}) that specifies the
        behaviour.  In all cases, you can shorten the operation string to three
        characters.  It is not the job of this function to modify the values of
        masks.
        
        begin{itemize}
        
        item{default - } this retrieves  the name of the default pixelmask
        as the return value of the function call.
        
        item{get - } this retrieves the name(s) of the existing pixelmasks
        as the return value of the function call (string or vector of strings).
        
        item{set - } this lets you change the default pixelmask to that given by the
        {stfaf name} argument.  If {stfaf name} is empty, then the default
        mask is unset (i.e. an all good mask is effectively applied).
        
        item{delete - } this lets you delete the pixelmasks specified by the
        {stfaf name} argument.  To delete more than one mask, {stfaf name} can
        be a vector of strings.    Any supplied pixelmask name that does not
        exist is silently ignored.
        
        item{rename - } this lets you rename the mask specified by {stfaf name[0]}
        to {stfaf name[1]}.  Thus the {stfaf name} argument must be a vector of
        length 2.
        
        item{copy - } this lets you copy a mask to another in the same image, or
        copy a mask from another image into this image.  Thus the {stfaf name}
        argument must be a vector of length 2.
        
        For the first case, the first element of {stfaf name} must be the name
        of the mask to copy, and the second element must be the name of the
        pixelmask to which it will be copied.
        
        For the second case, the first element of {stfaf name} must be the name
        of the input image and pixelmask with a colon delimiter (e.g. {cf
        hcn:mask2}). The second element must be the name of the pixelmask to
        which the input pixelmask will be copied.
        
        end{itemize}
        
        Use the summary function to see the
        available pixelmasks.  You can do this either via the logger display, or via
        the returned record, which contains the mask names. In the logger display,
        any pixelmask which is not the default mask is listed in square brackets.  If
        a default mask is set, it is listed first, and is not enclosed in square
        brackets.
        """
        schema = {'op': {'type': 'cStr'}, 'name': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}}
        doc = {'op': op, 'name': name}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _maskhandler_result = [_str_dc(_x) for _x in self._swigobj.maskhandler(_str_ec(_pc.document['op']), [_str_ec(_x) for _x in _pc.document['name']])]
        return _maskhandler_result

    def miscinfo(self):
        """A casa imagefile can accumulate miscellaneous information
        during its lifetime.  This information is stored in a record called the {stff
        miscinfo} record.  For example, the fits filler puts header keywords
        it doesn't otherwise use into the {stff miscinfo} record.  This {stff
        miscinfo} record is not guaranteed to have any entries, so it's up to
        you to check for any fields that you require.
        
        You can also put things into this record (see
        setmiscinfo) yourself, to keep
        information that the system might not otherwise store for you.
        
        When the image is written out to fits, the items in the
        {stff miscinfo} record are written to the fits file
        as keywords with the corresponding record field name.
        """
        _miscinfo_result = _dict_dc(self._swigobj.miscinfo())
        return _miscinfo_result

    def modify(self, model, region={ }, mask='', subtract=True, list=True, stretch=False):
        """This function applies a model of the sky to the image. You can add or
        subtract the model which is contained in a
        Componentlist tool.
        
        The pixel values are only changed where the total mask
        (combination of the default pixelmask [if any] and the OTF mask)
        is good (True).   If the computation fails for a particular
        pixel (e.g. coordinate undefined) that pixel will be
        masked bad.
        """
        schema = {'model': {'type': 'cDict'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'subtract': {'type': 'cBool'}, 'list': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'model': model, 'region': region, 'mask': mask, 'subtract': subtract, 'list': list, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _modify_result = self._swigobj.modify(_dict_ec(_pc.document['model']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['subtract'], _pc.document['list'], _pc.document['stretch'])
        return _modify_result

    def maxfit(self, region={ }, point=True, width=int(5), negfind=False, list=True):
        """This function finds the pixel with the maximum value in the region, and
        then uses function findsources
        to generate a Componentlist with one component.   The component
        will be of type Point ({stfaf point=T}) or Gaussian ({stfaf point=F}).
        
        If {stfaf negfind=F} the maximum pixel value is found in the region and fit.
        If {stfaf negfind=T} the absolute maximum pixel value is found in the region
        and fit.
        
        See function findsources for
        a description of arguments {stfaf point} and {stfaf width}.
        
        See also the function fitcomponents.
        """
        schema = {'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'point': {'type': 'cBool'}, 'width': {'type': 'cInt'}, 'negfind': {'type': 'cBool'}, 'list': {'type': 'cBool'}}
        doc = {'region': region, 'point': point, 'width': width, 'negfind': negfind, 'list': list}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _maxfit_result = _dict_dc(self._swigobj.maxfit(_any_ec(_pc.document['region']), _pc.document['point'], _pc.document['width'], _pc.document['negfind'], _pc.document['list']))
        return _maxfit_result

    def moments(self, moments=[ int(0) ], axis=int(-10), region={ }, mask='', method=[  ], smoothaxes=[ int(-1) ], smoothtypes=[ ], smoothwidths=[ float(0.0) ], includepix=[ float(-1) ], excludepix=[ float(-1) ], peaksnr=float(3.0), stddev=float(0.0), doppler='RADIO', outfile='', smoothout='', overwrite=False, drop=True, stretch=False, async=False):
        """noindent{bf Summary}
        
        The primary goal of this function is to enable you to analyze a
        multi-dimensional image by generating moments of a specified axis.
        This is a time-honoured spectral-line analysis technique used for
        extracting information about spectral lines.
        
        You can generate one or more output moment images.  The return value
        of this function is an on-the-fly Image tool holding the {bf first}
        of the output moment images.
        
        The word `moment' is used loosely here.  It refers to collapsing an axis
        (the moment axis) to one pixel and setting the value of that pixel (for
        all of the other non-collapsed axes) to something computed from the data
        values along the moment axis.  For example, take an RA-DEC-Velocity
        cube, collapse the velocity axis by computing the mean intensity at each
        RA-DEC pixel.  This function offers many different moments and a variety
        of automatic methods to compute them.
        
        We try to make a distinction between a `moment' and a `method'.  This
        boundary is a little blurred, but it claims to refer to the distinction
        between what you are computing, and how the pixels that were included in
        that computation were selected.  For example, a `moment' would be the
        average value of some pixel values in a spectrum.  A `method' for
        selecting those pixels would be a simple pixel value range specifying
        which pixels should be included.
        
        There are many available moments, and you specify each one with an
        integer code as it would get rather cumbersome to refer to them via
        strings.  In the list below, the value of the $i$th pixel of the
        spectrum is $I_i$, the coordinate of this pixel is $v_i$ (of course it
        may not be velocity), and there are $n$ pixels in the spectrum.  The
        available moments are:
        
        begin{itemize}
        item{$-1$} -- the mean value of the spectrum
        begin{displaymath}
        { {1over n}  {sum {I_i}}}
        end{displaymath}
        medskip
        
        item{0} -- the integrated value of the spectrum
        begin{displaymath}
        M_0 = Delta v sum I_i
        end{displaymath}
        
        where $Delta v$ is the width (in world coordinate units) of a pixel
        along the moment axis
        medskip
        
        item{1} -- the intensity weighted coordinate (this is
        traditionally used to get 'velocity fields')
        
        begin{displaymath}
        M_1 = { {sum {I_i v_i}} over {M_0}}
        end{displaymath}
        medskip
        
        item{2} -- the intensity weighted dispersion of the coordinate
        (this is traditionally used to get 'velocity dispersion fields')
        
        begin{displaymath}
        sqrt{ { {sum {I_i left(v_i - M_1right)^2}} over {M_0}}}
        end{displaymath}
        medskip
        
        item{3} -- the median of $I$
        medskip
        
        item{4} -- the median coordinate.  Here we treat the spectrum as a
        probability distribution, generate the cumulative distribution, and then
        find the coordinate corresponding to the 50% value.  This moment is not
        very robust, but it is useful for quickly generating a velocity field in
        a way that is not sensitive to noise.  However, it will only give
        sensible results under certain conditions.  The generation of the
        cumulative distribution and the finding of the 50% level really only
        makes sense if the cumulative distribution is monotonic.  This
        essentially means only selecting pixels which are positive or negative.
        For this reason, this moment type is only supported with the basic
        method (see below -- i.e.  no smoothing, no windowing, no fitting) with
        a pixel selection range that is either all positive, or all negative
        medskip
        
        item{5} -- the standard deviation about the mean of the spectrum
        begin{displaymath}
        sqrt{ {1over {left(n-1right)}}  sum{left(I_i - bar{I}right)^2 }}
        end{displaymath}
        medskip
        
        item{6} -- the root mean square of the spectrum
        begin{displaymath}
        sqrt{ {1 over n} sum{I_i^2}}
        end{displaymath}
        medskip
        
        item{7} -- the absolute mean deviation of the spectrum
        begin{displaymath}
        {1 over n} sum {|(I_i - bar{I})|}
        end{displaymath}
        medskip
        
        item{8} -- the maximum value of the spectrum
        medskip
        item{9} -- the coordinate of the maximum value of the spectrum
        medskip
        item{10} -- the minimum value of the spectrum
        medskip
        item{11} -- the coordinate of the minimum value of the spectrum
        medskip
        end{itemize}
        
        bigskip
        noindent {Smoothing}
        
        The purpose of the smoothing functionality is purely to provide
        a mask.  Thus, you can smooth the input image, apply a pixel
        include or exclude range, and generate a smoothed mask which is then
        applied before the moments are generated.  The smoothed data
        are not used to compute the actual moments; that is always done
        from the original data.
        
        bigskip
        noindent{bf Basic Method}
        
        The basic method is to just compute moments directly from the pixel
        values.  This can be modified by applying pixel value inclusion or
        exclusion ranges (arguments {stfaf includepix} and {stfaf excludepix}).
        
        You can then also convolve the image (arguments {stfaf smoothaxes}, {stfaf
        smoothtypes}, and {stfaf smoothwidths}) and find a mask based on the inclusion
        or exclusion ranges applied to the convolved image.  This mask is then
        applied to the unsmoothed data for moment computation.
        
        bigskip
        noindent{bf Window Method}
        
        The window method (invoked with argument {stfaf method='window'}) does
        no pixel-value-based selection.  Instead a window is found (hopefully
        surrounding the spectral line feature) and only the pixels in that
        window are used for computation.  This window can be found from the
        convolved or unconvolved image (arguments {stfaf smoothaxes}, {stfaf
        smoothtypes}, and {stfaf smoothwidths}).
        
        The moments are always computed from the unconvolved data.  The window
        can be found (for each spectrum) automatically.  The
        automatic methods are via Bosma's converging mean algorithm ({stfaf
        method='window'}) or by fitting Gaussians and taking $pm 3sigma$ as
        the window ({stfaf method='window,fit'}).
        In Bosma's algorithm, an initial guess for a range of pixels surrounding
        a spectral feature is refined by widening until the mean of the pixels
        outside of the range converges (to the noise).
        
        bigskip
        noindent{bf Fit Method}
        
        The fit method ({stfaf method='fit'}) fits Gaussians to spectral
        features automatically. The moments are then computed from the
        Gaussian fits (not the data themselves).
        
        bigskip
        noindent{bf Other Arguments}
        
        begin{itemize}
        
        item {stfaf outfile} - If you are creating just one moment image,
        and you specify {stfaf outfile}, then the image is created
        on disk with this name.  If you leave {stfaf outfile} empty
        then a temporary image is created.  In both cases, you can
        access this image with the returned Image tool.  If you are
        making more than one moment image, then theses images are always
        created on disk.  If you specify {stfaf outfile} then this is
        the root for the output file names.  If you don't specify it,
        then the input image name is used as the root.
        
        item {stfaf smoothing} - If you smooth the image to generate a
        mask, you  specify the kernel widths via the {stfaf smoothwidths}
        argument in the same way as in the
        sepconvolve function.  See it for
        details.
        
        item {stfaf stddev} - Some of the automatic methods also require an
        estimate of the noise level in the image.  This is used to assess
        whether a spectrum is purely noise or not, and whether there is any
        signal worth digging out.  If you don't give it via the {stfaf stddev}
        argument, it will be worked out automatically from a Gaussian fit to the
        bins above 25% from a histogram of the entire image.
        
        item {stfaf includepix, excludepix} - The vectors given by arguments
        {stfaf includepix} and {stfaf excludepix} specify a range of pixel
        values for which pixels are either included or excluded.  They are
        mutually exclusive; you can specify one or the other, but not both.  If
        you only give one value for either of these, say {stfaf includepix=b},
        then this is interpreted as {stfaf includepix=[-abs(b),abs(b)]}.
        
        The convolving point-spread function is normalized to have a volume of
        unity.  This means that point sources are depressed in value, but
        extended sources that are large with respect to the PSF remain
        essentially on the same intensity scale; these are the structures you
        are trying to find with the convolution so this is what you want.
        If you convolve the image, then arguments like {stfaf includepix} select
        based upon the convolved image pixel values.  If you are having trouble
        getting these right, you can output the convolved image ({stfaf smoothout})
        and assess the validity of your pixel ranges.  Note also that if you are
        Hanning convolving (usually used on a velocity axis), then the width for
        this kernel must be 3 pixels (triangular smoothing kernels of other
        widths have no valid theoretical basis).
        
        item {stfaf doppler} - If you compute the moments along a spectral
        axis, it is conventional to compute the world coordinate (needed for
        moments 0, 1 and 2) along that axis in "km/s".   The argument {stfaf
        doppler} lets you specify what doppler convention the velocity will be
        calculated in. You can choose from {stfaf doppler=radio, optical,
        true}.   See function summary for the
        definitions of these codes.  For other moment-axis types, the world coordinate
        is computed in the native units.
        
        item {stfaf mask} - The total input mask is the combination  of the
        default pixelmask (if any) and the OTF mask.  Once this mask
        has been established, then the moment method may make additional
        pixel selections.
        
        item {stfaf drop} - If this is true (the default) then the moment axis
        is dropped from the output image.  Otherwise, the output images have  a
        moment axis of unit length and coordinate information that is the same
        as for the input image.  This coordinate information may be totally
        meaningless for the moment images.
        
        end{itemize}
        
        Finally, if you ask for a moment which requires the coordinate to be
        computed for each profile pixel (these are the intensity weighted mean
        coordinate [moment 1] and the intensity weighted dispersion of the
        coordinate [moment 2]), and the profile axis is not separable then there
        will be a performance loss.  Examples of non-separable axes are RA and
        Dec.  If the axis is separable (e.g.  a spectral axis) there is no
        penalty.  In the latter case, the vector of coordinates for one profile
        is the same as the vector for another profile, and it can be precomputed
        (once).
        
        Note that this function has no ``virtual'' output file capability. All
        output files are written to disk.   The output mask for these images is
        good (T) unless the moment method fails to generate a value (e.g.  the
        total input pixel mask was all bad for the profile) in which case it will be bad (F).
        
        If an image has multiple (per-channel beams) and the moment axis is equal to the
        spectral axis, each channel will be convolved with a beam that is equal to the beam
        having the largest area in the beamset prior to moment determination.
        """
        schema = {'moments': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'axis': {'type': 'cInt'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'method': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}, 'smoothaxes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'smoothtypes': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'smoothwidths': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'includepix': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'excludepix': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'peaksnr': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'stddev': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'doppler': {'type': 'cStr'}, 'outfile': {'type': 'cStr'}, 'smoothout': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'drop': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}, 'async': {'type': 'cBool'}}
        doc = {'moments': moments, 'axis': axis, 'region': region, 'mask': mask, 'method': method, 'smoothaxes': smoothaxes, 'smoothtypes': smoothtypes, 'smoothwidths': smoothwidths, 'includepix': includepix, 'excludepix': excludepix, 'peaksnr': peaksnr, 'stddev': stddev, 'doppler': doppler, 'outfile': outfile, 'smoothout': smoothout, 'overwrite': overwrite, 'drop': drop, 'stretch': stretch, 'async': async}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _moments_result = _wrap_image(swig_object=self._swigobj.moments(_pc.document['moments'], _pc.document['axis'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), [_str_ec(_x) for _x in _pc.document['method']], _pc.document['smoothaxes'], _any_ec(_pc.document['smoothtypes']), _pc.document['smoothwidths'], _pc.document['includepix'], _pc.document['excludepix'], _pc.document['peaksnr'], _pc.document['stddev'], _str_ec(_pc.document['doppler']), _str_ec(_pc.document['outfile']), _str_ec(_pc.document['smoothout']), _pc.document['overwrite'], _pc.document['drop'], _pc.document['stretch'], _pc.document['async']))
        return _moments_result

    def name(self, strippath=False):
        """This function returns the name of the imagefile By default, this
        function returns the full absolute path of the imagefile.  You can
        strip this path off if you wish with the {stfaf strippath} argument and
        just recover the imagefile name itself.
        """
        schema = {'strippath': {'type': 'cBool'}}
        doc = {'strippath': strippath}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _name_result = _str_dc(self._swigobj.name(_pc.document['strippath']))
        return _name_result

    def open(self, infile, cache=True):
        """This method detaches from the current image (if an image is attached to the tool), and
        reattaches it (opens) to the new image.
        
        The input image file may be in native CASA, FITS, or Miriad format. In the case of CASA images,
        both Float and Complex valued images aresupported.
        
        The cache parameter applies only to component list images and indicates if pixel values should
        be cached after they are computed for faster retrieval.
        """
        schema = {'infile': {'type': 'cReqPath', 'coerce': _coerce.expand_path}, 'cache': {'type': 'cBool'}}
        doc = {'infile': infile, 'cache': cache}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _open_result = self._swigobj.open(_str_ec(_pc.document['infile']), _pc.document['cache'])
        return _open_result

    def pad(self, outfile='', npixels=int(1), value=float(0), padmask=False, overwrite=False, region={ }, box='', chans='', stokes='', mask='', stretch=False, wantreturn=True):
        """This method pads the directional plane of an image with a specified number of pixels on each side. The
        numerical and mask values of the padding pixels may also be specified. If a region is selected, a subimage
        of that region is created and then padded with the specified pixel parameters. Thus, padding an image of
        shape (ra, dec, freq) = (512, 512, 10) specifying npixels = 3 results in an image of size (518, 518, 10), with
        the blc of the directional plane of the original pixel set corresponding to the directional pixel of (3, 3)
        in the output.
        If wantreturn is True, an image analysis tool attached to the output image is returned. If False, none is
        returned.
        
        """
        schema = {'outfile': {'type': 'cStr'}, 'npixels': {'type': 'cInt'}, 'value': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'padmask': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'box': {'type': 'cStr'}, 'chans': {'type': 'cStr'}, 'stokes': {'type': 'cStr'}, 'mask': {'type': 'cStr'}, 'stretch': {'type': 'cBool'}, 'wantreturn': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'npixels': npixels, 'value': value, 'padmask': padmask, 'overwrite': overwrite, 'region': region, 'box': box, 'chans': chans, 'stokes': stokes, 'mask': mask, 'stretch': stretch, 'wantreturn': wantreturn}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _pad_result = _wrap_image(swig_object=self._swigobj.pad(_str_ec(_pc.document['outfile']), _pc.document['npixels'], _pc.document['value'], _pc.document['padmask'], _pc.document['overwrite'], _any_ec(_pc.document['region']), _str_ec(_pc.document['box']), _str_ec(_pc.document['chans']), _str_ec(_pc.document['stokes']), _str_ec(_pc.document['mask']), _pc.document['stretch'], _pc.document['wantreturn']))
        return _pad_result

    def crop(self, outfile='', axes=[  ], overwrite=False, region={ }, box='', chans='', stokes='', mask='', stretch=False, wantreturn=True):
        """This method crops masked slices from the perimeter of an image. The axes parameter specifies which axes to
        consider. Axes not specified will not be cropped. An empty array implies that all axes should be considered.
        If wantreturn is True, an image analysis tool attached to the output image is returned. If False, none is
        returned.
        
        """
        schema = {'outfile': {'type': 'cStr'}, 'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'overwrite': {'type': 'cBool'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'box': {'type': 'cStr'}, 'chans': {'type': 'cStr'}, 'stokes': {'type': 'cStr'}, 'mask': {'type': 'cStr'}, 'stretch': {'type': 'cBool'}, 'wantreturn': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'axes': axes, 'overwrite': overwrite, 'region': region, 'box': box, 'chans': chans, 'stokes': stokes, 'mask': mask, 'stretch': stretch, 'wantreturn': wantreturn}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _crop_result = _wrap_image(swig_object=self._swigobj.crop(_str_ec(_pc.document['outfile']), _pc.document['axes'], _pc.document['overwrite'], _any_ec(_pc.document['region']), _str_ec(_pc.document['box']), _str_ec(_pc.document['chans']), _str_ec(_pc.document['stokes']), _str_ec(_pc.document['mask']), _pc.document['stretch'], _pc.document['wantreturn']))
        return _crop_result

    def pixelvalue(self, pixel=[ int(-1) ]):
        """This function gets the value of the image and the mask at the specified
        pixel coordinate.  The values are returned in a record with fields
        'value', 'mask' and 'pixel'.  The value is returned as a quantity, the mask
        as a Bool (T is good).  The 'pixel' field holds the actual
        pixel coordinate used.
        
        If the specified pixel coordinate is off the image, "{}" is returned.
        
        Excessive elements in {stfaf pixel} are silently discarded.
        Missing elements are given the (nearest integer) value of the reference pixel.
        This is reflected in the output record 'pixel' field.
        """
        schema = {'pixel': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'pixel': pixel}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _pixelvalue_result = _dict_dc(self._swigobj.pixelvalue(_pc.document['pixel']))
        return _pixelvalue_result

    def putchunk(self, pixels=[ ], blc=[ int(-1) ], inc=[ int(1) ], list=False, locking=True, replicate=False):
        """This function puts an array into the imagefile.  If there is a
        default pixelmask it is ignored in this process.  It is the complement of the
        getchunk function.  You can specify the {stfaf
        blc} and {stfaf inc} if desired.  If they are unspecified, they default
        to the beginning of the image and an increment of one.
        
        Any illegal {stfaf blc} values are set to zero.  Any illegal {stfaf
        inc} values are set to unity.
        
        An error will result if you attempt to put an array beyond the extent of
        the image (i.e., it is not truncated or decimated).
        
        If there are fewer axes in the array than in the image, the array is
        assumed to have trailing axes of length unity.  Thus, if you have a 2D
        array and want to put it in as the YZ plane rather than the XY plane,
        you must ensure that the shape of the array is [1,nx,ny].
        
        However, the argument {stfaf replicate} can be used to replicate the array
        throughout the image (from the blc to the trc).  For example, if you
        provide a 2D array to a 3D image, you can replicate it through the third
        axis by setting {stfaf replicate=T}.   The replication is done
        from the specified {stfaf blc} to the end of the image.
        Use function putregion  if you
        want to terminate the replication at a {stfaf trc} value.
        
        The argument {stfaf locking} controls two things.  If True, then
        after the function is called, the image is unlocked (so some other
        process can acquire a lock) and it is indicated that the image has
        changed.  The reason for having this argument is
        that the unlocking and updating processes are quite expensive.  If you
        are repeatedly calling {stff putchunk} in a for loop, you would be
        advised to use this switch.
        
        A related function is putregion
        which puts the pixels and masks into a more complex region.
        Function {stff putchunk} is retained because it is faster and therefore
        preferable for repeated operation in loops if the pixelmask is not required.
        
        See also the functions set and
        calc which can also change pixel values.
        """
        schema = {'pixels': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'blc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'inc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'list': {'type': 'cBool'}, 'locking': {'type': 'cBool'}, 'replicate': {'type': 'cBool'}}
        doc = {'pixels': pixels, 'blc': blc, 'inc': inc, 'list': list, 'locking': locking, 'replicate': replicate}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putchunk_result = self._swigobj.putchunk(_any_ec(_pc.document['pixels']), _pc.document['blc'], _pc.document['inc'], _pc.document['list'], _pc.document['locking'], _pc.document['replicate'])
        return _putchunk_result

    def putregion(self, pixels=[ ], pixelmask=[ ], region={ }, list=False, usemask=True, locking=True, replicate=False):
        """This function replaces data and/or pixelmask values in the image in
        the specified region.  The {stfaf pixels} and/or {stfaf pixelmask}
        arrays must be the shape of the bounding box, and the whole bounding box
        is replaced in the image.  The region is really only used to specify
        the bounding box.  If the region extends beyond the image, it is
        truncated.  If the {stfaf pixels} or {stfaf pixelmask} array shapes do not
        match the bounding box, an error will result.
        
        When you put a pixelmask, it either replaces the current default pixelmask, or
        is created.  The pixelmask is put before the pixels.
        
        The argument {stfaf usemask} is only relevant when you are putting
        pixel values and there is a pixelmask (meaning also the one you might have
        just put in place).  If {stfaf usemask=T} then only pixels for which
        the mask is good (T) are altered.  If {stfaf usemask=F} then all the
        pixels in the region are altered - the mask is ignored.
        
        The argument {stfaf replicate} can be used to replicate the array
        throughout the image (from the blc to the trc).  For example, if you
        provide a 2D array to a 3D image, you can replicate it through the third
        axis by setting {stfaf replicate=T}.   The replication
        is done in the specified {stfaf region}.
        
        The argument {stfaf locking} controls two things.  If True, then
        after the function is called, the image is unlocked (so some other
        process can acquire a lock) and it is indicated that the image has
        changed.  The reason for having this argument is
        that the unlocking and updating processes are quite expensive.  If you
        are repeatedly calling {stff putregion} in a for loop, you would be
        advised to use this switch (and to consider using {stff putchunk}).
        
        See the related functions putchunk, set and calc.
        """
        schema = {'pixels': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'pixelmask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'list': {'type': 'cBool'}, 'usemask': {'type': 'cBool'}, 'locking': {'type': 'cBool'}, 'replicate': {'type': 'cBool'}}
        doc = {'pixels': pixels, 'pixelmask': pixelmask, 'region': region, 'list': list, 'usemask': usemask, 'locking': locking, 'replicate': replicate}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putregion_result = self._swigobj.putregion(_any_ec(_pc.document['pixels']), _any_ec(_pc.document['pixelmask']), _any_ec(_pc.document['region']), _pc.document['list'], _pc.document['usemask'], _pc.document['locking'], _pc.document['replicate'])
        return _putregion_result

    def rebin(self, outfile, bin, region='', mask='', dropdeg=False, overwrite=False, async=False, stretch=False, crop=False):
        """This application rebins the current image by the specified integer binning
        factors for each axis. It supports both float valued and complex valued images.
        The corresponding output pixel value is the average of the
        input pixel values. The output pixel will be masked bad if there
        were no good input pixels.  A polarization axis cannot be rebinned.
        
        The binning factors array must contain at least one element and no more
        elements than the number of input image axes. If the number of elements
        specified is less than the number of image axes, then the remaining axes
        not specified are not rebinned. All specified values must be positive. A
        value of one indicates that no rebinning of the associated axis will occur.
        
        Binning starts from the origin pixel of the bounding box of the selected region or
        the origin pixel of the input image if no region is specified. The value of crop
        is used to determine how to handle cases where there are pixels
        at the end of the axis that do not form a complete bin. If crop=True,
        extra pixels at the end of the axis are discarded. If crop=False, the remaining
        pixels are averaged into the final bin along that axis. Should the length
        of the axis to be rebinned be an integral multiple of the associated binning
        factor, the value of crop is irrelevant.
        
        A value of dropdeg=True will result in the output image not containing
        axes that are degenerate in the specified region or in the input image if no
        region is specified. Note that, however, the binning
        factors array must still account for degenerate axes, and the binning
        factor associated with a degenerate axis must always be 1.
        
        If {stfaf outfile} is given, the image is written to the specified
        disk file.  If {stfaf outfile} is unset, the Image tool is
        associated with a temporary image.  This temporary image may be in
        memory or on disk, depending on its size.  When you destroy the
        on-the-fly Image tool returned by this function (with the done function) this
        temporary image is deleted.
        """
        schema = {'outfile': {'type': 'cStr'}, 'bin': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'region': {'anyof': [{'type': 'cStr'}, {'type': 'cDict'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'dropdeg': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'async': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}, 'crop': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'bin': bin, 'region': region, 'mask': mask, 'dropdeg': dropdeg, 'overwrite': overwrite, 'async': async, 'stretch': stretch, 'crop': crop}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _rebin_result = _wrap_image(swig_object=self._swigobj.rebin(_str_ec(_pc.document['outfile']), _pc.document['bin'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['dropdeg'], _pc.document['overwrite'], _pc.document['async'], _pc.document['stretch'], _pc.document['crop']))
        return _rebin_result

    def regrid(self, outfile='', shape=[ int(-1) ], csys={ }, axes=[ int(-1) ], region={ }, mask='', method='linear', decimate=int(10), replicate=False, doref=True, dropdeg=False, overwrite=False, force=False, asvelocity=False, async=False, stretch=False):
        """This function regrids the current image onto a grid specified by the
        given Coordinate System.   You can also specify the shape of the
        output image.
        
        The Coordinate System must be given via a Coordsys tool (using
        coordsys.torecord()).  It is optional; if not specified, the Coordinate
        System from the input image (i.e.  the one to which you are applying
        the regrid function) is taken.  The order of the coordinates and axes
        in the output image is always the same as the input image.  It simply
        'finds' the relevant coordinate in the supplied Coordinate System in
        order to figure out the regridding parameters.  The supplied
        Coordinate System must have at least as many coordinates as are
        required to accomodate the axes you are regridding (e.g.  if you
        regrid the first two axes, and these belong to a Direction Coordinate,
        you need one Direction Coordinate in the supplied Coordinate System).
        Coordinates pertaining to axes that are not being regridded are
        supplied from the input image, not the given Coordinate System.
        
        Reference changes are handled (e.g.  J2000 to B1950, LSR to TOPO).  In
        general, the conversion machinery attempts to work out how sophisticated
        it needs to be (e.g.  am I regridding LSR to LSR or LSR to TOPO).
        However, it errs on the side of conservatism so that it can be that the
        conversion machine requires more information than it actually needs.
        For full frame conversions, one needs to know things like location on
        earth (e.g.  observatory), direction of observation, and time of
        observation.
        
        If you get the above errors and you {bf are} doing a frame conversion,
        then that means you must insert some extra information into the
        Coordinate System of your image.  Most likely it's the time
        (coordsys.setepoch) and location
        (coordsys.settelescope) that are
        missing. If you get these errors and you {bf know} that you are not
        specifying a frame change (e.g.  regrid LSR to LSR) then try setting
        {stfaf doref=F}.  This will (silently) bypass all possible frame
        conversions.  Note that if you {bf are} requesting a frame conversion
        and you set {stfaf doref=F} you are doing a bad thing (and you will
        get no warnings).
        
        If you regrid a plane holding a Direction Coordinate and the units are
        Jy/pixel then the output is scaled to conserve flux (roughly; just one
        scale factor at the reference pixel is computed).
        
        Regridding of complex-valued images is supported. The real and imaginary parts are
        regridded independently and the resulting regridded pixel values are combined to
        form the regridded, complex-valued image.
        
        A variety of interpolation schemes are provided (you need only specify
        the first three characters to {stfaf method}).  The cubic interpolation
        is substantially slower than linear, and often the improvement is
        modest.  By default you get linear interpolation.
        
        You specify the shape of the output image ({stfaf shape}) and which
        output axes you want to regrid ({stfaf axes}).  Note that a Stokes axis
        cannot be regridded (you will get a warning if you try).
        
        The {stfaf axes} argument cannot be used to discard axes from the
        output image; it can only be used to specify which {bf output} axes are
        going to be regridded and which are not.  Any axis that you are not
        regridding must have the same output shape as the input image shape for
        that axis.
        
        The {stfaf axes} argument can also be used to specify the order in
        which the {bf output} axes are regridded.  This may give you
        significant performance benefits.  For example, imagine we are going to
        regrid a spectral-line cube of shape [512,512,1204] to shape
        [256,256,32].  If you specified {stfaf axes=[0,1,2]} then first, the
        Direction axes would be regridded for each of the 1024 pixels (and
        stored in a temporary image).  Then each profile at each spatial
        location in the temporary image would be regridded to 32 pixels.  You
        could speed this process up significantly by setting {stfaf
        axes=[2,0,1]}.  In this case, first each profile would be regridded to
        32 pixels, and then each plane of the 32 pixels would be regridded.
        Note that the order of {stfaf axes} does not affect the order of the
        {stfaf shape} argument.  I.e.  it should be given in the natural pixel
        axis order of the image {stfaf [256,256,32]} in both cases.
        
        You can also specify a region to be applied to the input image.  If
        you do this, you need to be careful with the output shape for
        non-regridded axes (must match that of the region - use function
        boundingbox to find that out).
        
        If {stfaf outfile} is given, the image is written to the specified
        disk file.  If {stfaf outfile} is unset, the on-the-fly Image tool
        returned by this function is associated with a temporary image.  This
        temporary image may be in memory or on disk, depending on its size.
        When you destroy the on-the-fly Image tool (with the done function) this
        temporary image is deleted.
        
        The argument {stfaf replicate} can be used to simply replicate pixels
        rather than regridding them.  Normally ({stfaf replicate=F}), for every
        output pixel, its world coordinate is computed and the corresponding
        input pixel found (then a little interpolation grid is generated).  If
        you set {stfaf replicate=T}, then what happens is that for every output
        axis, a vector of regularly sampled input pixels is generated (based on
        the ratio of the output and input axis shapes).  So this just means the
        pixels get replicated (by whatever interpolation scheme you use) rather
        than regridded in world coordinate space.  This process is much faster,
        but its not a true world coordinate based regrid.
        
        As decribed above, when {stfaf replicate} is False, a coordinate is
        computed for each output pixel; this is an expensive operation.  The
        argument {stfaf decimate} allows you to decimate the computation of
        that coordinate grid to a sparse grid, which is then filled in via fast
        interpolation.  The default for {stfaf decimate} is 10.  The number of
        pixels per axis in the sparse grid is the number of output pixels for
        that axis divided by the decimation factor.  A factor of 10 does pretty
        well.  You may find that for very non-linear coordinate systems (e.g.
        very close to the pole) that you have to reduce the decimation factor.
        You may also have to reduce the decimation factor if the number of pixels
        in the output image along an axis to be regridded is less than about 50, or
        the output image may be completely masked.
        
        If one of the axes to be regridded is a spectral axis and asvelocity=True,
        the axis will be regridded to match the velocity, not the frequency,
        description of the template coordinate system. Thus the output pixel
        values will correspond only to the velocity, not the frequency, of the
        output axis.
        
        Sometimes it is useful to drop axes of length one (degenerate axes).
        Use the {stfaf dropdeg} argument if you want to do this.  It will
        discard the axes from the input image.  Therefore the output shape and
        Coordinate System that you supply must be consistent with the input
        image after the degenerate axes are dropped.
        
        Argument {stfaf force} can be used to force all specified axes to be
        regridded, even if the algorithm determines that they don't need to be (because
        the input and output coordinate information is identical).
        
        There is a useful function
        setreferencelocation that
        you can use to keep a specific world coordinate in the center of an
        image when regridding (see example below).
        
        The output pixelmask will be good (T) unless the regridding failed to
        find a value for that output pixel in which case it will be bad (F).
        For example, if the total input mask (default input pixelmask plus OTF
        mask) for all of the relevant input pixels were masked bad
        then the output pixel would be masked bad (F).
        
        {bf Multiple axis Coordinates limitation} -- Some cooordinates pertain
        to more than one axis.  E.g.  a Direction Coordinate holds longitude and
        latitude.  A Linear Coordinate can also hold many axes.  When you regrid
        *any* axis from a Coordinate which holds multiple axes, you must fully
        specify the coordinate information for all axes in that Coordinate in
        the Coordinate System that you provide.  For example, you have a Linear
        Coordinate with two axes and you want to regrid axis one only.  In the
        Coordinate System you provide, the coordinate information for axis two
        (not being regridded) must correctly be a copy from the input coordinate
        system (it won't be filled in for you).
        
        If an image has per-plane beams and one attempts to regrid the spectral axis,
        an exception is thrown.
        
        IMPORTANT NOTE ABOUT FLUX CONSERVATION
        in general regridding is inaccurate for images that the angular resolution is poorly
        sampled. A check is done for such cases and a warning message is emitted if a beam present.
        However, no such check is done if there is no beam present. To add a restoring beam to
        an image, use ia.setrestoringbeam().
        """
        schema = {'outfile': {'type': 'cStr'}, 'shape': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'csys': {'type': 'cDict'}, 'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'method': {'type': 'cStr'}, 'decimate': {'type': 'cInt'}, 'replicate': {'type': 'cBool'}, 'doref': {'type': 'cBool'}, 'dropdeg': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'force': {'type': 'cBool'}, 'asvelocity': {'type': 'cBool'}, 'async': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'shape': shape, 'csys': csys, 'axes': axes, 'region': region, 'mask': mask, 'method': method, 'decimate': decimate, 'replicate': replicate, 'doref': doref, 'dropdeg': dropdeg, 'overwrite': overwrite, 'force': force, 'asvelocity': asvelocity, 'async': async, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _regrid_result = _wrap_image(swig_object=self._swigobj.regrid(_str_ec(_pc.document['outfile']), _pc.document['shape'], _dict_ec(_pc.document['csys']), _pc.document['axes'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _str_ec(_pc.document['method']), _pc.document['decimate'], _pc.document['replicate'], _pc.document['doref'], _pc.document['dropdeg'], _pc.document['overwrite'], _pc.document['force'], _pc.document['asvelocity'], _pc.document['async'], _pc.document['stretch']))
        return _regrid_result

    def transpose(self, outfile='', order=[ ]):
        """This method transposes the axes in the input image to the specified
        order. The associated pixel and mask values and coordinate system are transposed.
        
        If the outfile parameter is empty, only a temporary image is created; no output image
        is written to disk.
        
        The order parameter describes the mapping of the input axes to the output axes.
        It can be one of three types: a non-negative integer, a string, or a list of
        strings. If a string or non-negative integer, it should contain
        zero-based digits describing the new order of the input axes. It must
        contain the same number of (unique) digits as the number of input axes. For example,
        specifying reorder="1032" or reorder=1032 for a four axes image maps input axes
        1, 0, 3, 2 to output axes 0, 1, 2, 3. In the case of order being a nonnegative integer
        and the zeroth axis in the input being mapped to zeroth axis in the output, the zeroth
        digit is implicitly understood to be 0 so that to transpose an image where one would
        use a string order="0321", one could equivalently specify an int order=321.
        IMPORTANT: When specifying a non-negative integer and mapping the zeroth axis of
        the input to the zeroth axis of the output, do *not* explicitly specify the leading
        0; eg, specify order=321 rather than order=0321. Python interprets an integer with
        a leading 0 as an octal number.
        
        Because of ambiguity for axes numbers greater than nine, using string or integer order
        specifications cannot handle images containing more than 10 axes.
        The order parameter can also be specified as a list of strings which uniquely minimally match,
        ignoring case, the image axis names (ia.coordsys().names()).
        So to reorder an image with right ascension, declination, and frequency axes, one could
        specify order=["d", "f", "r"] or equivalently ["decl", "frequ", "right a"]. Note that
        specifying "ra" for the right ascension axis will result in an error because "ra" does
        not match the first two characters of right ascension.
        Axes can be simultaneously inverted in cases where order is a string or an array of
        strings by specifying negative signs in front of the axis/axes to be inverted. So,
        in a 4-D image, order="-10-3-2" maps input axes 1, 0, 3, 2 to output axes 0, 1, 2, 3
        and reverses the direction and values of input axes 1, 3, and 2.
        
        """
        schema = {'outfile': {'type': 'cStr'}, 'order': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'outfile': outfile, 'order': order}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _transpose_result = _wrap_image(swig_object=self._swigobj.transpose(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['order'])))
        return _transpose_result

    def rotate(self, outfile='', shape=[ int(-1) ], pa=[ ], region={ }, mask='', method='cubic', decimate=int(0), replicate=False, dropdeg=False, overwrite=False, stretch=False):
        """This function rotates two axes of an image.  These axes are either
        those associated with a Direction coordinate or with a Linear
        coordinate. The Direction coordinate takes precedence.
        If rotating a Linear coordinate, it must hold precisely two axes.
        
        The method is that the Coordinate is rotated and then the input
        image is regridded to the rotated Coordinate System.
        
        If the image brightness units are Jy/pixel then the output is scaled to
        conserve flux (roughly; just one scale factor at the reference pixel is
        computed).
        
        A variety of interpolation schemes are provided (you need only specify
        the first three characters to {stfaf method}).  The cubic
        interpolation is substantially slower than linear.  By default you get
        cubic interpolation.
        
        You can specify the shape of the output image ({stfaf shape}).
        However, all axis that are not regrided retain the same output shape
        as the input image shape for that axis.  Only the direction coordinate
        axes are regridded.
        
        You can also specify a region to be applied to the input image.  If
        you do this, you need to be careful with the output shape for
        non-regridded axes (must match that of the region - use function
        boundingbox to find that out).
        
        If {stfaf outfile} is given, the image is written to the specified
        disk file.  If {stfaf outfile} is unset, the on-the-fly Image tool
        returned by this function is associated with a temporary image.  This
        temporary image may be in memory or on disk, depending on its size.
        When you destroy the on-the-fly Image tool (with the done function) this
        temporary image is deleted.
        
        The argument {stfaf replicate} can be used to simply replicate pixels
        rather than regridding them.  Normally ({stfaf replicate=F}), for every
        output pixel, its world coordinate is computed and the corresponding
        input pixel found (then a little interpolation grid is generated).  If
        you set {stfaf replicate=T}, then what happens is that for every output
        axis, a vector of regularly sampled input pixels is generated (based on
        the ratio of the output and input axis shapes).  So this just means the
        pixels get replicated (by whatever interpolation scheme you use) rather
        than regridded in world coordinate space.  This process is much faster,
        but its not a true world coordinate based regrid.
        
        As decribed above, when {stfaf replicate} is False, a coordinate is
        computed for each output pixel; this is an expensive operation.  The
        argument {stfaf decimate} allows you to decimate the computation of
        that coordinate grid to a sparse grid, which is then filled in via
        fast interpolation.  The default for {stfaf decimate} is 0 (no
        decimation).  The number of pixels per axis in the sparse grid is the
        number of output pixels for that axis divided by the decimation
        factor.  A factor of 10 does pretty well.  You may find that for very
        non-linear coordinate systems (e.g.  very close to the pole) that you
        have to reduce the decimation factor.
        
        The output pixelmask will be good (T) unless the regridding failed to
        find a value for that output pixel in which case it will be bad (F).
        For example, if the total input mask (default input pixelmask plus OTF
        mask) for all of the relevant input pixels were masked bad
        then the output pixel would be masked bad (F).
        """
        schema = {'outfile': {'type': 'cStr'}, 'shape': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'pa': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'method': {'type': 'cStr'}, 'decimate': {'type': 'cInt'}, 'replicate': {'type': 'cBool'}, 'dropdeg': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'shape': shape, 'pa': pa, 'region': region, 'mask': mask, 'method': method, 'decimate': decimate, 'replicate': replicate, 'dropdeg': dropdeg, 'overwrite': overwrite, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _rotate_result = _wrap_image(swig_object=self._swigobj.rotate(_str_ec(_pc.document['outfile']), _pc.document['shape'], _any_ec(_pc.document['pa']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _str_ec(_pc.document['method']), _pc.document['decimate'], _pc.document['replicate'], _pc.document['dropdeg'], _pc.document['overwrite'], _pc.document['stretch']))
        return _rotate_result

    def rotatebeam(self, angle=[ ]):
        """This method rotates the attached image's beam(s) counterclockwise through the specified angle.
        This is the same thing as increasing the position angle(s) of the beam(s) by the specified angle.
        If the image does not have a beam, no changes to the image are made. If the image has multiple
        beams, all the beams are rotated through the same angle.
        """
        schema = {'angle': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'angle': angle}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _rotatebeam_result = self._swigobj.rotatebeam(_any_ec(_pc.document['angle']))
        return _rotatebeam_result

    def rename(self, name, overwrite=False):
        """This function renames the imagefile associated with the imagetool.
        If a file with name {stfaf name} already exists, you can overwrite it
        with the argument {stfaf overwrite}; otherwise a fail will
        result.
        """
        schema = {'name': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}}
        doc = {'name': name, 'overwrite': overwrite}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _rename_result = self._swigobj.rename(_str_ec(_pc.document['name']), _pc.document['overwrite'])
        return _rename_result

    def replacemaskedpixels(self, pixels=[ ], region={ }, mask='', update=False, list=False, stretch=False):
        """This application replaces the values of all pixels whose total input mask
        (default input pixelmask and OTF mask) is bad (F) with the specified
        value. It supports both float valued and compplex valued images.
        
        If the argument {stfaf update} is F (the default), the actual pixelmask
        is left unchanged.  That is, masked pixels remain masked.   However, if
        you set {stfaf update=T} then the pixelmask will be updated so that the
        pixelmask will now be T (good) where the {bf total} input mask was F
        (bad).
        
        See maskhandler for information
        on how to set the default pixelmask.
        
        There are a few ways in which you can specify what to replace the
        masked pixel values by.
        
        begin{itemize}
        
        item First, you can give the {stfaf pixels} argument a simple numeric
        scalar (e.g.  {cf pixels=1.0}).  Then, all masked values will be
        replaced by that value.
        
        item Second, you can give a scalar
        htmladdnormallink{LEL}{../../notes/223/223.html} expression string
        (e.g.  {cf pixels='min(myimage)'}).  Then, all masked values will be
        replaced by the scalar that results from the expression.  If the scalar expression
        is illegal (e.g.  in the expression {cf pixels='min(myimage)'} there
        were no good pixels in {sff myimage}) then the value 0 is used for
        replacement.
        
        item Third, you can give a
        htmladdnormallink{LEL}{../../notes/223/223.html} expression string
        which has the same shape as the imagefile you are applying the
        function to.  For example, putting {cf pixels='myotherimage'} means
        replace all masked pixels in this imagefile with the equivalent pixel
        in the imagefile called {sff myotherimage}.
        
        Your expression might be quite complex, and you can think of it as
        producing another masked lattice.  However, in the replace process, the
        mask of that expression lattice is ignored.  Thus, only the mask of
        the imagefile you are replacing and the pixel values of the expression
        lattice are relevant.
        
        The expression must conform with the subimage formed by applying the
        region to the image (i.e.  that associated with this Image tool).  If
        you use the {stfaf mask} argument as well, the region is applied to
        it as well (see examples).
        
        end{itemize}
        """
        schema = {'pixels': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'update': {'type': 'cBool'}, 'list': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'pixels': pixels, 'region': region, 'mask': mask, 'update': update, 'list': list, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _replacemaskedpixels_result = self._swigobj.replacemaskedpixels(_any_ec(_pc.document['pixels']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['update'], _pc.document['list'], _pc.document['stretch'])
        return _replacemaskedpixels_result

    def beamarea(self, channel=int(-1), polarization=int(-1)):
        """Get the area of the image's restoring beam.
        
        """
        schema = {'channel': {'type': 'cInt'}, 'polarization': {'type': 'cInt'}}
        doc = {'channel': channel, 'polarization': polarization}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _beamarea_result = _dict_dc(self._swigobj.beamarea(_pc.document['channel'], _pc.document['polarization']))
        return _beamarea_result

    def restoringbeam(self, channel=int(-1), polarization=int(-1)):
        """This function gets the restoring beam(s), if any. If the image has a traditional
        restoring beam, that is returned no matter what channel and polarization are set to.
        If the image has per-plane beams and at least one of channel or polarization is
        set to a non-negative value, the beam for that particular plane is returned. In both
        these cases, the returned record contains fields 'major', 'minor' and
        'postionangle'.   Each of these fields contains a quantity.
        
        If the image contains multiple beams and both channel and polarization are negative,
        a record containing all the beams is returned. This record contains three fields.
        "nChannels" contains an integer value equal to the number of channels, "nStokes"
        contains an integer value equal to the number of polarizations, and "beams" contains
        a record of information for all beams.
        If the image has no polarization
        axis or no spectral axis, the fields in the "beams" record run from "*0" to the number
        of spectral channels or number of polarizations less one, eg "*31" for an image with 32 channels.
        Each of these fields references a beam subrecord with the structure described above for a single beam.
        
        If the image contains both a spectral axis and a polarization axis, the record returned contains
        fields running from "*0" to the number of spectral channels less one, eg "*31" for an image
        with 32 spectral channels. Each of these fields has an associated subrecord with fields running
        from "*0" to the number of polarizations less one, eg "*3" in an image with 4 polarizations.
        Each one of those fields is associated with a beam record for that corresponding channel and
        polarization. The beam record has a structure described above for a single beam.
        
        If there is no restoring beam, this function returds an empty record.
        
        You can set the restoring beam with function
        setrestoringbeam.
        """
        schema = {'channel': {'type': 'cInt'}, 'polarization': {'type': 'cInt'}}
        doc = {'channel': channel, 'polarization': polarization}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _restoringbeam_result = _dict_dc(self._swigobj.restoringbeam(_pc.document['channel'], _pc.document['polarization']))
        return _restoringbeam_result

    def sepconvolve(self, outfile='', axes=[ int(-1) ], types=[ '' ], widths=[ ], scale=float(-1), region={ }, mask='', overwrite=False, stretch=False):
        """This function  does Fourier-based
        convolution of an imagefile by a specified separable kernel.
        
        If {stfaf outfile} is given, the image is written to the specified
        disk file.  If {stfaf outfile} is unset, the on-the-fly Image tool
        returned by this function is associated with a temporary image.  This
        temporary image may be in memory or on disk, depending on its size.
        When you destroy the Image tool (with the done function) this
        temporary image is deleted.
        
        You specify which axes of the image you wish to convolve, by what kernel
        of what width. The kernel types can be shortened to {cf `gauss',
        `hann'} and {cf `box'}.
        
        You specify the widths of the convolution kernels via the argument
        {stfaf widths}.  The values can be specified as a vector of three
        different types.
        
        begin{itemize}
        
        item Quantity - for example {stfaf widths=qa.quantity("1arcsec 0.00001rad")}.
        Note that you can use pixel units, viz. {stfaf widths=qa.quantity("10pix 0.00001rad")}
        see below.
        
        item String - for example {stfaf widths="1km 2arcsec"} (i.e. a string that
        qa.quantity() accepts).
        
        
        
        item Numeric - for example {stfaf widths=[10,20]}.  In this case,
        the units of the widths are assumed to be in pixels.
        
        end{itemize}
        
        The interpretation of {stfaf widths} depends upon the kernel type.
        
        begin{itemize}
        
        item Gaussian - the specified width is the full-width at
        half-maximum.
        
        item Boxcar (tophat) - the specified width is
        the full width.
        
        item Hanning - The kernel is $z[i] = 0.25*y[i-1] + 0.5*y[i] +
        0.25*y[i+1]$.  The width is always 3 pixels, regardless of what
        you give (but you still have to give it !).
        
        end{itemize}
        
        The scaling of the output image is determined by the argument {stfaf scale}.
        If you leave it unset, then autoscaling will be invoked which means that
        the convolution kernels will all be normalized to have unit volume
        to as to conserve flux.
        
        If you do not leave {stfaf scale} unset, then the convolution kernel
        will be scaled by this value (it has peak unity before application
        of this scale factor).
        
        Masked pixels will be assigned the value 0.0 before convolution.
        The output mask is the combination (logical OR) of the default input
        pixelmask (if any) and the OTF mask.  Any other input pixelmasks
        will not be copied.  Use function
        maskhandler if you need to copy other
        masks too.
        
        See also the other convolution functions
        convolve2d,
        convolve and
        hanning.
        """
        schema = {'outfile': {'type': 'cStr'}, 'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'types': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}, 'widths': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'scale': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'axes': axes, 'types': types, 'widths': widths, 'scale': scale, 'region': region, 'mask': mask, 'overwrite': overwrite, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _sepconvolve_result = _wrap_image(swig_object=self._swigobj.sepconvolve(_str_ec(_pc.document['outfile']), _pc.document['axes'], [_str_ec(_x) for _x in _pc.document['types']], _any_ec(_pc.document['widths']), _pc.document['scale'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['overwrite'], _pc.document['stretch']))
        return _sepconvolve_result

    def set(self, pixels=[ ], pixelmask=int(-1), region={ }, list=False):
        """This function replaces data and/or mask values within the image in the
        specified region.  You can think of it as a simplified version of the
        image calculator.
        
        Unlike the calc function, you can
        only set a scalar value for all pixels in the specified region.  For
        example, it can be useful to set a whole image to one value, or a mask
        in a region to one value.  Although you could do that with the related
        functions putregion and
        putchunk, you would have to make an
        array of the shape of the image and if that is large, it could be
        resource expensive.
        
        The value for the pixels is specified with the {stfaf pixels} argument.  It can
        be given as either a Lattice Expression Language (or LEL) expression
        string or a simple numeric scalar.  See htmladdnormallink{note
        223}{../../notes/223/223.html} for a detailed description of the LEL
        expression syntax.  If you give a LEL expression it must be a scalar
        expression.
        
        Note that any default mask is {em ignored} by this function when you
        set pixel values.  This is different from
        calc where the extant mask is
        honoured.
        
        The value for the pixel mask is specified with the {stfaf pixelmask}
        argument ({cf T, F, unset}).  If it's {cf unset} then the mask is not
        changed.
        
        If you specify {stfaf pixelmask=} T or F, then the mask that is affected is
        the current default mask (see
        maskhandler).  If there is no mask, a
        mask is created for you and made the default mask.
        """
        schema = {'pixels': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'pixelmask': {'type': 'cInt'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'list': {'type': 'cBool'}}
        doc = {'pixels': pixels, 'pixelmask': pixelmask, 'region': region, 'list': list}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _set_result = self._swigobj.set(_any_ec(_pc.document['pixels']), _pc.document['pixelmask'], _any_ec(_pc.document['region']), _pc.document['list'])
        return _set_result

    def setbrightnessunit(self, unit):
        """This function sets the image brightness unit. Both float and complex
        valued images are supported.
        You can get the brightness unit with function
        brightnessunit.
        """
        schema = {'unit': {'type': 'cStr'}}
        doc = {'unit': unit}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setbrightnessunit_result = self._swigobj.setbrightnessunit(_str_ec(_pc.document['unit']))
        return _setbrightnessunit_result

    def setcoordsys(self, csys):
        """This function replaces the coordinate system in the image. It is supported for both
        float and complex valued images. Coordinate systems are manipulated with the
        cs tool.  The coordinate system can be
        recovered from an image via the coordsys
        function.
        
        Note that changing the cs tool has no effect on the original
        image, until it is replaced with this function; the value returned
        by coordsys() is a copy of, not a reference to, the image's coordinate system.
        """
        schema = {'csys': {'type': 'cDict'}}
        doc = {'csys': csys}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setcoordsys_result = self._swigobj.setcoordsys(_dict_ec(_pc.document['csys']))
        return _setcoordsys_result

    def sethistory(self, origin='', history=[  ]):
        """A casa imagefile can accumulate history information
        from  an input fits file or by you writing something into
        it explicitly with this function.     Each element of
        the input vector is one line of history.  The new
        history is appended to the old.
        
        
        You can recover the history information with function
        history.
        """
        schema = {'origin': {'type': 'cStr'}, 'history': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}}
        doc = {'origin': origin, 'history': history}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _sethistory_result = self._swigobj.sethistory(_str_ec(_pc.document['origin']), [_str_ec(_x) for _x in _pc.document['history']])
        return _sethistory_result

    def setmiscinfo(self, info):
        """A casa imagefile can accumulate miscellaneous information
        during its lifetime; it is stored in a record called the {stff
        miscinfo} record.  For example, the fits reader
        (fromfits) puts header keywords
        it doesn't otherwise use into the {stff miscinfo} record.  The {stff
        miscinfo} record is not guaranteed to have any entries, so it's up to
        you to check for any fields that you require.
        
        This function sets the {cf miscinfo} record of the imagefile.  Note
        that this function {em replaces} the record, it doesn't add to it, so
        if you want to augment the existing record, you should first capture
        it with the miscinfo function, add
        to the record, and then put it back.  The fits writer will attempt
        to write all the fields in the {stff miscinfo} record to the fits file.
        It can do so for scalars and 1-dimensional arrays.  Records
        will be omitted, and multi-dimensional arrays will be flattened into
        1-dimensional arrays.
        """
        schema = {'info': {'type': 'cDict'}}
        doc = {'info': info}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setmiscinfo_result = self._swigobj.setmiscinfo(_dict_ec(_pc.document['info']))
        return _setmiscinfo_result

    def shape(self):
        """The shape of an image is a vector holding the length of each axis of
        the image.  Although this information is also available in the summary function, it is
        so useful that it can be obtained directly. Both Float and Complex valued
        images are supported.
        """
        _shape_result = self._swigobj.shape()
        return _shape_result

    def setrestoringbeam(self, major=[ ], minor=[ ], pa=[ ], beam={ }, remove=False, log=True, channel=int(-1), polarization=int(-1), imagename=''):
        """This function sets the restoring beam(s) for an image.
        
        You may supply the beam in one of two ways.
        
        First, you can use the argument {stfaf beam} which you must assign to a
        record containing  fields 'major', 'minor' and 'positionangle'.
        Each of these fields contains a quantity.   This record is in the same
        format as  one returned by function
        restoringbeam.
        If {stfaf beam} is used, the arguments {stfaf major, minor, & pa} are
        ignored.
        
        Second, you can use the arguments {stfaf major}, {stfaf minor}
        and {stfaf pa}.   Only the ones that you assign are used.
        Each argument should be assigned either a quantity or a float (units
        are implicitly those of the current beam - or if none, arcsec for
        the axes and degrees for the position angle). These parameters are only
        used if {stfaf beam} is not specified.
        
        An image must have exactly one of the following states:
        
        1. An image can have a single "traditional" beam. In that case, the beam applies
        to every channel and polarization in the image.
        
        2. If an image has more than one spectral channel or more than one polarization,
        it can have a set of beams. In this case, each channel and/or polarization will have
        its own beam.
        
        3. An image can have neither a traditional beam nor a beam set.
        
        It is never permissible for an image to have both a traditional (global) beam and
        a set of per-plane beams. Task and method behavior is undefined in that case and
        any resulting products are considered corrupt.
        
        RULES FOR BEAM MODIFICATION
        
        If an image has no beams, a traditional (global) beam can be added by setting
        both channel and polarization to negative values.
        
        If an image has no beams, a set of per-plane beams can be added by setting either
        or both channel and/or polarization to a non-negative value. In this case, a number
        of per-plane beams are added consistent with the image and they are all set to be
        the same with parameters equal to those specified by either the beam or major/minor/pa
        parameters.
        
        If an image has a traditional beam, it can be modified by setting both channel and
        polarization to negative values. If one or both is not set to a negative value, an
        exception is thrown, and nothing is modified.
        
        If an image has a set of per plane beams, one at a time of these can be modified by
        setting the appropriate channel number and/or polarization number. All the per-plane
        beams can be modified to the same values in one go by setting both channel and
        polarization to negative values. Also, in the case where an image has multiple channels,
        the beams associated with all channels for a given polarization can be modified to the same
        beam by setting polarization equal to the desired polarization plane number and by setting
        channel to a negative value. Similarly, in the case where an image has multiple polarizations,
        the beams associated with all polarizations for a given spectral channel can be modified to the same
        beam by setting channel equal to the desired spectral channel number and by setting
        polarization to a negative value.
        
        A beam or set of beams can be copied from another image using the imagename parameter to specify
        that image's name. If both the current image and specified image have multiple beams, the current
        image shape must be consistent with the specified image beam set shape.
        
        The traditional beam or a set of multiple beams can be deleted from an image by setting {stfaf delete=T}. If set
        to true, all other parameters are then ignored; all existing beams
        will be irrevocably deleted.
        """
        schema = {'major': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'minor': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'pa': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'beam': {'type': 'cDict'}, 'remove': {'type': 'cBool'}, 'log': {'type': 'cBool'}, 'channel': {'type': 'cInt'}, 'polarization': {'type': 'cInt'}, 'imagename': {'type': 'cStr'}}
        doc = {'major': major, 'minor': minor, 'pa': pa, 'beam': beam, 'remove': remove, 'log': log, 'channel': channel, 'polarization': polarization, 'imagename': imagename}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setrestoringbeam_result = self._swigobj.setrestoringbeam(_any_ec(_pc.document['major']), _any_ec(_pc.document['minor']), _any_ec(_pc.document['pa']), _dict_ec(_pc.document['beam']), _pc.document['remove'], _pc.document['log'], _pc.document['channel'], _pc.document['polarization'], _str_ec(_pc.document['imagename']))
        return _setrestoringbeam_result

    def statistics(self, axes=[ int(-1) ], region={ }, mask='', includepix=[ float(-1) ], excludepix=[ float(-1) ], list=False, force=False, disk=False, robust=False, verbose=False, stretch=False, logfile='', append=True, algorithm='classic', fence=float(-1), center='mean', lside=True, zscore=float(-1), maxiter=int(-1), clmethod='auto', niter=int(3)):
        """This function computes statistics
        from the pixel values in the image.  You can then list them
        and retrieve them (into a record) for further analysis.
        
        The names of the fields in the returned record are summarized below:
        
        begin{itemize}
        
        item {stfaf npts} - the number of unmasked points used
        
        item {stfaf sum} - the sum of the pixel values: $sum I_i$
        
        item {stfaf flux} - flux or flux density, see below for details
        
        item {stfaf sumsq} - the sum of the squares of the pixel values: $sum I_i^2$
        
        item {stfaf mean} - the mean of pixel values: $bar{I} = sum I_i / n$
        
        item {stfaf sigma} - the standard deviation about the
        mean: $sigma^2 = (sum I_i - bar{I})^2 / (n-1)$
        
        item {stfaf rms} - the root mean square: $sqrt {sum I_i^2 / n}$
        
        item  {stfaf min} - minimum pixel value
        
        item {stfaf max} - the maximum pixel value
        
        item {stfaf median} - the median pixel value (if {stfaf robust=T})
        
        item {stfaf medabsdevmed} - the median of the absolute deviations from the median
        (if {stfaf robust=T})
        
        item {stfaf quartile} - the inter-quartile range (if {stfaf
        robust=T}).  Find the points which are 25% largest and 75% largest
        (the median is 50% largest).
        
        item {stfaf q1} - The first quartile. Reported only if robust=T.
        
        item {stfaf q3} - The third quartile. Reported only if robust=T.
        
        item {stfaf blc} - the absolute pixel coordinate of the bottom left
        corner of the bounding box of the region of interest.  If 'region' is
        unset, this will be the bottom left corner of the whole image.
        
        item {stfaf blcf} - the formatted absolute world coordinate of the bottom left corner of the bounding box of the region of interest.
        
        item {stfaf trc} - the absolute pixel coordinate of the top right corner of the bounding box of the region of interest.
        
        item {stfaf trcf} - the formatted absolute world coordinate of the top right corner of the bounding box of the region of interest.
        
        item {stfaf minpos} - absolute pixel coordinate of minimum pixel value
        
        item {stfaf maxpos} - absolute pixel coordinate of maximum pixel value
        
        item {stfaf minposf} - formatted string of the world coordinate of
        the minimum pixel value
        
        item  {stfaf maxposf} - formatted string of the world coordinate of
        the maximum pixel value
        
        end{itemize}
        
        The last four fields only appear if you evaluate the statistics over all
        axes in the image.  As an example, if the returned record is captured in
        {stfaf `mystats'}, then you could access the `mean' field via
        {cf print mystats['mean']}.
        
        If there are no good points (e.g.  all pixels are masked bad in the
        region), then the length of these fields will be 0 (e.g.  {cf
        len(mystats['npts'])==0}).
        
        You have no control over which statistics are listed to the logger,
        you always get the same selection.  You can choose to list the
        statistics or not (argument {stfaf list}).
        
        As well as the simple (and faster to calculate) statistics like means
        and sums, you can also compute some robust (quantile-like) statistics.  Currently
        these are the median, median absolute deviations from the median,
        the first and third quartiles, and the inner-quartile range.  Because these are computationally
        expensive, they are only computed if robust=True.
        
        Note that if the axes are set to all of the axes in the image (which is
        the default) there is just one value per statistic.
        
        You have control over which pixels are included in the statistics computations
        via the {stfaf includepix} and {stfaf excludepix} arguments.  These vectors
        specify a range of pixel values for which pixels are either included or
        excluded.  They are mutually exclusive; you can specify one or the
        other, but not both.  If you only give one value for either of these,
        say {stfaf includepix=b}, then this is interpreted as {stfaf
        includepix=[-abs(b),abs(b)]}.
        
        This function generates a `storage' lattice, into which the statistics
        are written.  It is only regenerated when necessary.  For example, if
        you run the function twice with identical arguments, the statistics will
        be directly retrieved from the storage lattice the second time.
        However, you can force regeneration of the storage image if you set
        {stfaf force=T}.  The storage medium is either in memory or on disk,
        depending upon its size.  You can force it to disk if you set {stfaf
        disk=T}, otherwise it decides for itself.
        
        CURSOR AXES
        The axes parameter allows one to set the cursor axes over which statistics
        are computed. For example, consider a 3-dimensional image for which axes=[0,2].
        The statistics would be computed for each XZ (axes 0 and 2) plane in the
        image.  One could then examine those statistics as a function of the Y
        (axis 1) axis.
        
        Each statistic is stored in an array in its own field in the returned dictionary.
        The dimensionality of these arrays is equal to the number of axes over which the
        statistics were not evaluated (called the display axes). For example, if the input
        image has four axes, and axes=[0], the output statistic arrays will have three dimensions.
        If axes=[0, 1], the output statistic arrays will have two dimensions.
        
        The shape of the output arrays when axes has a positive number of elements is based on
        the region selection. If there is no region selection, the shape of the statistic arrays
        is just the shape of the image along the display (non-cursor) axes. For example, if the
        input image has dimensions of 300x400x4x80 and axes=[0, 1], in the absence of a region
        selection, the shape of the output statistic arrays will be 4x80. If there is a region
        selection, the shape of the output statistic arrays will be determined by the number of
        planes along the display axes chosen in the region selection. For example, continuing with
        our example, if axes=[0,1] and region=rg.box([0, 0, 1, 20], [299,399, 2, 60]), the output
        statistic arrays will have shapes of 2x41. Only the selected planes will be displayed in the
        logger output if verbose=True.
        
        In the case where the image has a pixel mask, and/or the mask parameter is specified, and because
        of this specification a plane is entirely masked, this element is included in the statistic arrays
        (usually with a value of 0). It is not included in the logger output if verbose=True. One can
        exclude such elements from computations on the output arrays by using the numpy.extract() method.
        For example, to compute the minimum rms value, not including any fully masked planes, one could
        use
        
        stats = ia.statistics(...)
        rmsmin = numpy.min(numpy.extract(stats['npts']>0, stats['rms']))
        
        Thus in the computation of rmsmin, only the rms elements are considered which have
        associated values of npts that are not zero.
        
        ALGORITHMS
        
        Several types of statistical algorithms are supported:
        
        * classic: This is the familiar algorithm, in which all unmasked pixels, subject to any
        specified pixel ranges, are used. One may choose one of two methods, which vary only by
        performance, for computing classic statistics, via the clmethod parameter. The "tiled"
        method is the old method and is fastest in cases where there are a large number of
        individual sets of statistics to be computed and a small number of data points per set.
        This can occur when one sets the axes parameter, which causes several individual sets of
        statistics to be computed. The "framework" method uses the new statistics framework to
        compute statistics. This method is fastest in the regime where one has a small number of
        individual sets of statistics to calculate, and each set has a large number of points.
        For example, this method is fastest when computing statistics over an entire image in one
        go (no axes specified). A third option, "auto", chooses which method to use by predicting
        which be faster based on the number of pixels in the image and the choice of the axes
        parameter.
        
        * fit-half: This algorithm calculates statistics on a dataset created from real and virtual pixel values.
        The real values are determined by the input parameters center and lside. The parameter center
        tells the algorithm where the center value of the combined real+virtual dataset should be. Options
        are the mean or the median of the input image's pixel values, or at zero. The lside parameter tells
        the algorithm on which side of this center the real pixel values are located. True indicates that
        the real pixel values to be used are <= center. False indicates the real pixel values to be used
        are >= center. The virtual part of the dataset is then created by reflecting all the real values
        through the center value, to create a perfectly symmetric dataset composed of a real and a virtual
        component. Statistics are then calculated on this resultant dataset. These two parameters are
        ignored if algorithm is not "fit-half". Because the maximum value is virtual if lside is True and the
        minimum value is virtual if lside is False, the value of the maximum position (if lside=True) or
        minimum position (if lside=False) is not reported in the returned record.
        
        * hinges-fences: This algorithm calculates statistics by including data in a range
        between Q1 - f*D and Q3 + f*D, inclusive, where Q1 is the first quartile of the distribution
        of unmasked data, subject to any specified pixel ranges, Q3 is the third quartile, D = Q3 - Q1
        (the inner quartile range), and f is the user-specified fence factor. Negative values of f
        indicate that the full distribution is to be used (ie, the classic algorithm is used). Sufficiently
        large values of f will also be equivalent to using the classic algorithm. For f = 0, only data
        in the inner quartile range is used for computing statistics. The value of fence is silently
        ignored if algortihm is not "hinges-fences".
        
        * chauvenet: The idea behind this algorithm is to eliminate outliers based on a maximum z-score value.
        A z-score is the number of standard deviations a point is from the mean of a distribution. This
        method thus is meant to be used for (nearly) normal distributions. In general, this is an iterative
        process, with successive iterations discarding additional outliers as the remaining points become
        closer to forming a normal distribution. Iterating stops when no additional points lie beyond the
        specified zscore value, or, if zscore is negative, when Chauvenet's criterion is met (see below).
        The parameter maxiter can be set to a non-negative value to prematurely abort this iterative
        process. When verbose=True, the "N iter" column in the table that is logged represents the number
        of iterations that were executed.
        
        Chauvenet's criterion allows the target z-score to decrease as the number of points in the
        distribution decreases on subsequent iterations. Essentially, the criterion is that the probability
        of having one point in a normal distribution at a maximum z-score of z_max must be at least 0.5.
        z_max is therefore a function of (only) the number of points in the distrbution and is given by
        
        npts = 0.5/erfc(z_max/sqrt(2))
        
        where erfc() is the complementary error function. As iterating proceeds, the number of remaining
        points decreases as outliers are discarded, and so z_max likewise decreases. Convergence occurs when
        all remaining points fall within a z-score of z_max. Below is an illustrative table of z_max values
        and their corresponding npts values. For example, it is likely that there will be a 5-sigma "noise
        bump" in a perfectly noisy image with one million independent elements.
        
        z_max    npts
        1.0                1
        1.5                3
        2.0               10
        2.5               40
        3.0              185
        3.5            1,074
        4.0            7,893
        4.5           73,579
        5.0          872,138
        5.5       13,165,126
        6.0      253,398,672
        6.5    6,225,098,696
        7.0  195,341,107,722
        
        * biweight: The biweight algorithm is a robust iterative algorithm that computes two
        quantities called the "location" and the "scale", which are analogous to the mean
        and the standard deviation. In this case, the only keys present in the returned
        dictionary are 'mean' (location), 'sigma' (scale), 'npts', 'min', and 'max'. The
        last three represent the values using the entire distribution. Note that the
        biweight algorithm does not support computation of quantile-like values (median,
        madm, q1, q3, and iqr), so setting robust=True will cause a warning message to
        be logged regarding that, and the computation will proceed.
        
        Important equations for the biweight algorithm are
        
        A. How to compute u_i values, which are related to the weights w_i = (1 - u_i*u_i),
        using the
        equation
        
        u_i = (x_i - c_bi)/(6.0*s_bi)                 (1)
        
        where x_i are the data values, c_bi is the biweight location and s_bi is the
        biweight scale. For the initial computation of the u_i values, c_bi is set
        equal to the median of the distribution and s_bi is set equal to
        the normalized median of the absolute deviation about the median (that is the
        median of the absolute deviation about the median multiplied by the value of
        the probit function at 0.75).
        
        B  The location, c_bi, is computed from
        
        c_bi = sum(x_i * w_i^2)/sum(w_i^2)            (2)
        
        where only values of u_i which satisfy abs(u_i) < 1 (w_i > 0) are used in the sums.
        
        C. The scale value is computed using
        
        n * sum((x_i - c_bi)^2 * w_i^4)
        s_bi^2 = _______________________________      (3)
        p * max(1, p - 1)
        
        where n is the number of points for the entire distribution (which includes all
        the data, even for which abs(u_i) >= 1) and p is given by
        
        p = abs(sum((w_i) * (5*w_i - 4)))
        
        Again, the sums include only data for which abs(u_i) < 1.
        
        The algorithm proceeds as follows.
        1. Compute initial u_i values (and hence w_i values) from equation (1), setting
        c_bi equal to the median of the distribution and s_bi equal to the normalized
        median of the absolute deviation about the median.
        2. Compute the initial value of the scale using the w_i values computed in
        step 1. using equation 3.
        3. Recompute u_i/w_i values using the most recent previous scale and location
        values.
        4. Compute the location using the u_i.w_i values from step 3 and equation (2).
        5. Recompute u_i/w_i values using the most recent previous scale and location
        values.
        6. Compute the new scale value using the the u_i/w_i values computed in
        step 5 and the value of the location computed in step 4.
        7. Steps 3. - 6. are repeated until convergence occurs or the maximum number of
        iterations (specified in the niter parameter) is reached. The convergence
        criterion is given by
        
        abs(s_bi - s_bi,prev) < 0.03 * sqrt(0.5/(n - 1))
        
        where s_bi,prev is the value of the scale computed in the previous iteration.
        
        In the special case where niter is specified to be negative, the faster,
        non-iterative algorithm proceeds as follows:
        
        1. Compute u_i/w_i values using the median for the location and the normalized
        median of the absolute deviation about the median as the scale
        2. Compute the location and scale (which can be carried out simultaneously)
        using the u_i/w_i values computed in step 1. The value of the location is
        just the median that is used in equation (3) to compute the scale
        
        NOTES ON FLUX DENSITIES AND FLUXES
        
        Fluxes and flux densities are not computed if any of the following conditions is met:
        
        1. The image does not have a direction coordinate
        2. The image does not have a intensity-like brightness unit. Examples of such units
        are Jy/beam (in which case the image must also have a beam) and K.
        3. There are no direction axes in the cursor axes that are used.
        4. If the (specified region of the) image has a non-degenerate spectral axis,
        and the image has a tablular spectral axis (axis with varying increments)
        5. Any axis that is not a direction nor a spectral axis that is included in the cursor
        axes is not degenerate within in the specified region
        
        Note that condition 4 may be removed in the future.
        
        In cases where none of the above conditions is met, the flux density(ies) (intensities
        integrated over direction planes) will be computed if any of the following conditions
        are met:
        
        1. The image has no spectral coordinate
        2. The cursor axes do not include the spectral axis
        3. The spectral axis in the chosen region is degenerate
        
        In the case where there is a nondegenerate spectral axis that is included in the cursor
        axes, the flux (flux density integrated over spectral planes) will be computed. In this
        case, the spectral portion of the flux unit will be the velocity unit of the spectral
        coordinate if it has one (eg, if the brightness unit is Jy/beam and the velocity unit is
        km/s, the flux will have units of Jy.km/s). If not, the spectral portion of the flux unit
        will be the frequency unit of the spectral axis (eg, if the brightness unit is K and the
        frequency unit is Hz, the resulting flux unit will be K.arcsec2.Hz).
        
        In both cases of flux density or flux being computed, the resulting numerical value is
        assigned to the "flux" key in the output dictionary.
        
        If the image has units of Jy/beam, the flux density is just the mean intensity multiplied
        by the number of beam areas included in the region. The beam area is defined as the volume
        of the elliptical Gaussian defined by the synthesized beam, divided by the maximum of
        that function, which is equivalent to
        
        pi/(4*ln(2)) * major * minor
        
        where ln() is the natural logarithm and major and minor are the major and minor FWHM axes
        of the beam, respectively.
        """
        schema = {'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cReqPath', 'coerce': _coerce.expand_path}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'includepix': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'excludepix': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'list': {'type': 'cBool'}, 'force': {'type': 'cBool'}, 'disk': {'type': 'cBool'}, 'robust': {'type': 'cBool'}, 'verbose': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}, 'logfile': {'type': 'cStr'}, 'append': {'type': 'cBool'}, 'algorithm': {'type': 'cStr'}, 'fence': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'center': {'type': 'cStr'}, 'lside': {'type': 'cBool'}, 'zscore': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'maxiter': {'type': 'cInt'}, 'clmethod': {'type': 'cStr'}, 'niter': {'type': 'cInt'}}
        doc = {'axes': axes, 'region': region, 'mask': mask, 'includepix': includepix, 'excludepix': excludepix, 'list': list, 'force': force, 'disk': disk, 'robust': robust, 'verbose': verbose, 'stretch': stretch, 'logfile': logfile, 'append': append, 'algorithm': algorithm, 'fence': fence, 'center': center, 'lside': lside, 'zscore': zscore, 'maxiter': maxiter, 'clmethod': clmethod, 'niter': niter}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _statistics_result = _dict_dc(self._swigobj.statistics(_pc.document['axes'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['includepix'], _pc.document['excludepix'], _pc.document['list'], _pc.document['force'], _pc.document['disk'], _pc.document['robust'], _pc.document['verbose'], _pc.document['stretch'], _str_ec(_pc.document['logfile']), _pc.document['append'], _str_ec(_pc.document['algorithm']), _pc.document['fence'], _str_ec(_pc.document['center']), _pc.document['lside'], _pc.document['zscore'], _pc.document['maxiter'], _str_ec(_pc.document['clmethod']), _pc.document['niter']))
        return _statistics_result

    def twopointcorrelation(self, outfile='', region={ }, mask='', axes=[ int(-1) ], method='structurefunction', overwrite=False, stretch=False):
        """This function  computes
        two-point auto-correlation functions from an image.
        
        By default, the auto-correlation function is computed for the Sky axes.
        If there is no sky in the image, then the first two axes are used.
        Otherwise you can specify which axes the auto-correlation function lags
        are computed over with the {stfaf axes} argument (must be of length 2).
        
        Presently, only the Structure Function is implemented.  This is defined as :
        
        begin{displaymath}
        S(lx,ly) = < (data(i,j) - data(i+lx,j+ly))^2 >
        end{displaymath}
        
        where $lx, ly$ are integer lags in the x (0-axis) and y (1-axis)
        directions.  The ensemble average is over all the values at the same
        lag pair.  This process is extremely compute intensive and so you may
        have to be patient.
        
        In an auto-correlation function image there are some symmetries.  The
        first and third quadrants are symmetric, and the second and fourth are
        symmetric.  So in principle, all the information is in the top or bottom
        half of the image.  We just write it all out to look nice.  The long
        lags don't have a lot of contributing values of course.
        """
        schema = {'outfile': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'axes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'method': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'region': region, 'mask': mask, 'axes': axes, 'method': method, 'overwrite': overwrite, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _twopointcorrelation_result = self._swigobj.twopointcorrelation(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['axes'], _str_ec(_pc.document['method']), _pc.document['overwrite'], _pc.document['stretch'])
        return _twopointcorrelation_result

    def subimage(self, outfile='', region='', mask='', dropdeg=False, overwrite=False, list=True, stretch=False, wantreturn=True, keepaxes=[  ]):
        """This function copies all or part of the image to another on-the-fly Image tool.
        Both float and complex valued images are supported.
        
        If {stfaf outfile} is given, the subimage is written to the specified
        disk file.  If {stfaf outfile} is unset, the returned Image tool actually
        references the input image file (i.e.  that associated with the Image
        tool to which you are applying this function).  So if you deleted the
        input image disk file, it would render this tool useless.  When you
        destroy this tool (with the done function)
        the reference connection is broken.
        
        Sometimes it is useful to drop axes of length one (degenerate axes).
        Use the {stfaf dropdeg} argument if you want to do this. Further control
        is provided via the keepaxes parameter. If dropdeg=True, you may specify
        a list of degenerate axes to keep in the keep axes parameter. This allows
        you to drop only a subset of degenerate axes. This parameter is ignored if
        dropdeg=False. If dropdeg=True, all degenerate axes are dropped if keepaxes
        is set to an empty list (this is the default behavior). Nondegenerate
        axes are implicitly kept, even if they are included in the keepaxes list.
        
        The output mask is the combination (logical OR) of the default input
        pixelmask (if any) and the OTF mask.  Any other input pixelmasks
        will not be copied.  Use function maskhandler if you
        need to copy other masks too.
        
        If the mask has fewer dimensions than the image and if the shape
        of the dimensions the mask and image have in common are the same,
        the mask will automatically have the missing dimensions added so
        it conforms to the image.
        
        If stretch is true and if the number of mask dimensions is less than
        or equal to the number of image dimensions and some axes in the
        mask are degenerate while the corresponding axes in the image are not,
        the mask will be stetched in the degenerate dimensions. For example,
        if the input image has shape [100, 200, 10] and the input
        mask has shape [100, 200, 1] and stretch is true, the mask will be
        stretched along the third dimension to shape [100, 200, 10]. However if
        the mask is shape [100, 200, 2], stretching is not possible and an
        error will result.
        """
        schema = {'outfile': {'type': 'cStr'}, 'region': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'dropdeg': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'list': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}, 'wantreturn': {'type': 'cBool'}, 'keepaxes': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'outfile': outfile, 'region': region, 'mask': mask, 'dropdeg': dropdeg, 'overwrite': overwrite, 'list': list, 'stretch': stretch, 'wantreturn': wantreturn, 'keepaxes': keepaxes}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _subimage_result = _wrap_image(swig_object=self._swigobj.subimage(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['dropdeg'], _pc.document['overwrite'], _pc.document['list'], _pc.document['stretch'], _pc.document['wantreturn'], _pc.document['keepaxes']))
        return _subimage_result

    def summary(self, doppler='RADIO', list=True, pixelorder=True, verbose=False):
        """This function summarizes miscellaneous information such as shape, Coordinate System,
        restoring beams, and masks.
        
        If called without any arguments, this function displays a summary of the
        image header to the logger; where appropriate, values will be
        formatted nicely (e.g.  HH:MM:SS.SS for the reference value of RA axes).
        
        For spectral axes, the information is listed as a velocity as well as
        a frequency.  The argument {stfaf doppler} allows you to specify what
        velocity doppler convention it is listed in.  You can choose from
        {stfaf radio, optical} and {stfaf true}.  Alternative names are
        {stfaf z} for {stfaf optical}, and {stfaf beta} or {stfaf
        relativistic} for {stfaf true}.  The default is {stfaf radio}.  The
        definitions are
        
        begin{itemize}
        item radio: $1 - F$
        item optical: $-1 + 1/F$
        item true: $(1 - F^2)/(1 + F^2)$
        end{itemize}
        where $F = nu/nu_0$ and $nu_0$ is the rest frequency.  If the rest
        frequency has not been set in your image, you can set it via
        a Coordsys tool with
        the function setrestfrequency.
        
        If the output of summary is saved to a variable, then the {stfaf
        header} field (for instance, {stfaf mysummary['header']}) has the
        following fields filled in:
        
        begin{description}
        item[ndim]       Dimension of the image.
        item[shape]      Length of each axis in the image.
        item[tileshape]  Shape of the chunk which is most efficient for I/O.
        item[axisnames]  Name of each axis.
        item[refpix]     Reference pixel for each axis (0-relative)
        item[refval]     Reference value for each axis.
        item[incr]       Increment for each axis.
        item[axisunits]  Unit name for each axis.
        item[unit]       Brightness units for the pixels.
        item[hasmask]    True if the image has a mask.
        item[defaultmask]The name of the mask which is applied by default.
        item[masks]      The names of all the masks stored in this image.
        item[restoringbeam] The restoring beam(s) if present.
        item[imagetype]   The image type.
        end{description}
        
        For an image with multiple beams, the restoringbeam field is a dictionary of dictionaries with
        keys of names "*" followed by the channel number, if the image has a spectral coordinate,
        or the polarization number if it does not. That is, the keys have names "*0", "*1", "*2", etc.
        If the image has both a spectral and a polarization coordinate, each of these dictionaries is
        a dictionary with keys of the same form which range from 0 to the number of polarizations
        minus 1; "*0", "*1", ... The dictionaries pointed to by the channel and/or polarization number
        contain information for the beam at that position.
        
        If you set {stfaf list=F}, then the summary will not be written to
        the logger.  The
        return value of the function, in the {stfaf header} field is a
        vector string containing the formatted output that would normally
        have gone to the logger.
        
        If verbose is True and the image contains multiple beams, the formatted output,
        whether it is written to the logger or placed in the output record, will have
        information on every beam in the dataset. If verbose=False and the image has
        multiple beams, only a summary of beams for each polarization is listed. In this
        case, the beams with the maximum area, the minimum area, and the median area for
        each polarization are listed. However, all the beams can still be found in the
        restoringbeam field of the returned dictionary. If the image does not have multiple
        beams, verbose is not used.
        """
        schema = {'doppler': {'type': 'cStr'}, 'list': {'type': 'cBool'}, 'pixelorder': {'type': 'cBool'}, 'verbose': {'type': 'cBool'}}
        doc = {'doppler': doppler, 'list': list, 'pixelorder': pixelorder, 'verbose': verbose}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _summary_result = _dict_dc(self._swigobj.summary(_str_ec(_pc.document['doppler']), _pc.document['list'], _pc.document['pixelorder'], _pc.document['verbose']))
        return _summary_result

    def tofits(self, outfile='', velocity=False, optical=True, bitpix=int(-32), minpix=float(1), maxpix=float(-1), region={ }, mask='', overwrite=False, dropdeg=False, deglast=False, dropstokes=False, stokeslast=True, wavelength=False, airwavelength=False, async=False, stretch=False, history=True):
        """This function converts the image into a fits file.
        
        
        If the image has a rest frequency associated with it, it will always
        write velocity information into the fits file.  By default the
        frequency information will be primary as it is the internal native format.
        If you select {stfaf velocity=T} then by default
        the velocity is written in the optical convention, but if {stfaf
        optical=F} it will use the radio convention instead.
        Alternatively, if you use  {stfaf velocity=F} and {stfaf wavelength=T},
        the spectral axis will be written in wavelength.
        
        The fits definition demands equal increment pixels.  Therefore, if you
        write wavelength or optical velocity information as primary, the increment
        is computed at the spectral reference pixel.
        If the bandwidth is large, this may incur non-negligible coordinate
        calculation errors far from the reference pixel if the spectral
        bins are not originally equidistant in wavelength.
        Images generated by the CASA clean task have spectral axes which
        are always equidistant in frequency.
        
        By default the image is written as a floating point fits file
        ({stfaf bitpix= -32}).  Under rare circumstances you might want to
        save space and write it as scaled 16 bit integers ({stfaf bitpix =
        16}).  You can have {stff tofits} calculate the scaling factors by
        using the default {stfaf minpix} and {stfaf maxpix}.  If you set
        {stfaf minpix} and {stfaf maxpix}, values outside of that range will
        be truncated.  This can be useful if all of the fits images dynamic
        range is being used by a few high or low values and you are not
        interested in preserving those values exactly.  Besides the factor of
        two space savings you get by using 16 instead of 32 bits, integer
        images usually also compress well (for example, with the standard GNU
        software facility {tt gzip}).
        
        If the specified region extends beyond the image, it is truncated.
        
        The output mask is the combination (logical OR) of the default input
        pixelmask (if any) and the OTF mask.
        
        Sometimes it is useful to drop axes of length one (degenerate axes)
        because not all FITS readers can handle them.  Use the {stfaf dropdeg}
        argument if you want to do this.
        If you want to specifically only drop a degenerate Stokes axis, use the {stfaf dropstokes}
        argument.
        
        If you want to place degenerate axes last in the FITS header,
        use the {stfaf deglast} argument.
        If you want to make sure that the Stokes axis is placed last in the FITS header,
        use the {stfaf stokeslast} argument.
        """
        schema = {'outfile': {'type': 'cStr'}, 'velocity': {'type': 'cBool'}, 'optical': {'type': 'cBool'}, 'bitpix': {'type': 'cInt'}, 'minpix': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'maxpix': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'overwrite': {'type': 'cBool'}, 'dropdeg': {'type': 'cBool'}, 'deglast': {'type': 'cBool'}, 'dropstokes': {'type': 'cBool'}, 'stokeslast': {'type': 'cBool'}, 'wavelength': {'type': 'cBool'}, 'airwavelength': {'type': 'cBool'}, 'async': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}, 'history': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'velocity': velocity, 'optical': optical, 'bitpix': bitpix, 'minpix': minpix, 'maxpix': maxpix, 'region': region, 'mask': mask, 'overwrite': overwrite, 'dropdeg': dropdeg, 'deglast': deglast, 'dropstokes': dropstokes, 'stokeslast': stokeslast, 'wavelength': wavelength, 'airwavelength': airwavelength, 'async': async, 'stretch': stretch, 'history': history}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _tofits_result = self._swigobj.tofits(_str_ec(_pc.document['outfile']), _pc.document['velocity'], _pc.document['optical'], _pc.document['bitpix'], _pc.document['minpix'], _pc.document['maxpix'], _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['overwrite'], _pc.document['dropdeg'], _pc.document['deglast'], _pc.document['dropstokes'], _pc.document['stokeslast'], _pc.document['wavelength'], _pc.document['airwavelength'], _pc.document['async'], _pc.document['stretch'], _pc.document['history'])
        return _tofits_result

    def toASCII(self, outfile, region={ }, mask='', sep=':', format='%e', maskvalue=float(-999), overwrite=False, stretch=False):
        """This function converts the image into an ascii file. The format is one
        image row per line (see
        fromascii).
        
        The output mask is the combination (logical OR) of the default input
        pixelmask (if any) and the OTF mask.  Because the mask is not
        transferred to the ascii file, you must specify what data value to use
        if a pixel is masked.  By default, the underlying data value in the
        image is used. But this could be anything (and often it's a NaN), so you
        could set, say, {stfaf maskvalue=-10000} as a magic value.
        """
        schema = {'outfile': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'sep': {'type': 'cStr'}, 'format': {'type': 'cStr'}, 'maskvalue': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'overwrite': {'type': 'cBool'}, 'stretch': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'region': region, 'mask': mask, 'sep': sep, 'format': format, 'maskvalue': maskvalue, 'overwrite': overwrite, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _toASCII_result = self._swigobj.toASCII(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _str_ec(_pc.document['sep']), _str_ec(_pc.document['format']), _pc.document['maskvalue'], _pc.document['overwrite'], _pc.document['stretch'])
        return _toASCII_result

    def torecord(self):
        """You can convert an associated image to a record for manipulation or passing it to inputs of other function of other tools.
        This and fromrecord are used for serialization and deserialization.
        """
        _torecord_result = _dict_dc(self._swigobj.torecord())
        return _torecord_result

    def type(self):
        """This function returns the string `image'.  It can be used in
        a script to make sure this variable is an Image
        tool.
        """
        _type_result = _str_dc(self._swigobj.type())
        return _type_result

    def topixel(self, value=[ ]):
        """This function converts from absolute world to pixel coordinate (0-rel).
        The world coordinate can be provided in many formats (numeric, string,
        quantum etc.) via the argument {stfaf value}.  These match the output
        formats of function toworld.
        
        This function is just a wrapper for the Coordsys tool function
        topixel so see the documentation there
        for a description and more examples.
        """
        schema = {'value': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'value': value}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _topixel_result = _dict_dc(self._swigobj.topixel(_any_ec(_pc.document['value'])))
        return _topixel_result

    def toworld(self, value=[ ], format='n', dovelocity=True):
        """This function converts between absolute pixel coordinate (0-rel)
        and world (physical coordinate).
        
        This function is just a wrapper for the Coordsys tool function
        toworld so see the documentation there
        for a description of the arguments and more examples.
        """
        schema = {'value': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'format': {'type': 'cStr'}, 'dovelocity': {'type': 'cBool'}}
        doc = {'value': value, 'format': format, 'dovelocity': dovelocity}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _toworld_result = _dict_dc(self._swigobj.toworld(_any_ec(_pc.document['value']), _str_ec(_pc.document['format']), _pc.document['dovelocity']))
        return _toworld_result

    def unlock(self):
        """This function releases any lock set on the imagefile (and also flushes
        any outstanding I/O to disk).  It is not of general user interest.  It
        can be useful in scripts when a file is being shared between more than
        one process.  See also functions lock and
        haslock.
        """
        _unlock_result = self._swigobj.unlock()
        return _unlock_result

    def newimagefromarray(self, outfile='', pixels=[ ], csys={ }, linear=False, overwrite=False, log=True):
        """This function converts an array of any size into a casa
        imagefile.
        
        If {stfaf outfile} is given, the image is written to the specified
        disk file.  If {stfaf outfile} is unset, the on-the-fly Image tool
        returned by this function is associated with a temporary image.  This
        temporary image may be in memory or on disk, depending on its size.
        When you destroy the on-the-fly Image tool (with the done function) this
        temporary image is deleted.
        
        At present, no matter what type the {stfaf pixels} array is, a
        real-valued image will be written (the input pixels will be converted
        to Float).  In the future, Complex images will be supported.
        
        The Coordinate System, provided as a record describing a Coordsys tool (via
        coordsys.torecord(), for instance) is optional.  If you provide it, it
        must be dimensionally consistent with the pixels array you give (see
        also coordsys).
        
        If you don't provide the Coordinate System (unset), a default Coordinate System
        is made for you.  If {stfaf linear=F} (the default) then it is a
        standard RA/DEC/Stokes/Spectral Coordinate System depending exactly upon
        the shape of the {stfaf pixels} array (Stokes axis must be no longer
        than 4 pixels and you may find the spectral axis coming out before the
        Stokes axis if say, {cf shape=[64,64,32,4]}).  Extra dimensions are
        given linear coordinates.  If {stfaf linear=T} then you get a linear
        Coordinate System.
        """
        schema = {'outfile': {'type': 'cStr'}, 'pixels': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'csys': {'type': 'cDict'}, 'linear': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'log': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'pixels': pixels, 'csys': csys, 'linear': linear, 'overwrite': overwrite, 'log': log}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _newimagefromarray_result = _wrap_image(swig_object=self._swigobj.newimagefromarray(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['pixels']), _dict_ec(_pc.document['csys']), _pc.document['linear'], _pc.document['overwrite'], _pc.document['log']))
        return _newimagefromarray_result

    def newimagefromfits(self, outfile='', infile='', whichrep=int(0), whichhdu=int(0), zeroblanks=False, overwrite=False):
        """This function is used to convert a FITS disk image file (Float,
        Double, Short, Long are supported) to an casa imagefile.  If
        {stfaf outfile} is given, the image is written to the specified disk
        file.  If {stfaf outfile} is unset, the on-the-fly Image tool
        returned by this function is associated with a temporary image.  This
        temporary image may be in memory or on disk, depending on its size.
        When you destroy the on-the-fly Image tool (with the done function) this
        temporary image is deleted.
        
        This function reads from the FITS primary array (when the image is at
        the beginning of the FITS file; {stfaf whichhdu=0}), or an image
        extension (when the image is elsewhere in the FITS file, {stfaf
        whichhdu $>$ 0}).
        
        By default, any blanked pixels will be converted to a mask value which
        is false, and a pixel value that is NaN.  If you set {stfaf
        zeroblanks=T} then the pixel value will be zero rather than NaN.  The
        mask will still be set to false.  See the function
        replacemaskedpixels if you
        need to replace masked pixel values after you have created the image.
        """
        schema = {'outfile': {'type': 'cStr'}, 'infile': {'type': 'cStr'}, 'whichrep': {'type': 'cInt'}, 'whichhdu': {'type': 'cInt'}, 'zeroblanks': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'infile': infile, 'whichrep': whichrep, 'whichhdu': whichhdu, 'zeroblanks': zeroblanks, 'overwrite': overwrite}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _newimagefromfits_result = _wrap_image(swig_object=self._swigobj.newimagefromfits(_str_ec(_pc.document['outfile']), _str_ec(_pc.document['infile']), _pc.document['whichrep'], _pc.document['whichhdu'], _pc.document['zeroblanks'], _pc.document['overwrite']))
        return _newimagefromfits_result

    def newimagefromimage(self, infile='', outfile='', region={ }, mask='', dropdeg=False, overwrite=False):
        """This function applies a region to a disk imagefile, creates a new
        imagefile containing the (sub)image, and associates a new imagetool
        with it.
        
        The input disk image file may be in native casa, fits (Float,
        Double, Short, Long are supported), or Miriad format.  Look
        htmlref{here}{IMAGES:FOREIGNIMAGES} for more information on foreign
        images.
        
        If {stfaf outfile} is given, the (sub)image is written to the specified
        disk file.
        
        If {stfaf outfile} is unset, the Image tool actually references the
        input image file.  So if you deleted the input image disk file, it
        would render this tool useless.  When you destroy this on-the-fly
        tool (with the done
        function) the reference connection is broken.
        
        Sometimes it is useful to drop axes of length one (degenerate axes).
        Use the {stfaf dropdeg} argument if you want to do this.
        
        The output mask is the combination (logical OR) of the default input
        pixelmask (if any) and the OTF mask.  Any other input pixelmasks
        will not be copied.  Use function
        maskhandler if you need to copy other
        masks too.
        
        See also the subimage function.
        """
        schema = {'infile': {'type': 'cStr'}, 'outfile': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'mask': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'dropdeg': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}}
        doc = {'infile': infile, 'outfile': outfile, 'region': region, 'mask': mask, 'dropdeg': dropdeg, 'overwrite': overwrite}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _newimagefromimage_result = _wrap_image(swig_object=self._swigobj.newimagefromimage(_str_ec(_pc.document['infile']), _str_ec(_pc.document['outfile']), _any_ec(_pc.document['region']), _any_ec(_pc.document['mask']), _pc.document['dropdeg'], _pc.document['overwrite']))
        return _newimagefromimage_result

    def newimagefromshape(self, outfile='', shape=[ int(0) ], csys={ }, linear=False, overwrite=False, log=True, type='f'):
        """This function creates a casa imagefile with the specified shape.  All
        the pixel values in the image are set to 0.  Both float valued and complex
        valued images are supported; the data type of the image is specified via
        the type parameter.
        
        If {stfaf outfile} is given, the image is written to the specified
        disk file.  If {stfaf outfile} is unset, the on-the-fly Image tool
        returned by this function is associated with a temporary image.  This
        temporary image may be in memory or on disk, depending on its size.
        When you destroy the on-the-fly Image tool (with the done function) this
        temporary image is deleted.
        
        The Coordinate System, provided as a record describing a Coordsys tool (created via
        coordsys.torecord(), for instance), is optional.  If you provide it,
        it must be dimensionally consistent with the pixels array you give
        (see also coordsys).
        
        If you don't provide the Coordinate System, a default Coordinate System
        is made for you.  If {stfaf linear=F} (the default) then it is a
        standard RA/DEC/Stokes/Spectral Coordinate System depending exactly upon
        the shape (Stokes axis must be no longer than 4 pixels and you may find
        the spectral axis coming out before the Stokes axis if say, {cf
        shape=[64,64,32,4]}).  Extra dimensions are given linear coordinates.
        If {stfaf linear=T} then you get a linear Coordinate System.
        """
        schema = {'outfile': {'type': 'cStr'}, 'shape': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'csys': {'type': 'cDict'}, 'linear': {'type': 'cBool'}, 'overwrite': {'type': 'cBool'}, 'log': {'type': 'cBool'}, 'type': {'type': 'cStr'}}
        doc = {'outfile': outfile, 'shape': shape, 'csys': csys, 'linear': linear, 'overwrite': overwrite, 'log': log, 'type': type}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _newimagefromshape_result = _wrap_image(swig_object=self._swigobj.newimagefromshape(_str_ec(_pc.document['outfile']), _pc.document['shape'], _dict_ec(_pc.document['csys']), _pc.document['linear'], _pc.document['overwrite'], _pc.document['log'], _str_ec(_pc.document['type'])))
        return _newimagefromshape_result

    def pbcor(self, pbimage='', outfile='', overwrite=False, box='', region={ }, chans='', stokes='', mask='', mode='divide', cutoff=float(-1.0), stretch=False):
        """Correct an image for primary beam attenuation using an image of the primary beam pattern.
        The primary beam pattern can be provided as an image, in which case 1. it must have the same
        shape as the input image and its coordinate system must be the same, or 2. it must
        be a 2-D image in which case its coordinate system must consist of a (2-D) direction
        coordinate which is the same as the direction coordinate in the input image and
        its direction plane must be the same shape as that of the input image. Alternatively,
        pbimage can be an array of pixel values in which case the same dimensionality and
        shape constraints apply.
        An image tool referencing the corrected image is returned. The corrected image will also
        be written to disk if outfile is not empty (and overwrite=True if outfile already exists).
        One can choose between dividing the image by the primary beam pattern (mode="divide") or
        multiplying the image by the primary beam pattern (mode="multiply"). One can also choose
        to specify a cutoff limit for the primary beam pattern. For mode="divide", for all pixels
        below this cutoff in the primary beam pattern, the output image will be masked. In the
        case of mode="multiply", all pixels in the output will be masked corresponding to pixels
        with values greater than the cutoff in the primary beam pattern. A negative value for
        cutoff means that no cutoff will be applied, which is the default.
        
        """
        schema = {'pbimage': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'outfile': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'box': {'type': 'cStr'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'chans': {'type': 'cStr'}, 'stokes': {'type': 'cStr'}, 'mask': {'type': 'cStr'}, 'mode': {'type': 'cStr'}, 'cutoff': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'stretch': {'type': 'cBool'}}
        doc = {'pbimage': pbimage, 'outfile': outfile, 'overwrite': overwrite, 'box': box, 'region': region, 'chans': chans, 'stokes': stokes, 'mask': mask, 'mode': mode, 'cutoff': cutoff, 'stretch': stretch}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _pbcor_result = _wrap_image(swig_object=self._swigobj.pbcor(_any_ec(_pc.document['pbimage']), _str_ec(_pc.document['outfile']), _pc.document['overwrite'], _str_ec(_pc.document['box']), _any_ec(_pc.document['region']), _str_ec(_pc.document['chans']), _str_ec(_pc.document['stokes']), _str_ec(_pc.document['mask']), _str_ec(_pc.document['mode']), _pc.document['cutoff'], _pc.document['stretch']))
        return _pbcor_result

    def pv(self, outfile='', start=[ ], end=[ ], center=[ ], length=[ ], pa=[ ], width=int(1), unit='arcsec', overwrite=False, region={ }, chans='', stokes='', mask='', stretch=False, wantreturn=True):
        """Create a position-velocity image by specifying either two points between which a slice is taken in the direction
        coordinate or a center, position angle, and length describing the slice. The spectral extent of the resulting image
        will be that provided by the region specification or the entire spectral range of the input image if no region is
        specified. One may not specify a region in direction space; that is accomplished by specifying the start and end
        points or the center, length, and position angle of the slice. The parameters start and end may be specified as two
        element arrays of numerical values, in which case these values will be interpreted as pixel locations in the input
        image. Alternatively, they may be expressed as arrays of two strings each representing the direction. These strings
        can either represent quantities (eg ["40.5deg", "0.5rad") or be sexigesimal format (eg ["14h20m20.5s","-30d45m25.4s"],
        ["14:20:20.5s","-30.45.25.4"]). In addition, they may be expressed as a single string containing the longitude and
        latitude values and optionally a reference frame value, eg "J2000 14:20:20.5s -30.45.25.4". The center parameter is
        specified in the same way. The length parameter may be specified as a single numerical value, in which case it is
        interpreted as the length in pixels, or a valid quantity, in which case it must have units conformant with the direction
        axes units. The pa (position angle) parameter must be specified as a valid quantity with angular units. The position
        angle is interpreted in the usual astronomical sense; ie measured from north through east. Either start/end or
        center/pa/length must be specified; if a parameter from one of these sets is specified, a parameter from the other set may
        not be specified. In either case, the end points of the segment must fail within the input image, and they both must be at
        least 2 pixels from the edge of the input image to facilite rotation (see below).
        
        One may specify a width, which is the number of pixels centered along and perpendicular
        to the direction slice that are used for averaging along the slice. The width may be specified as an integer, in which
        case it must be positive and odd. Alternatively, it may be specified as a valid quantity string (eg, "4arcsec") or
        quantity record (eg qa.quantity("4arcsec"). In this case, units must be conformant to the direction axes units (usually
        angular units) and the specified quantity will be rounded up, if necessary, to the next highest equivalent odd integer number
        of pixels. The default value of 1 represents no averaging.
        A value of 3 means average one pixel on each side of the slice and the pixel on the slice.
        Note that this width is applied to pixels in the image after it has been rotated (see below for a description
        of the algorithm used). The end points of the specified segment must fail within the input
        image, and they both must be at least 2 pixels from the edge of the input image to facilite rotation (see below).
        
        One may specify the unit for the angular offset axis.
        
        A true value for the wantreturn parameter indicates that an image analysis tool attached to the created
        image should be returned. Nothing is returned if wantreturn is false, but then outfile should be specified
        (unless perhaps you are debugging).
        
        Internally, the image is first rotated, padding first if necessary to include relevant pixels that would otherwise
        be excluded by the rotation operation, so that the slice is horizontal, with the starting pixel left of the
        ending pixel. Then, the pixels within the specified width of the slice are averaged and the resulting image is
        written and/or returned. The output image has a linear coordinate in place of the direction coordinate of the
        input image, and the corresponding axis represents angular offset with the center pixel having a value of 0.
        
        The equivalent coordinate system, with a (usually) rotated direction coordinate (eg, RA and Dec) is written
        to the output image as a table record. It can be retrieved using the table tool as shown in the example below.
        
        """
        schema = {'outfile': {'type': 'cStr'}, 'start': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'end': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'center': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'length': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'pa': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'width': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'unit': {'type': 'cStr'}, 'overwrite': {'type': 'cBool'}, 'region': {'anyof': [{'type': 'cDict'}, {'type': 'cStr'}]}, 'chans': {'type': 'cStr'}, 'stokes': {'type': 'cStr'}, 'mask': {'type': 'cStr'}, 'stretch': {'type': 'cBool'}, 'wantreturn': {'type': 'cBool'}}
        doc = {'outfile': outfile, 'start': start, 'end': end, 'center': center, 'length': length, 'pa': pa, 'width': width, 'unit': unit, 'overwrite': overwrite, 'region': region, 'chans': chans, 'stokes': stokes, 'mask': mask, 'stretch': stretch, 'wantreturn': wantreturn}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _pv_result = _wrap_image(swig_object=self._swigobj.pv(_str_ec(_pc.document['outfile']), _any_ec(_pc.document['start']), _any_ec(_pc.document['end']), _any_ec(_pc.document['center']), _any_ec(_pc.document['length']), _any_ec(_pc.document['pa']), _any_ec(_pc.document['width']), _str_ec(_pc.document['unit']), _pc.document['overwrite'], _any_ec(_pc.document['region']), _str_ec(_pc.document['chans']), _str_ec(_pc.document['stokes']), _str_ec(_pc.document['mask']), _pc.document['stretch'], _pc.document['wantreturn']))
        return _pv_result

    def makearray(self, v=float(0.0), shape=[ int(0) ]):
        """This function takes two arguments. The first argument is the initial
        value for the new array.  The second is a vector giving the lengths of
        the dimensions of the array.
        """
        schema = {'v': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'shape': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'v': v, 'shape': shape}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _makearray_result = _any_dc(self._swigobj.makearray(_pc.document['v'], _pc.document['shape']))
        return _makearray_result

    def isconform(self, other):
        """Returns True if the shape, coordinate system, and axes order of the specified image
        matches the current image.
        """
        schema = {'other': {'type': 'cStr'}}
        doc = {'other': other}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _isconform_result = self._swigobj.isconform(_str_ec(_pc.document['other']))
        return _isconform_result


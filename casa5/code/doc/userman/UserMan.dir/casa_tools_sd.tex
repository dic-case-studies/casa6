%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% STM 2007-04-13  split from previous version
% STM 2007-04-15  for toolguide

\chapter{Single Dish Data Processing}
\label{chapter:sd}

%Version  JM 2007-03-05
%Updated STM 2007-03-07
%Updated STM 2007-04-15

For single-dish spectral calibration and analysis, 
CASA uses the ATNF Spectral Analysis Package (ASAP).  This is
imported as the {\tt sd} tool, and forms the basis for a series
of tasks (the ``SDtasks'') that encapsulate the functionality
within the standard CASA task framework.  ASAP was developed to
support the Australian telescopes such as Mopra, Parkes, and
Tidbinbilla, and we have adapted it for use within CASA for
GBT and eventually ALMA data also.  For details on ASAP, see
the ASAP home page at ATNF: 
\begin{itemize}
   \item \url{http://www.atnf.csiro.au/computing/software/asap/}
\end{itemize}
You can also download the ASAP User Guide and Reference Manual at this
web site.  There is also a brief tutorial.  Note that within CASA,
the ASAP tools are prefaced with {\tt sd.}, e.g. where it
says in the ASAP User Guide to use {\tt scantable} you will use
{\tt sd.scantable} in CASA.  See \S~\ref{section:sd.asap} for more
information on the tools.

All of the ASAP functionality is available with a CASA
installation.  In the following, we outline how to access ASAP
functionality within CASA with the tasks and tools,
and the data flow for standard use cases.

If you run into trouble, be sure to check the list of known issues
and features of ASAP and the SDtasks presented in 
\S~\ref{section:sd.issues} first.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Guidelines for Use of ASAP and SDtasks in CASA}
\label{section:sd.intro}

\subsection{Environment Variables}
\label{section:sd.intro.env}

There are a number of environment variables that the ASAP tools
(and thus the SDtasks) use to help control their operation.
These are described in the ASAP User Guide as being in the 
{\tt .asaprc} file.  Within CASA, these are contained in the
Python dictionary {\tt sd.rcParams} and are accessible through
its keys and values.  For SDtask users, the most important are the
{\tt verbose} parameter controlling the display of detailed
messages from the tools. By default 
\small
\begin{verbatim}
     sd.rcParams['verbose'] = True
\end{verbatim}
\normalsize
and you get lots of messages.  Also
), and the {\tt scantable.storage}
parameter controlling whether scantable operations are done
in memory or on disk.  The default 
\small
\begin{verbatim}
     sd.rcParams['scantable.storage'] = 'memory'
\end{verbatim}
\normalsize
does it in memory (best choice if you have enough), while to
force the scantables to disk use
\small
\begin{verbatim}
     sd.rcParams['scantable.storage'] = 'disk'
\end{verbatim}
\normalsize
which might be necessary to allow processing of large datasets.
See \S~\ref{subsection:sd.asap.environ} for more details on the
ASAP environment variables.

\subsection{Assignment}
\label{section:sd.intro.ass}

Some ASAP methods and function require you to assign that method
to a variable which you can then manipulate.  This includes
{\tt sd.scantable} and {\tt sd.selector}, which make objects.
For example,
\small
\begin{verbatim}
     s = sd.scantable('OrionS_rawACSmod', average=False)
\end{verbatim}
\normalsize

\subsection{Lists}
\label{section:sd.intro.lists}

For lists of scans or IFs, such as in {\tt scanlist} and {\tt
iflist} in the SDtasks, the tasks and functions want a comma-separated 
Python list, e.g.
\small
\begin{verbatim}
     scanlist = [241, 242, 243, 244, 245, 246]
\end{verbatim}
\normalsize
You can use the Python {\tt range} function to generate a list of
consecutive numbers, e.g.
\small
\begin{verbatim}
     scanlist = range(241,247)
\end{verbatim}
\normalsize
giving the same list as above, e.g.
\small
\begin{verbatim}
CASA <3>: scanlist=range(241,247)
CASA <4>: print scanlist
[241, 242, 243, 244, 245, 246]
\end{verbatim}
\normalsize
You can also combine multiple ranges by summing lists
\small
\begin{verbatim}
CASA <5>: scanlist=range(241,247) + range(251,255)
CASA <6>: print scanlist
[241, 242, 243, 244, 245, 246, 251, 252, 253, 254]
\end{verbatim}
\normalsize
Note that in the future, the {\tt sd} tools and SDtasks will use
the same selection language as in the synthesis part of the package.

Spectral regions, such as those for setting masks, are pairs of
min and max values for whatever spectral axis unit is currently
chosen.  These are fed into the tasks and tools as a list of lists,
with each list element a list with the {\tt [min,max]} for that
sub-region, e.g.
\small
\begin{verbatim}
     masklist=[[1000,3000], [5000,7000]].
\end{verbatim}
\normalsize

\subsection{Text}
\label{section:sd.intro.text}

The SDtasks trap leading and trailing whitespace on string parameters
(such as {\tt infile} and {\tt sdfile}), but ASAP does not, so be
careful with setting string parameters.  ASAP is also case-sensitive,
with most parameters being upper-case, such as {\tt ASAP} for the
{\tt sd.scantable.save} file format.  The SDtasks are generally
more forgiving.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Using The ASAP Toolkit Within CASA}
\label{section:sd.asap}

ASAP is included with the CASA installation/build. It is not loaded
upon start-up, however, and must be imported as a standard Python
package. A convenience function exists for importing ASAP along with
a set of prototype tasks for single dish analysis:
\small
\begin{verbatim}
  CASA <1>: asap_init
\end{verbatim}
\normalsize
Once this is done, all of the ASAP functionality is now under the
Python 'sd' tool.  {bf: Note: This means that if you are following
the ASAP cookbook or documentation, all of the commands should be 
invoked with a 'sd.' before the native ASAP command.}

The ASAP interface is essentially the same as that
of the CASA toolkit, that is, there are groups of functionality (aka
tools) which have the ability to operate on your data. Type:

\small
\begin{verbatim}
  CASA <4>: sd.<TAB>
  sd.__class__               sd._validate_bool          sd.list_scans
  sd.__date__                sd._validate_int           sd.mask_and
  sd.__delattr__             sd.asapfitter              sd.mask_not
  sd.__dict__                sd.asaplinefind            sd.mask_or
  sd.__doc__                 sd.asaplog                 sd.merge
  sd.__file__                sd.asaplotbase             sd.os
  sd.__getattribute__        sd.asaplotgui              sd.plf
  sd.__hash__                sd.asapmath                sd.plotter
  sd.__init__                sd.asapplotter             sd.print_log
  sd.__name__                sd.asapreader              sd.quotient
  sd.__new__                 sd.average_time            sd.rc
  sd.__path__                sd.calfs                   sd.rcParams
  sd.__reduce__              sd.calnod                  sd.rcParamsDefault
  sd.__reduce_ex__           sd.calps                   sd.rc_params
  sd.__repr__                sd.commands                sd.rcdefaults
  sd.__setattr__             sd.defaultParams           sd.reader
  sd.__str__                 sd.dosigref                sd.scantable
  sd.__version__             sd.dototalpower            sd.selector
  sd._asap                   sd.fitter                  sd.simple_math
  sd._asap_fname             sd.is_ipython              sd.sys
  sd._asaplog                sd.linecatalog             sd.unique
  sd._is_sequence_or_number  sd.linefinder              sd.version
  sd._n_bools                sd.list_files              sd.welcome
  sd._to_list                sd.list_rcparameters       sd.xyplotter
\end{verbatim}
\normalsize

...to see the list of tools.

In particular, the following are essential for most reduction
sessions: 
\begin{itemize}
   \item {\tt sd.scantable} - the data structure for ASAP and the core
         methods for manipulating the data; allows importing data,
         making data selections, basic operations (averaging,
         baselines, etc) and setting data characteristics (e.g.,
         frequencies, etc).
   \item {\tt sd.selector} - selects a subset of data for subsequent operations
   \item {\tt sd.fitter} - fit data 
   \item {\tt sd.plotter} - plotting facilities (uses {\tt matplotlib})
\end{itemize}

The {\tt scantable} functions are used most often and can be applied
to both the initial scantable and to any spectrum from that scan
table.  Type
\small
\begin{verbatim}
     sd.scantable.<TAB>
\end{verbatim}
\normalsize
(using TAB completion) to see the full list. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Environment Variables}
\label{subsection:sd.asap.environ}

The {\tt asaprc} environment variables are stored in the Python
dictionary {\tt sd.rcParams} in CASA.  This contains a number
of parameters that control how ASAP runs, for both tools and
tasks.  You can see what these are set to by typing at the
CASA prompt:

\small
\begin{verbatim}
  CASA <2>: sd.rcParams
  Out[2]: 
{'insitu': True,
 'plotter.colours': '',
 'plotter.decimate': False,
 'plotter.ganged': True,
 'plotter.gui': True,
 'plotter.histogram': False,
 'plotter.linestyles': '',
 'plotter.panelling': 's',
 'plotter.papertype': 'A4',
 'plotter.stacking': 'p',
 'scantable.autoaverage': True,
 'scantable.freqframe': 'LSRK',
 'scantable.save': 'ASAP',
 'scantable.storage': 'memory',
 'scantable.verbosesummary': False,
 'useplotter': True,
 'verbose': True}
\end{verbatim}
\normalsize

The use of these parameters is described in detail in the
ASAP Users Guide.

You can also change these parameters through the {\tt sd.rc}
function.  The use of this is described in {\tt help sd.rc}:

\small
\begin{verbatim}
CASA <3>: help(sd.rc)
Help on function rc in module asap:

rc(group, **kwargs)
    Set the current rc params.  Group is the grouping for the rc, eg
    for scantable.save the group is 'scantable', for plotter.stacking, the
    group is 'plotter', and so on.  kwargs is a list of attribute
    name/value pairs, eg
    
      rc('scantable', save='SDFITS')
    
    sets the current rc params and is equivalent to
    
      rcParams['scantable.save'] = 'SDFITS'
    
    Use rcdefaults to restore the default rc params after changes.
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Import}
\label{subsection:sd.asap.import}

Data can be loaded into ASAP by using the {\tt scantable} function
which will read a variety of recognized formats (RPFITS, varieties of
SDFITS, and the CASA MeasurementSet). For example:


\small
\begin{verbatim}
  CASA <1>: scans = sd.scantable('OrionS_rawACSmod', average=False)
  Importing OrionS_rawACSmod...
\end{verbatim}
\normalsize

{\bf NOTE:} It is important to use the {\tt average=False} parameter
setting as the calibration routines supporting GBT data require all of
the individual times and phases.

{\bf NOTE:} GBT data may need some pre-processing prior to using
ASAP. In particular, the program which converts GBT raw data into CASA
MeasurementSets tends to proliferate the number of spectral windows
due to shifts in the tracking frequency; this is being worked on by
GBT staff. In addition, GBT SDFITS is currently not readable by ASAP
(in progress).

{\bf NOTE:} The MeasurementSet to scantable conversion is able to deduce
the reference and source data and assigns an '\_r' to the reference
data to comply with the ASAP conventions.

{\bf NOTE:} GBT observing modes are identifiable in scantable in the
name assignment: position switched ('\_ps'), Nod ('\_nod'), and
frequency switched ('\_fs'). These are combined with the reference data
assignment. (For example, the reference data taken in position
switched mode observation are assigned as '\_psr'.)

Use the {\tt summary} function to examine the data and get basic information:

\small
\begin{verbatim}
CASA <8>: scans.summary()
--------------------------------------------------------------------------------
 Scan Table Summary
--------------------------------------------------------------------------------
Beams:         1   
IFs:           26  
Polarisations: 2   (linear)
Channels:      8192

Observer:      Joseph McMullin
Obs Date:      2006/01/19/01:45:58
Project:       AGBT06A_018_01
Obs. Type:     OffOn:PSWITCHOFF:TPWCAL
Antenna Name:  GBT
Flux Unit:     Jy
Rest Freqs:    [4.5490258e+10] [Hz]
Abcissa:       Channel
Selection:     none

Scan Source         Time      Integration       
     Beam    Position (J2000)
          IF       Frame   RefVal          RefPix    Increment   
--------------------------------------------------------------------------------
  20 OrionS_psr     01:45:58    4 x       30.0s
        0    05:15:13.5 -05.24.08.2
            0      LSRK   4.5489354e+10   4096    6104.233
            1      LSRK   4.5300785e+10   4096    6104.233
            2      LSRK   4.4074929e+10   4096    6104.233
            3      LSRK   4.4166215e+10   4096    6104.233
  21 OrionS_ps      01:48:38    4 x       30.0s
        0    05:35:13.5 -05.24.08.2
            0      LSRK   4.5489354e+10   4096    6104.233
            1      LSRK   4.5300785e+10   4096    6104.233
            2      LSRK   4.4074929e+10   4096    6104.233
            3      LSRK   4.4166215e+10   4096    6104.233
  22 OrionS_psr     01:51:21    4 x       30.0s
        0    05:15:13.5 -05.24.08.2
            0      LSRK   4.5489354e+10   4096    6104.233
            1      LSRK   4.5300785e+10   4096    6104.233
            2      LSRK   4.4074929e+10   4096    6104.233
            3      LSRK   4.4166215e+10   4096    6104.233
  23 OrionS_ps      01:54:01    4 x       30.0s
        0    05:35:13.5 -05.24.08.2
            0      LSRK   4.5489354e+10   4096    6104.233
            1      LSRK   4.5300785e+10   4096    6104.233
            2      LSRK   4.4074929e+10   4096    6104.233
            3      LSRK   4.4166215e+10   4096    6104.233
  24 OrionS_psr     02:01:47    4 x       30.0s
        0    05:15:13.5 -05.24.08.2
           12      LSRK   4.3962126e+10   4096   6104.2336
           13      LSRK    4.264542e+10   4096   6104.2336
           14      LSRK    4.159498e+10   4096   6104.2336
           15      LSRK   4.3422823e+10   4096   6104.2336
  25 OrionS_ps      02:04:27    4 x       30.0s
        0    05:35:13.5 -05.24.08.2
           12      LSRK   4.3962126e+10   4096   6104.2336
           13      LSRK    4.264542e+10   4096   6104.2336
           14      LSRK    4.159498e+10   4096   6104.2336
           15      LSRK   4.3422823e+10   4096   6104.2336
  26 OrionS_psr     02:07:10    4 x       30.0s
        0    05:15:13.5 -05.24.08.2
           12      LSRK   4.3962126e+10   4096   6104.2336
           13      LSRK    4.264542e+10   4096   6104.2336
           14      LSRK    4.159498e+10   4096   6104.2336
           15      LSRK   4.3422823e+10   4096   6104.2336
  27 OrionS_ps      02:09:51    4 x       30.0s
        0    05:35:13.5 -05.24.08.2
           12      LSRK   4.3962126e+10   4096   6104.2336
           13      LSRK    4.264542e+10   4096   6104.2336
           14      LSRK    4.159498e+10   4096   6104.2336
           15      LSRK   4.3422823e+10   4096   6104.2336
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Scantable Manipulation}
\label{subsection:sd.asap.scantable}

Within ASAP, data is stored in a {\tt scantable}, which holds all of the
observational information and provides functionality to manipulate the
data and information. The building block of a {\tt scantable} is an
integration which is a single row of a scantable. Each row contains
just one spectrum for each beam, IF and polarization.  

Once you have a {\tt scantable} in ASAP, you can select a subset of the
data based on scan numbers, sources, or types of scan; note that each
of these selections returns a new 'scantable' with all of the 
underlying functionality: 

\small
\begin{verbatim}
  CASA <5>: scan27=scans.get_scan(27)                 # Get the 27th scan
  CASA <6>: scans20to24=scans.get_scan(range(20,25))  # Get scans 20 - 24
  CASA <7>: scans_on=scans.get_scan('*_ps')           # Get ps scans on source
  CASA <8>: scansOrion=scans.get_scan('Ori*')         # Get all Orion scans
\end{verbatim}
\normalsize

To copy a scantable, do:

\small
\begin{verbatim}
  CASA <15>: ss=scans.copy()
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Data Selection}
\label{subsubsection:sd.asap.scantable.select}

In addition to the basic data selection above, data can be selected
based on IF, beam, polarization, scan number as well as values such as
Tsys.  To make a selection you create a {\tt selector} object which
you then define with various selection functions, e.g.,

\small
\begin{verbatim}
  sel = sd.selector()      # initialize a selector object
                           # sel.<TAB> will list all options
  sel.set_ifs(0)           # select only the first IF of the data
  scans.set_selection(sel) # apply the selection to the data
  print scans              # shows just the first IF
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{State Information}
\label{subsubsection:sd.asap.scantable.state}

Some properties of a scantable apply to all of the data, such as
example, spectral units, frequency frame, or Doppler type. This
information can be set using the {\tt scantable} \_set\_xxxx\_
methods.  These are currently:
\small
\begin{verbatim}
CASA <1>: sd.scantable.set_<TAB>
sd.scantable.set_dirframe    sd.scantable.set_fluxunit    sd.scantable.set_restfreqs   
sd.scantable.set_doppler     sd.scantable.set_freqframe   sd.scantable.set_selection   
sd.scantable.set_feedtype    sd.scantable.set_instrument  sd.scantable.set_unit
\end{verbatim}
\normalsize

For example, {\tt sd.scantable.set\_fluxunit} sets the default units
that describe the flux axis:
\small
\begin{verbatim}
  scans.set_fluxunit('K')  # Set the flux unit for data to Kelvin
\end{verbatim}
\normalsize
Choices are {\tt 'K'} or {\tt 'Jy'}.
Note: the scantable.set\_fluxunit function only changes the {\bf name}
of the current fluxunit. To change fluxunits, use 
{\tt scantable.convert\_flux} as described in 
\S~\ref{subsubsection:sd.asap.calib.fluxunit}
instead (currently you need to do some gymnastics for GBT or non-AT
telescopes).

Use {\tt sd.scantable.set\_unit} to set the units to be used on 
the spectral axis:
\small
\begin{verbatim}
  scans.set_unit('GHz')    # Use GHZ as the spectral axis for plots
\end{verbatim}
\normalsize
The choices for the units are {\tt 'km/s'}, {\tt 'channel'}, or
{\tt '*Hz'} (e.g. {\tt 'GHz'}, {\tt 'MHz'}, {\tt 'kHz'}, {\tt 'Hz'}).
This does the proper conversion using the current frame and doppler
reference as can be seen when the spectrum is plotted.

You can use {\tt sd.scantable.set\_freqframe}
to set the frame in which the freqency (spectral) axis is defined:
\small
\begin{verbatim}
CASA <2>: help(sd.scantable.set_freqframe)
Help on method set_freqframe in module asap.scantable:

set_freqframe(self, frame=None) unbound asap.scantable.scantable method
    Set the frame type of the Spectral Axis.
    Parameters:
        frame:   an optional frame type, default 'LSRK'. Valid frames are:
                 'REST', 'TOPO', 'LSRD', 'LSRK', 'BARY',
                 'GEO', 'GALACTO', 'LGROUP', 'CMB'
    Examples:
        scan.set_freqframe('BARY')
\end{verbatim}
\normalsize
The most useful choices here are {\tt frame = 'LSRK'} (the default for
the function) and {\tt frame = 'TOPO'} (what the GBT actually observes
in).  Note that the {\tt 'REST'} option is not yet available.
The doppler frame is set with {\tt sd.scantable.set\_doppler}:
\small
\begin{verbatim}
CASA <3>: help(sd.scantable.set_doppler)
Help on method set_doppler in module asap.scantable:

set_doppler(self, doppler='RADIO') unbound asap.scantable.scantable method
    Set the doppler for all following operations on this scantable.
    Parameters:
        doppler:    One of 'RADIO', 'OPTICAL', 'Z', 'BETA', 'GAMMA'
\end{verbatim}
\normalsize

Finally, there are a number of functions to query the state of the
scantable.  These can be found in the usual way:
\small
\begin{verbatim}
CASA <4>: sd.scantable.get<TAB>
sd.scantable.get_abcissa       sd.scantable.get_restfreqs     sd.scantable.getbeamnos
sd.scantable.get_azimuth       sd.scantable.get_scan          sd.scantable.getcycle
sd.scantable.get_column_names  sd.scantable.get_selection     sd.scantable.getif
sd.scantable.get_direction     sd.scantable.get_sourcename    sd.scantable.getifnos
sd.scantable.get_elevation     sd.scantable.get_time          sd.scantable.getpol
sd.scantable.get_fit           sd.scantable.get_tsys          sd.scantable.getpolnos
sd.scantable.get_fluxunit      sd.scantable.get_unit          sd.scantable.getscan
sd.scantable.get_parangle      sd.scantable.getbeam           sd.scantable.getscannos
\end{verbatim}
\normalsize
These include functions to get the current values of the states
mentioned above, as well as
as methods to query the number of scans, IFs, and polarizations
in the scantable, and their designations.  See the
inline help for the individual functions for more information.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Masks}
\label{subsubsection:sd.asap.scantable.masks}

Several functions (fitting, baseline subtraction, statistics, etc) may
be run on a range of channels (or velocity/frequency ranges). You can
create masks of this type using the {\tt create\_mask} function:

\small
\begin{verbatim}
  # spave = an averaged spectrum
  spave.set_unit('channel')
  rmsmask=spave.create_mask([5000,7000])   # create a region over channels 5000-7000
  rms=spave.stats(stat='rms',mask=rmsmask) # get rms of line free region

  rmsmask=spave.create_mask([3000,4000],invert=True) # choose the region 
                                                     # *excluding* the specified channels
\end{verbatim}
\normalsize

The mask is stored in a simple Python variable (a list) and so may be
manipulated using an Python facilities. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Scantable Management}
\label{subsubsection:sd.asap.scantable.management}

{\tt scantables} can be listed via:

\small
\begin{verbatim}
  CASA <33>: sd.list_scans()
  The user created scantables are:
  ['scans20to24', 's', 'scan27']
\end{verbatim}
\normalsize

As every {\tt scantable} will consume memory, if you will not use it
any longer, you can explicitly remove it via:

\small
\begin{verbatim}
  del <scantable name>
\end{verbatim}
\normalsize
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Scantable Mathematics}
\label{subsubsection:sd.asap.scantable.scanmath}

It is possible to do simple mathematics directly on {\tt scantables}
from the CASA command line using the $+,-,*,/$ operators as well as
their cousins $+=, -=, *=, /=$

\small
\begin{verbatim}
  CASA <10>: scan2=scan1+2.0 # add 2.0 to data 
  CASA <11>: scan *= 1.05    # scale spectrum by 1.05 
\end{verbatim}
\normalsize

{\bf NOTE:} mathematics between two scantables is not currently
available in ASAP.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Scantable Save and Export}
\label{subsubsection:sd.asap.scantable.export}

ASAP can save scantables in a variety of formats, suitable for reading
into other packages. The formats are: 

\begin{itemize}
    \item ASAP -- This is the internal format used for ASAP. It is the only
     format that allows the user to restore the data, fits, etc,
     without loosing any information. As mentioned before, the ASAP
     scantable is a CASA Table (memory-based table). This function
     just converts it to a disk-based table. You can access this with
     the CASA {\tt browsetable} task or any other CASA table tasks. 

   \item SDFITS -- The Single Dish FITS format. This format was designed
     for interchange between packages but few packages can actually
     read it. 

   \item ASCII -- A simple text based format suitable for the user to
     process using Python or other means. 

   \item MeasurementSet (V2: CASA format) -- Saves the data in a
     MeasurementSet. All CASA tasks which use an MS should work on
     this. 
\end{itemize}

\small
\begin{verbatim}
  scans.save('output_filename','format'), e.g.,
  CASA <19>: scans.save('FLS3a_calfs','MS2')
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Calibration}
\label{subsection:sd.asap.calib}

For some observatories, the calibration happens transparently as the
input data contains the Tsys measurements taken during the
observations. The nominal 'Tsys' values may be in Kelvin or
Jansky. The user may wish to apply a Tsys correction or apply
gain-elevation and opacity corrections.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Tsys scaling}
\label{subsubsection:sd.asap.calib.tsys}

If the nominal Tsys measurement at the telescope is wrong due to
incorrect calibration, the {\tt scale} function allows it to be corrected.  

\small
\begin{verbatim}
  scans.scale(1.05,tsys=True) # by default only the spectra are scaled
                              # (and not the corresponding Tsys) unless tsys=True
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Flux and Temperature Unit Conversion}
\label{subsubsection:sd.asap.calib.fluxunit}

To convert measurements in Kelvin to Jansky (and vice versa), the {\tt
convert\_flux} function may be used. This converts and scales the data
to the selected units. The user may need to supply the aperture
efficiency, telescope diameter or the Jy/K factor

\small
\begin{verbatim}
  scans.convert_flux(eta=0.48, d=35.) # Unknown telescope
  scans.convert_flux(jypk=15) # Unknown telecope (alternative)
  scans.convert_flux() # known telescope (mostly AT telescopes)
  scans.convert_flux(eta=0.48) # if telescope diameter known
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Gain-Elevation and Atmospheric Optical Depth Corrections}
\label{subsubsection:sd.asap.calib.gain}

At higher frequencies, it is important to make corrections for
atmospheric opacity and gain-elevation effects. {\bf NOTE:} Currently,
the MS to scantable conversion does not adequately populate the
azimuth and elevation in the {\tt scantable}. As a result, one must
calculate these via:

\small
\begin{verbatim}
  scans.recalc_azel()
  Computed azimuth/elevation using 
  Position: [882590, -4.92487e+06, 3.94373e+06]
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   ...
\end{verbatim}
\normalsize


Once you have the correct Az/El, you can correct for a {\it known}
opacity by:

\small
\begin{verbatim}
  scans.opacity(tau=0.09)  # Opacity from which the correction factor: 
                           # exp(tau*zenith-distance)
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Calibration of GBT data}
\label{subsubsection:sd.asap.calib.gbt}

Data from the GBT is uncalibrated and comes as sets of integrations
representing the different phases within a calibration cycle (e.g., on
source, calibration on, on source, calibration off, on reference,
calibration on; on reference, calibration off). Currently, there are a
number of routines emulating the standard GBT calibration (in GBTIDL):
\begin{itemize}
   \item calps - calibrate position switched data
   \item calfs - calibrate frequency switched data
   \item calnod - calibration nod (beam switch) data
\end{itemize}

All these routines calibrate the spectral data to antenna temperature
adopting the GBT calibration method as described in the
GBTIDL calibration document available at: 
\begin{itemize}
   \item \url{http://wwwlocal.gb.nrao.edu/GBT/DA/gbtidl/gbtidl_calibration.pdf}
\end{itemize}
There are two basic steps:

First: determine system temperature using a noise tube calibrator
(sd.dototalpower()) 

For each integration, the system temperature is calculated from
CAL noise on/off data as:

$ T_{sys} = T_{cal}$ x 
$\frac{<ref_{caloff}>}{<ref_{calon} - ref_{caloff}>} + \frac{T_{cal}}{2} $

{\tt ref} refers to reference data and the spectral data are averaged
across the bandpass.  Note that the central 80\% of the spectra are
used for the calculation.

Second, determine antenna temperature (sd.dosigref())

The antenna temperature for each channel is calculated as:

$ T_a(\nu) = T_{sys}$ x 
$\frac{sig(\nu) - ref(\nu)}{ref(\nu)}$

where $sig = \frac{1}{2}(sig_{calon} + sig_{caloff})$, 
      $ref = \frac{1}{2}(sig_{calon} + sig_{caloff}).$


Each calibration routine may be used as:


\small
\begin{verbatim}
  scans=sd.scantable('inputdata',False)         # create a scantable called 'scans'
  calibrated_scans = sd.calps(scans,[scanlist]) # calibrate scantable with position-switched 
                                                # scheme
\end{verbatim}
\normalsize


{\bf Note:} For calps and calnod, the scanlist must be scan pairs in
correct order as these routines only do miminum checking.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Averaging}
\label{subsubsection:sd.asap.averaging}

One can average polarizations in a scantable using the
{\tt sd.scantable.average\_pol} function:
\small
\begin{verbatim}
  averaged_scan = scans.average_pol(mask,weight)

  where:
    Parameters:
        mask:        An optional mask defining the region, where the
                     averaging will be applied. The output will have all
                     specified points masked.
        weight:      Weighting scheme. 'none' (default), 'var' (1/var(spec)
                     weighted), or 'tsys' (1/Tsys**2 weighted)

    Example:

  spave = stave.average_pol(weight='tsys')
\end{verbatim}
\normalsize

One can also average scans over time using {\tt sd.average\_time}:
\small
\begin{verbatim}
  sd.average_time(scantable,mask,scanav,weight,align)

  where:

    Parameters:
        one scan or comma separated  scans
        mask:     an optional mask (only used for 'var' and 'tsys' weighting)
        scanav:   True averages each scan separately.
                  False (default) averages all scans together,
        weight:   Weighting scheme.
                    'none'     (mean no weight)
                    'var'      (1/var(spec) weighted)
                    'tsys'     (1/Tsys**2 weighted)
                    'tint'     (integration time weighted)
                    'tintsys'  (Tint/Tsys**2)
                    'median'   ( median averaging)
        align:    align the spectra in velocity before averaging. It takes
                  the time of the first spectrum in the first scantable
                  as reference time.
    Example:
  
  stave = sd.average_time(scans,weight='tintsys')
\end{verbatim}
\normalsize

Note that alignment of the velocity frame should be done before
averaging if the time spanned by the scantable is 
long enough.  This is done through the {\tt align=True} option in
{\tt sd.average\_time}, or explicity through the
{\tt sd.scantable.freq\_align} function, e.g.
\small
\begin{verbatim}
CASA <62>: sc = sd.scantable('orions_scan20to23_if0to3.asap',False)
CASA <63>: sc.freq_align()
Aligned at reference Epoch 2006/01/19/01:49:23 (UTC) in frame LSRK
CASA <64>: av = sd.average_times(sc)
\end{verbatim}
\normalsize

The time averaging can also be applied to multiple scantables.  This
might have been taken on different days, for example.  The
{\tt sd.average\_time} function takes multiple scantables as input.
However, if taken at significantly different times (different days for
example) then {\tt sd.scantable.freq\_align} must be used to align
the velocity scales to the same time, e.g.
\small
\begin{verbatim}
CASA <65>: sc1 = sd.scantable('orions_scan21_if0to3.asap',False)
CASA <66>: sc2 = sd.scantable('orions_scan23_if0to3.asap',False)
CASA <67>: sc1.freq_align()
Aligned at reference Epoch 2006/01/19/01:49:23 (UTC) in frame LSRK
CASA <68>: sc2.freq_align(reftime='2006/01/19/01:49:23')
Aligned at reference Epoch 2006/01/19/01:54:46 (UTC) in frame LSRK
CASA <69>: scav = sd.average_times(sc1,sc2)
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spectral Smoothing}
\label{subsection:sd.asap.smoothing}

Smoothing on data can be done as follows:

\small
\begin{verbatim}
  scantable.smooth(kernel,    # type of smoothing: 'hanning' (default), 'gaussian', 'boxcar'
          width,              # width in pixls (ignored for hanning); FWHM for gaussian.
          insitu)             # if False (default), do smoothing in-situ; otherwise, 
                              # make new scantable

  Example:
  # spave is an averaged spectrum
  spave.smooth('boxcar',5)    # do a 5 pixel boxcar smooth on the spectrum
  sd.plotter.plot(spave)      # should see smoothed spectrum
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Baseline Fitting}
\label{subsection:sd.asap.BLfitting}

The function {\tt sd.scantable.poly\_baseline} carries out a
baseline fit, given an mask of channels (if desired):
\small
\begin{verbatim}
  msk=scans.create_mask([100,400],[600,900])
  scans.poly_baseline(msk,order=1)
\end{verbatim}
\normalsize
This will fit a first order polynomial to the selected channels and
subtract this polynomial from the full spectrum.

The {\tt auto\_poly\_baseline} function can be used to automatically
baseline your data without having to specify channel ranges for the
line free data. It automatically figures out the line-free emission
and fits a polynomial baseline to that data. The user can use masks to
fix the range of channels or velocity range for the fit as well as
mark the band edge as invalid:


\small
\begin{verbatim}
  scans.auto_poly_baseline(mask,edge,order,threshold,chan_avg_limit,plot,insitu):

    Parameters:
        mask:       an optional mask retreived from scantable
        edge:       an optional number of channel to drop at
                    the edge of spectrum. If only one value is
                    specified, the same number will be dropped from
                    both sides of the spectrum. Default is to keep
                    all channels. Nested tuples represent individual
                    edge selection for different IFs (a number of spectral
                    channels can be different)
        order:      the order of the polynomial (default is 0)
        threshold:  the threshold used by line finder. It is better to
                    keep it large as only strong lines affect the
                    baseline solution.
        chan_avg_limit:
                    a maximum number of consequtive spectral channels to
                    average during the search of weak and broad lines.
                    The default is no averaging (and no search for weak
                    lines). If such lines can affect the fitted baseline
                    (e.g. a high order polynomial is fitted), increase this
                    parameter (usually values up to 8 are reasonable). Most
                    users of this method should find the default value
                    sufficient.
        plot:       plot the fit and the residual. In this each
                    indivual fit has to be approved, by typing 'y'
                    or 'n'
        insitu:     if False a new scantable is returned.
                    Otherwise, the scaling is done in-situ
                    The default is taken from .asaprc (False)

    Example:
  scans.auto_poly_baseline(order=2,threshold=5)
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Line Fitting}
\label{subsection:sd.asap.LINEfitting}

Multi-component Gaussian fitting is available. This is done by
creating a fitting object, specifying fit parameters and finally
fitting the data. Fitting can be done on a {\tt scantable} selection
or an entire {\tt scantable} using the {\tt auto\_fit} function.

\small
\begin{verbatim}
  #spave is an averaged spectrum
  f=sd.fitter()                           # create fitter object
  msk=spave.create_mask([3928,4255])      # create mask region around line
  f.set_function(gauss=1)                 # set a single gaussian component
  f.set_scan(spave,msk)                   # set the scantable and region
                                          # 
                                          # Automatically guess start values
  f.fit()                                 # fit 
  f.plot(residual=True)                   # plot residual
  f.get_parameters()                      # retrieve fit parameters
  #   0: peak = 0.786 K , centre = 4091.236 channel, FWHM = 70.586 channel
  #      area = 59.473 K channel
  f.store_fit('orions_hc3n_fit.txt')      # store fit
                                          #
                                          # To specify initial guess:
  f.set_function(gauss=1)                 # set a single gaussian component
  f.set_gauss_parameters(0.4,4100,200\    # set initial guesses for Gaussian
        ,component=0)                     #   for first component (0)
                                          #   (peak,center,fwhm)
                                          #
                                          # For multiple components set
                                          # initial guesses for each, e.g.
  f.set_function(gauss=2)                 # set two gaussian components
  f.set_gauss_parameters(0.4,4100,200\    # set initial guesses for Gaussian
        ,component=0)                     #   for first component (0)
  f.set_gauss_parameters(0.1,4200,100\    # set initial guesses for Gaussian
        ,component=1)                     #   for second component (1)

\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Plotting}
\label{subsection:sd.asap.plotting}

The ASAP plotter uses the same Python matplotlib library as in CASA
(for x-y plots). It is accessed via the: 

\small
\begin{verbatim}
   sd.plotter<TAB>        # see all functions (omitted here)
  sd.plotter.plot(scans) # the workhorse function
  sd.plotter.set<TAB>
  sd.plotter.set_abcissa     sd.plotter.set_legend      sd.plotter.set_range
  sd.plotter.set_colors      sd.plotter.set_linestyles  sd.plotter.set_selection
  sd.plotter.set_colours     sd.plotter.set_mask        sd.plotter.set_stacking
  sd.plotter.set_font        sd.plotter.set_mode        sd.plotter.set_title
  sd.plotter.set_histogram   sd.plotter.set_ordinate    
  sd.plotter.set_layout      sd.plotter.set_panelling   
\end{verbatim}
\normalsize


Spectra can be plotted at any time, and it will attempt to do the
correct layout depending on whether it is a set of scans or a single
scan. 

The details of the plotter display (matplotlib) are detailed in the
earlier section. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Single Dish Spectral Analysis Use Case With ASAP Toolkit}
\label{subsection:sd.asap.usecase}

Below is a script that illustrates how to reduce single dish data
using ASAP within CASA.  First a summary of the dataset is given and
then the script.

\small
\begin{verbatim}
#           MeasurementSet Name:  /home/rohir3/jmcmulli/SD/OrionS_rawACSmod      MS Version 2
#
# Project: AGBT06A_018_01
# Observation: GBT(1 antennas)
#
#Data records: 256       Total integration time = 1523.13 seconds
#   Observed from   01:45:58   to   02:11:21
#
#Fields: 4
#  ID   Name          Right Ascension  Declination   Epoch
#  0    OrionS        05:15:13.45      -05.24.08.20  J2000
#  1    OrionS        05:35:13.45      -05.24.08.20  J2000
#  2    OrionS        05:15:13.45      -05.24.08.20  J2000
#  3    OrionS        05:35:13.45      -05.24.08.20  J2000
#
#Spectral Windows:  (8 unique spectral windows and 1 unique polarization setups)
#  SpwID  #Chans Frame Ch1(MHz)    Resoln(kHz) TotBW(kHz)  Ref(MHz)    Corrs
#  0        8192 LSRK  45464.3506  6.10423298  50005.8766  45489.3536  RR  LL HC3N
#  1        8192 LSRK  45275.7825  6.10423298  50005.8766  45300.7854  RR  LL HN15CO
#  2        8192 LSRK  44049.9264  6.10423298  50005.8766  44074.9293  RR  LL CH3OH
#  3        8192 LSRK  44141.2121  6.10423298  50005.8766  44166.2151  RR  LL HCCC15N
#  12       8192 LSRK  43937.1232  6.10423356  50005.8813  43962.1261  RR  LL HNCO
#  13       8192 LSRK  42620.4173  6.10423356  50005.8813  42645.4203  RR  LL H15NCO
#  14       8192 LSRK  41569.9768  6.10423356  50005.8813  41594.9797  RR  LL HNC18O
#  15       8192 LSRK  43397.8198  6.10423356  50005.8813  43422.8227  RR  LL SiO

# Scans: 21-24  Setup 1 HC3N et al
# Scans: 25-28  Setup 2 SiO et al

casapath=os.environ['AIPSPATH']

#ASAP script                            # COMMENTS                                      
#-------------------------------------- ----------------------------------------------- 
import asap as sd                       #import ASAP package into CASA                  
                                        #Orion-S (SiO line reduction only)
                                        #Notes:
                                        #scan numbers (zero-based) as compared to GBTIDL

                                        #changes made to get to OrionS_rawACSmod
                                        #modifications to label sig/ref positions
os.environ['AIPSPATH']=casapath         #set this environment variable back - ASAP changes it


s=sd.scantable('OrionS_rawACSmod',False)#load the data without averaging                
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{scantable}{5}
\caption{\label{fig:scantable} Multi-panel display of the
  scantable. There are two plots per scan indicating the \_psr
  (reference position data) and the \_ps (source data).} 
\hrulefill
\end{figure}
 
\small
\begin{verbatim}
s.summary()                             #summary info                                   
s.set_fluxunit('K')                     # make 'K' default unit
scal=sd.calps(s,[20,21,22,23])          # Calibrate HC3N scans                          
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{scal}{5}
\caption{\label{fig:scal} Two panel plot of the calibrated
  spectra. The GBT data has a separate scan for the SOURCE and
  REFERENCE positions so scans 20,21,22 and 23 result in these two
  spectra.} 
\hrulefill
\end{figure}

\small
\begin{verbatim}
scal.recalc_azel()                      # recalculate az/el to                          
scal.opacity(0.09)                      # do opacity correction                         
sel=sd.selector()                       # Prepare a selection
sel.set_ifs(0)                          # select HC3N IF
scal.set_selection(sel)                 # get this IF
stave=sd.average_time(scal,weight='tintsys')    # average in time
spave=stave.average_pol(weight='tsys')  # average polarizations;Tsys-weighted (1/Tsys**2) average
sd.plotter.plot(spave)                  # plot

spave.smooth('boxcar',5)                # boxcar 5                                      
spave.auto_poly_baseline(order=2)       # baseline fit order=2                          
sd.plotter.plot(spave)                  # plot                                          

spave.set_unit('GHz')                                                                   
sd.plotter.plot(spave)
sd.plotter.set_histogram(hist=True)       # draw spectrum using histogram                 
sd.plotter.axhline(color='r',linewidth=2) # zline                                       
sd.plotter.save('orions_hc3n_reduced.eps')# save postscript spectrum                    
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{spave}{5}
\caption{\label{fig:spave} Calibrated spectrum with a line at zero (using histograms).}
\hrulefill
\end{figure}
 
\small
\begin{verbatim}
spave.set_unit('channel')                                                               
rmsmask=spave.create_mask([5000,7000])  # get rms of line free regions                  
rms=spave.stats(stat='rms',mask=rmsmask)#  rms
                                        #---------------------------------------------- 
                                        #Scan[0] (OrionS_ps) Time[2006/01/19/01:52:05]: 
                                        # IF[0] = 0.048
                                        #----------------------------------------------
                                        # LINE
linemask=spave.create_mask([3900,4200])
max=spave.stats('max',linemask)         #  IF[0] = 0.918
sum=spave.stats('sum',linemask)         #  IF[0] = 64.994
median=spave.stats('median',linemask)   #  IF[0] = 0.091
mean=spave.stats('mean',linemask)       #  IF[0] = 0.210
                                                                                        
                                                                                        
                                                                                        
                                                                                        
                                        # Fitting
spave.set_unit('channel')               # set units to channel                          
sd.plotter.plot(spave)                  # plot spectrum
f=sd.fitter()
msk=spave.create_mask([3928,4255])      # create region around line                     
f.set_function(gauss=1)                 # set a single gaussian component               
f.set_scan(spave,msk)                   # set the data and region for the fitter        
f.fit()                                 # fit                                           
f.plot(residual=True)                   # plot residual
\end{verbatim}
\normalsize

% \begin{figure}[h!]
% \pngname{gaussfit}{4}
% \caption{\label{fig:gaussfit} Plot of fit and residual.}
% \hrulefill
% \end{figure}

\small
\begin{verbatim}
f.get_parameters()                      # retrieve fit parameters
#   0: peak = 0.786 K , centre = 4091.236 channel, FWHM = 70.586 channel
#      area = 59.473 K channel
                                                                                        
                                                                                        
                                                                                        
                                                                                        
                                                                                        
                                                                                        

f.store_fit('orions_hc3n_fit.txt')      # store fit                                     

# Save the spectrum
spave.save('orions_hc3n_reduced','ASCII',True)  # save the spectrum                     
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Single Dish Imaging}
\label{section:sd.imaging}

Single dish imaging is supported within CASA using standard
tasks and tools. The data must be in the MeasurementSet format. Once
there, you can use the {\tt sdgrid} task or the {\tt im} (imager) tool
to create images:

Tool example:

\small
\begin{verbatim}
  scans.save('outputms','MS2')                    # Save your data from ASAP into an MS

  im.open('outputms')                             # open the data set
  im.selectvis(nchan=901,start=30,step=1,         # choose a subset of the dataa   
     spwid=0,field=0)                             # (just the key emission channels) 
  dir='J2000 17:18:29 +59.31.23'                  # set map center                
  im.defineimage(nx=150,cellx='1.5arcmin',        # define image parameters
     phasecenter=dir,mode='channel',start=30,     # (note it assumes symmetry if ny,celly 
     nchan=901,step=1)                            #  aren't specified)
                                                                       
  im.setoptions(ftmachine='sd',cache=1000000000)  # choose SD gridding                
  im.setsdoptions(convsupport=4)                  # use this many pixels to support the 
                                                  # gridding function used
                                                  # (default=prolate spheroidal wave function)
  im.makeimage(type='singledish',                 # make the image
     image='FLS3a_HI.image') 
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Single Dish Imaging Use Case With ASAP Toolkit}
\label{subsection:sd.imaging.usecase}

Again, the data summary and then the script is given below. 

\small
\begin{verbatim}
# Project: AGBT02A_007_01
# Observation: GBT(1 antennas)
# 
#   Telescope Observation Date    Observer       Project
#   GBT       [                   4.57539e+09, 4.5754e+09]Lockman        AGBT02A_007_01
#   GBT       [                   4.57574e+09, 4.57575e+09]Lockman        AGBT02A_007_02
#   GBT       [                   4.5831e+09, 4.58313e+09]Lockman        AGBT02A_031_12
# 
# Thu Feb 1 23:15:15 2007    NORMAL ms::summary:
# Data records: 76860       Total integration time = 7.74277e+06 seconds
#    Observed from   22:05:41   to   12:51:56
# 
# Thu Feb 1 23:15:15 2007    NORMAL ms::summary:
# Fields: 2
#   ID   Name          Right Ascension  Declination   Epoch
#   0    FLS3a         17:18:00.00      +59.30.00.00  J2000
#   1    FLS3b         17:18:00.00      +59.30.00.00  J2000
# 
# Thu Feb 1 23:15:15 2007    NORMAL ms::summary:
# Spectral Windows:  (2 unique spectral windows and 1 unique polarization setups)
#   SpwID  #Chans Frame Ch1(MHz)    Resoln(kHz) TotBW(kHz)  Ref(MHz)    Corrs
#   0        1024 LSRK  1421.89269  2.44140625  2500        1420.64269  XX  YY
#   1        1024 LSRK  1419.39269  2.44140625  2500        1418.14269  XX  YY


# FLS3 data calibration
# this is calibration part of FLS3 data
#
casapath=os.environ['AIPSPATH']
import asap as sd
os.environ['AIPSPATH']=casapath

print '--Import--'

s=sd.scantable('FLS3_all_newcal_SP',false)         # read in MeasurementSet

print '--Split--'

# splitting the data for each field
s0=s.get_scan('FLS3a*')                            # split the data for the field of interest
s0.save('FLS3a_HI.asap')                           # save this scantable to disk (asap format)
del s0                                             # free up memory from scantable

print '--Calibrate--'
s=sd.scantable('FLS3a_HI.asap')                    # read in scantable from disk (FLS3a)
s.set_fluxunit('K')                                # set the brightness units to Kelvin
scanns = s.getscannos()                            # get a list of scan numbers
sn=list(scanns)                                    # convert it to a list
print "No. scans to be processed:", len(scanns)

res=sd.calfs(s,sn)                                 # calibrate all scans listed using frequency 
                                                   # switched calibration method

print '--Save calibrated data--'
res.save('FLS3a_calfs', 'MS2')                     # Save the dataset as a MeasurementSet

print '--Image data--'
                                                                
im.open('FLS3a_calfs')                             # open the data set
im.selectvis(nchan=901,start=30,step=1,            # choose a subset of the dataa   
spwid=0,field=0)                                   # (just the key emission channels)                 
dir='J2000 17:18:29 +59.31.23'                     # set map center                
im.defineimage(nx=150,cellx='1.5arcmin',           # define image parameters
phasecenter=dir,mode='channel',start=30,           # (note it assumes symmetry if ny,celly 
nchan=901,step=1)                                  #  aren't specified)
                                                                       
im.setoptions(ftmachine='sd',cache=1000000000)     # choose SD gridding                
im.setsdoptions(convsupport=4)                     # use this many pixels to support the 
                                                   # gridding function used       
                                                   # (default=prolate spheroidal wave function)  
im.makeimage(type='singledish',image='FLS3a_HI.image') # make the image
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{HI_cube}{7}
\caption{\label{fig:HI_cube} FLS3a HI emission. The display
  illustrates the visualization of the data cube (left) and the
  profile display of the cube at the cursor location (right); the
  Tools menu of the Viewer Display Panel has a Spectral Profile button
  which brings up this display. By default, it grabs the left-mouse
  button. Pressing down the button and moving in the display will show
  the profile variations. }
\hrulefill
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Known Issues, Problems, Deficiencies and Features}
\label{section:sd.issues}

The Single-Dish calibration and analysis package within CASA is still
very much under development.  Not surprisingly,
there are a number of issues with ASAP that are known and
are under repair.  Some of these are non-obvious "features" of the way
ASAP or {\tt sd} is implemented, or limitations of the current Python
tasking environment.  Some are functions that have yet to be
implemented.  These currently include: 

\begin{enumerate}

\item {\tt sd.plotter}

  Currently you can get hardcopy only after making a viewed plot.
  Ideally, ASAP should allow you to choose the device for plotting
  when you set up the plotter.

  Multi-panel plotting is poor.  Currently you can only add things
  (like lines, text, etc.) to the first panel.  Also,
  {\tt sd.plotter.set\_range()} sets the same range for multiple panels,
  while we would like it to be able to set the range for each independently,
  including the default ranges.

  The appearance of the plots need to be made a lot better.  In
  principle matplotlib can make "publication quality" figures, but in
  practice you have to do alot of work to make it do that, and our plots 
  are not good.

  The sd.plotter object remembers things throughout the session
  and thus can easily get confused.  For example you have to
  reset the range {\tt sd.plotter.set\_range()} if you have ever set it
  manually.  This is not always the expected behavior but is a consequence
  of having {\tt sd.plotter} be its own object that you feed data and
  commands to.

  Eventually we would like the capability to interactively set things
  using the plots, like select frequency ranges, identify lines,
  start fitting.

\item {\tt sd.selector}

  The selector object only allows one selection of each type.  It would be 
  nice to be able to make a union of selections (without resorting to query)
  for the {\tt set\_name} - note that the others like scans and IFs work off
  lists which is fine.  Should make {\tt set\_name} work off lists of names.

\item {\tt sd.scantable}

  There is no useful inline help on the scantable constructor
  when you do {\tt help sd.scantable}, nor in {help sd}.

  The inline help for scantable.summary claims that there is
  a verbose parameter, but there is not.  The scantable.verbosesummary
  asaprc parameter (e.g. in {\tt sd.rcParams}) does nothing.

  GBT data has incorrect fluxunit ({\tt 'Jy'}, should be {\tt 'K'}), 
  freqframe ({\tt 'LSRK'}, is really {\tt 'TOPO'}) and reference
  frequency (set to that of the first IF only).

  You cannot set the rest frequencies for GBT data.
  THIS IS THE MOST SERIOUS BUG RIGHT NOW.

  The {\tt sd.scantable.freq\_align} does not yet work correctly.

  Need to add to scantable.stats:
      {\tt 'maxord', 'minord'} - the ordinate (channel, vel, freq) 
      of the max/min
  
\item {\tt sd} general issues

  There should be a {\tt sdhelp} equivalent of {\tt toolhelp}
  and {\tt tasklist} for the sd tools and tasks.

  The current output of ASAP is verbose, and is controlled by
  setting {\tt sd.rcParams['verbose']=False} (or {\tt True}).
  At the least we should make some of the output less cryptic.

  Strip off leading and trailing whitespace on string parameters.

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

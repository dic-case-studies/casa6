%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% STM 2007-04-13  split from previous version
%Version  JM 2007-03-05
%Updated STM 2007-03-07
%Updated STM 2007-04-15
%Updated STM 2007-10-10  beta release (spell-checked)
%Updated STM 2007-11-22  put in appendix for beta release 0.0
%Updated  TT 2008-03-12  updated for beta patch 1.0 
%Updated STM 2008-05-13  start patch 2.0, separate task subsecs
%Updated  TT 2008-07-09  updated for beta patch 2.0 
%Updated  TT 2008-10-17  updated for beta patch 3.0 
%Updated STM 2009-05-20  start patch 4.0
%Updated TT 2009-11-05 start editing for R3.0 
%Updated TT 2009-12-15 added a few more notes
%Updated TT 2010-03-...      added comments from Takeshi, Wataru, and Kana for R3.0.1 updates
%Updated JO 2010-03-10 start editing for R3.0.1
%Updated TT 2010-05-27 start editing for R3.0.2, added inputs from Kana and Takeshi
%Updated TN 2010-10-12 start editing for R3.1, added inputs from Kana
%Updated TN 2011-04-12 start editing for R3.2, added inputs from Takeshi
%Updated TN 2011-04-18 first draft for R3.2, added inputs from Kana, Wataru
%and myself
%Updated JO 2010-10-29 JO edits for 3.1.0 
%Updated TN 2012-04-11 first draft for R3.4, added inputs from Kana and myself

%\chapter{Single Dish Data Processing}
\chapter[Single Dish Data Processing]{Single Dish Data Processing}
\label{chapter:sd}

% TT: Here is the SD part of the cookbook updated for new tasks.
% Please check if it looks ok.  I also took out the comment regarding
% setting rest frequencies was inoperative. As far as I can check,
% set_restfreqs does work but it does not replace previous values (every
% time you execute set_restfreqs it adds the new value(s) to the
% frequencies table) and the last value(s) is used as rest frequencies.

%% % KS: discarded the NOTE. (CASA 4.0) SD package is not only for CSV
%% % anymore since Cycle-I starts before the next release CASA 4.1?
%% % TT: took out "BETA"  
%% {\bf NOTE:} The single-dish analysis package within CASA 
%% is included in the release for the use
%% of the ALMA computing and commissioning groups.  
%% %Therefore, this description is included in this Cookbook
%% %as an appendix. 
%% However, it is fully accessible for general users.

%ALMA consists of an interferometric array (the 12m array) and the 
%ACA, which is an array with 16 7m antennas and 4 12m antennas.  
%The four 12m antennas are used as total-power single dish telescopes.  
%CASA has the capability to reduce and image 
%single dish spectral data.  Currently, 
The Single Dish part of CASA uses the ATNF Spectral Analysis Package (ASAP), 
which is imported as the {\tt sd} tool at the start-up of CASA. 
%For single-dish spectral calibration and analysis, 
ASAP forms the basis for a series
of tasks (the ``SDtasks'') that encapsulates the functionality
within the standard CASA task framework.  
ASAP was originally developed to
support the Australian telescopes such as Mopra, Parkes, and
Tidbinbilla.
%and eventually ALMA [Note: Some support for the ALMA is now available].  
%{\bf For R3.4 or later, the ASAP version included in CASA was updated to 4.0
%(which is the latest official release of ASAP as of Mar. 2012).
%In ASAP 4.0, data format was also updated from 3.0 to 4.0. 
%Note that data in version 3.0 format are automatically updated to version 4.0 format and replaced.}
Currently, datasets taken at ALMA, GBT (see the note below for limitation of 
GBT SDFITS handling), ASTE, NRO 45m and Mopra are supported for data processing 
within CASA. 


For details on ASAP -- including the User Guide, Reference Manual, and tutorial -- see
the ASAP home page at ATNF: 
\begin{itemize}
   %\item \url{http://www.atnf.csiro.au/computing/software/asap/} \, .
   \item \url{http://svn.atnf.csiro.au/trac/asap/} \, .
\end{itemize}
The ASAP tools are prefaced with {\tt sd.} within CASA, e.g., the ASAP tool {\tt scantable} becomes
{\tt sd.scantable}.  See \S~\ref{section:sd.asap} for more
information on the tools.

All of the ASAP functionalities are available within the CASA
installation.  Since we extended ASAP, there
are certain functionalities that are available only in the CASA version of ASAP.
In the following subsections, we outline how to access ASAP
from within CASA and the data flow for standard use cases.

If you run into trouble, be sure to check the list of known issues
and features of ASAP and the SDtasks presented in 
\S~\ref{section:sd.issues} first.

%%% 2010/10/12 TN
%%% This note is no longer necessary since filler for GBT data is implemented
%{\bf An important note for GBT raw SDFITS data:} The GBT raw SDFITS data format
%(in which the data are stored in multiple data tables within SDFITS file) are not
%supported in the current SDtasks or sd toolkit. Thus the data reduction for the GBT
%data starting from the raw SDFITS cannot be done. It is generally possible to 
%process the GBT data once it is converted with tools outside CASA 
%to a single data table SDFITS or other data format supported by ASAP.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Guidelines for the use of ASAP and SDtasks in CASA}
\label{section:sd.intro}

\subsection{Environment Variables}
\label{section:sd.intro.env}

There are a number of environment variables that the ASAP tools
(and thus the SDtasks) use to control the operation.
They are located in {\tt .asaprc} and are described in the ASAP User Guide.
Within CASA, they are contained in the
Python dictionary {\tt sd.rcParams} and are accessible through
its keys and values.  For SDtask users, the most important parameter is
{\tt verbose}, which controls the display of detailed
messages from the tools. By default,
\small
\begin{verbatim}
     sd.rcParams['verbose'] = True
\end{verbatim}
\normalsize
produces lots of messages.  Also, the {\tt scantable.storage}
parameter controls whether scantable operations are done
in memory or on disk.  The default is  
\small
\begin{verbatim}
     sd.rcParams['scantable.storage'] = 'memory'  
\end{verbatim}
\normalsize
which is the best choice if there is enough memory
than the size of the data to be loaded.  On the other hand,
\small
\begin{verbatim}
     sd.rcParams['scantable.storage'] = 'disk'
\end{verbatim}
\normalsize
forces the task to store datasets on disk, which might be necessary when the 
dataset is large.
See \S~\ref{subsection:sd.asap.environ} for more details on the
ASAP environment variables.

{\bf Important Note:}\\
User must use {\tt sd.rcParams[scantable.storage']='disk'} with care when 
you call any tool level functions since some functions may overwrite original data 
even if you set {\tt sd.rcParams['insitu']=False}, which tells the system not to 
overwrite the original data (in contrast, setting {\tt sd.rcParams['insitu']} to True 
forces to overwrite original data). 
Relevant methods, which may overwrite original data in the above case, are as follows:
\small
\begin{itemize}
   \item {\tt sd.average\_time}
   \item {\tt sd.merge}
   \item four operations ({\tt +, -, *, /}) of {\tt sd.scantable} instance with scalar or array
   \item {\tt sd.scantable.add}
   \item {\tt sd.scantable.clip}
   \item {\tt sd.scantable.flag}
   \item {\tt sd.scantable.flag\_nans}
   \item {\tt sd.scantable.flag\_row}
   \item {\tt sd.scantable.scale}
   \item {\tt sd.scantable.recalc\_azel}
   \item any setter functions of {\tt sd.scantable} class (both {\tt set\_xxx} and {\tt \_setxxx} functions)
\end{itemize}
\normalsize
If you only use the SDtasks, you don't need to worry about this since the 
SDtasks are designed to keep the original data unchanged.  

\subsection{Assignment}
\label{section:sd.intro.ass}

Some ASAP methods and functions require assigning a method
to a variable which can then be manipulated.  These methods and functions include
{\tt sd.scantable} and {\tt sd.selector}, both of which make objects.
For example,
\small
\begin{verbatim}
     s = sd.scantable('foo.PM01.asap', average=False) 
\end{verbatim}
\normalsize

\subsection{Lists}
\label{section:sd.intro.lists}

For lists of scans or IFs, such as in {\tt scanlist} and {\tt
iflist} in the SDtasks, the tasks and functions require a comma-delimited 
Python list, e.g.,
\small
\begin{verbatim}
     scanlist = [241, 242, 243, 244, 245, 246] 
\end{verbatim}
\normalsize
The python {\tt range} function can be used to generate a list of
consecutive numbers, e.g.,
\small
\begin{verbatim}
     scanlist = range(241,247) 
\end{verbatim}
\normalsize
giving the same list as above,
\small
\begin{verbatim}
CASA <3>: scanlist=range(241,247)
CASA <4>: print scanlist
[241, 242, 243, 244, 245, 246] 
\end{verbatim}
\normalsize
Multiple ranges can be created by summing lists,
\small
\begin{verbatim}
CASA <5>: scanlist=range(241,247) + range(251,255)
CASA <6>: print scanlist
[241, 242, 243, 244, 245, 246, 251, 252, 253, 254] 
\end{verbatim}
\normalsize
Note that in the future, the {\tt sd} tools and SDtasks will use
the same selection language as in the interferometric synthesis part of the CASA.

Spectral regions, such as those for setting masks, are pairs of
min and max values for whatever spectral axis unit is currently
chosen.  These are fed into the tasks and tools as a list of lists,
where each list element is a list with the {\tt [min,max]} for that
sub-region, e.g.,
\small
\begin{verbatim}
     masklist=[[1000,3000], [5000,7000]] 
\end{verbatim}
\normalsize

\subsection{Dictionaries}
\label{section:sd.intro.dict}

Currently, the SDtasks return the Python dictionary 
for the results of line fitting (in {\tt sdfit})
and region statistics (in {\tt sdstat}).  If you invoke
these tasks by assigning a variable for the return,
you can then access the
elements through the keywords, e.g.,
\small
\begin{verbatim}
CASA <10>: line_stat=sdstat()
Current fluxunit = K
No need to convert fluxunits
Using current frequency frame
Using current doppler convention

CASA <11>: line_stat
  Out[11]: 
{'eqw': 70.861755476162784,
 'max': 1.2750182151794434,
 'mean': 0.35996028780937195,
 'median': 0.23074722290039062,
 'min': -0.20840644836425781,
 'rms': 0.53090775012969971,
 'stddev': 0.39102539420127869,
 'sum': 90.350028991699219}
\end{verbatim}
\normalsize
One can then use these values in scripts by accessing this dictionary,
e.g.,
\small
\begin{verbatim}
CASA <12>: print "Line max = %5.3f K" % (line_stat['max'])
Line max = 1.275 K
\end{verbatim}
\normalsize

\subsection{Line Formatting}
\label{section:sd.intro.line}

The SDtasks trap leading and trailing whitespace on string parameters
(such as {\tt infile}) but ASAP does not, so be
careful when setting string parameters.  ASAP is case-sensitive,
with most parameters being upper-case, such as {\tt ASAP} for the
{\tt sd.scantable.save} file format.  The SDtasks are generally
more forgiving.  Also, beware Python's sensitivity to indentation.

\subsection{Logging}
\label{section:sd.intro.log}

Before R3.0, all messages from ASAP were written to the standard output
({\tt sys.stdout}) and they disappeared after exiting CASA. After R3.0, the
logging system of ASAP is integrated into CASA logging system.  Therefore, 
all outputs from ASAP commands, except for GUI related notifications, 
are sent to the log file for the current session and they
are displayed to the CASA Logger (see \S~\ref{section:intro.common.logger}). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% New section for CASA 4.2.  
% main aim for this section is to provide the user a step-by-step procedure
% for reducing and imaging ALMA single dish data.
% Shinya and Bunyo will work on this section
%
\section{A Step-by-Step Guide for Reducing and Imaging ALMA Single Dish Data}
\label{section:sd.sdguide}


%
% Feel free to change the strucuture of the following contents
% 
\subsection{Introduction and Workflow}
\label{section:sd.sdguide.intro}

Data from the Total Power (TP) array of ALMA is initially in a format called the 
ASDM.  These ASDMs must be converted to ASAP scantables in order to use standard calibration procedures for
single dish telescopes;

\begin{itemize}
\item
Reference (OFF) subtraction
\item
$T_{\rm sys}$ calibration
\item
Baseline subtraction
\end{itemize}
In the case of continuum observations, the baseline subtraction step can be skipped or be done in the 
spatial domain.  The final imaging part cannot be done in ASAP,  and the data must be converted back to
Measurement Sets (MSs), and then imaged using a standard CASA task.  Below we explain the data reduction in detail, assuming an ASDM
format called ``foo'', and the dataset contains data from antennas ``PM01'' and ``PM02''.  

\subsection{Create Single Dish Data Format}
\label{section:sd.sdguide.format}
The ASDMs can be converted to scantables in two ways; directly from the ASDM, or via a MS.  We expect that conversion via 
MS will be used more in the current version of CASA, as the direct conversion can work with only one antenna at a time,
while the conversion from a MS can work on multiple antennas simultaneously.  

\subsubsection{Direct Conversion from ASDM}
The standard importasdm task in CASA can convert ASDM to scantables by setting singledish=True.  It will work with only one 
antenna at a time, so in case the dataset contains several antennas, the same task must be repeated the same number of times 
each time specifying the antenna name or ID.

\begin{verbatim}
CASA <#>: importasdm(asdm = 'foo', vis = 'foo.PM01.asap', 
                     singledish=True, antenna="PM01")

CASA <#>: importasdm(asdm = 'foo', outfile = 'foo.PM02.asap', 
                     singledish=True, antenna="PM02")

\end{verbatim}
If the antenna name or ID is not specified, the task will default to the first antenna in the array.

\subsubsection{Conversion via MS}
A conversion to MS first then to scantables may be an efficient choice in the case of multiple antennas.
\begin{verbatim}
CASA <#>: importasdm(asdm = 'foo', vis = 'foo.ms')
\end{verbatim}
will create a MS with all antennas.  Then,
\begin{verbatim}
CASA <#>: sd.splitant(filename='foo.ms',outprefix='foo')
\end{verbatim}
will split the dataset into individual antennas while converting them
to scantables.  The individual scantables will have names in the
format of ``outprefix''+''antenna name'' followed by the .asap suffix.
For the following steps in the reduction, all tasks must be iterated
on the scantables of the individual antennas.  For simplicity we will
just note the CASA input parameters assuming the ``PM01'' antenna.

\subsection{Calibration}
\subsubsection{Interpolating $T_{\rm sys}$ into Science Spectral Windows}
In the current version of ALMA software (as of September 2013), the
system temperature ($T_{\rm sys}$) can only be measured using a
spectral setup of 124 channels over a 1.9375GHz bandwidth (assuming
use of the ACA correlator).  The actual science observing is likely to
have more channels, in which case a different spectral window (SPW) is
used.  In order to calibrate the data, the $T_{\rm sys}$ from the 124
channel SPW must be interpolated into these science SPWs, both in time
and frequency.

First, we must identify which $T_{\rm sys}$ SPW corresponds to which
science SPW.  This can be done automatically by looking for a
124-channel SPW with a $T_{\rm sys}$ intent which covers the frequency
range of a relevant science SPW,
\begin{verbatim}
tsysmap=tsysspwmap(vis='foo.ms',tsystable='foo.tsys')
\end{verbatim}
which returns an array where the $i$-th element corresponds to the $T_{\rm sys}$ SPW number 
that is mapped to SPW $i$.  The actual interpolation is done by 
\begin{verbatim}
filltsys('foo.PM01.asap', specif=i, tsysif=tsysmap[i], mode='linear', extrap=True)
\end{verbatim}
where specif is the science SPW, tsysif is the matching $T_{\rm sys}$
SPW, and the mode parameter specifies how the interpolation is done
(defaults to linear interpolation).  If the $T_{\rm sys}$ SPW
frequency range does not completely cover the science SPW, the user
may choose extrap=True to extrapolate the $T_{\rm sys}$ to those
channels (default=False).  Interpolation in the time domain is linear
when possible, but in cases where science observations are not
bracketed by $T_{\rm sys}$ scans, then the nearest $T_{\rm sys}$
measurement will be used.  The filltsys library can only deal with one
SPW at a time, so must be looped over the relevant SPWs.

\subsubsection{Apply Calibration and Inspect}

Applying calibration is done with the task sdcal or sdcal2.  Task
sdcal2 is an implementation of an interferometry-like calibration
scheme, i.e., generate caltables and apply them.


{\bf sdcal}

Task sdcal will calibrate the data into units of Kelvins, by applying
the $T_{\rm sys}$ calibration and removing the signal from the OFF
position.  In most science observations, calibration mode (calmode) is
'ps', for Position Switching.  If you use calmode = 'ps', it will do
an (ON-OFF)/OFF calculation by interpolating the nearest (in time)
OFFs to the ONs, and then apply the $T_{\rm sys}$ calibration.

For calibration SBs (i.e., continuum observations) or science
observations where the edge of the OTF maps do NOT contain any
emission, calmode = 'otf' or 'otfraster' will identify the edge of the
raster rows and assign them as OFFs.  Those modes are designed for OTF
observations without explicit OFF scans, but accept data with OFF
scans.  If the observing pattern is 'raster', you should use the
'otfraster' mode to calibrate data.  Otherwise, the 'otf' mode should
be used.

The OFF subtraction is done in the time domain. 
You must specify the SPWs (iflist) you want to work on. 

\begin{verbatim}
CASA <#>: sdcal(infile = 'foo.PM01.asap', outfile = 'foo.PM01.cal', 
               calmode = 'ps', iflist = [17,19,21,23])
\end{verbatim}
In this case the calibration is done only on SPWs 17, 19, 21 and 23.


{\bf sdcal2}

%Task sdcal2 is an implementation of an interferometry-like calibration 
scheme, i.e., generate caltables and apply them. 
Available calibration modes are 'ps', 'otf', 'otfraster', and 'tsys'.   
Those modes generates caltables for sky or $T_{\rm sys}$ calibration. 
Those caltables can be applied to the data by using calmode 'apply'. 
You can calibrate data on-the-fly like sdcal task by setting calmode to 
a composite calmode string separated by comma. 
For example, calmode = 'ps,apply' means doing sky calibration and apply 
it on-the-fly. 
In this case, caltable is generated as a temporary plain table and will 
be deleted at the end. 
%There are several control parameters for sky/Tsys calibration and 
application of caltables. 
%See the above parameter description.

\begin{verbatim}
CASA <#>: sdcal2(infile = 'foo.PM01.asap', outfile = 'foo.PM01.cal', 
                calmode = 'ps,apply', iflist = [17,19,21,23])
\end{verbatim}


\subsection{Data Inspection}
Look at the calibrated data for obvious or subtle problems. 
The task sdplot will enable looking at time- or scan-integrated spectra. 
If you need to look at individual data rows, use sdflag. Flag as 
necessary.

\begin{verbatim}
CASA <#>: sdplot(infile = 'foo.PM01.cal', plottype = 'spectra')
\end{verbatim}
or use plottype = 'pointing' to look at the data points on the sky. 
This will be useful also before calibration to check where OFFs and 
ATMcal scans were done. 


\subsection{Flagging}

Flagging of data is done using sdflag. 
You can look at individual data rows and choose which to flag using 
interactive = T, or interactive = F if you know which scans/spws to flag.

\begin{verbatim}
CASA <#>: sdflag(infile = 'foo.PM01.cal', specunit = 'channel', iflist 
= [17,19,21,23]
                maskflag = [[0, 99], [3980, 4079]], overwrite = T)
\end{verbatim}
In this case, 100 channels on each side are flagged. 

\begin{verbatim}
CASA <#>: sdflag(infile = 'foo.PM01.cal', specunit = 'channel', iflist 
= [17,19,21,23]
                scanlist=[1,2,3,4], overwrite = T)
\end{verbatim}
In this case, scans other than 1, 2, 3, and 4 are flagged. Note that 
scanlist selects scans to use. 


\subsection{Baseline Subtraction}
\label{section:sd.sdguide.baseline}
Relevant only for the spectral line observation, sdbaseline can identify 
lines automatically and iteratively (maskmode = 'auto') or you can 
specify the channel range (maskmode = 'list') to calculate the baselines. 
The baseline fitting method is controlled by the parameters blfunc and 
order. 
Many fitting methods are available ('poly', 'chebyshev', 'cspline', 
'sinusoid', see help of sdbaseline task for more information). 
Use of zeroth or first order polynomial is good for most cases. 


\begin{verbatim}
CASA <#>: sdbaseline(infile = 'foo.PM01.cal', outfile = 'foo.PM01.bl', 
                    maskmode = 'auto', thresh = 3.0, 
                    blfunc = 'poly', order = 1)
\end{verbatim}

Look at the baseline-subtracted data with sdplot. 
Spectral smoothing is done with task sdsmooth. 


\subsection{Batch Reduction: sdreduce}

Task sdreduce performs data selection, calibration, and/or spectral
baseline fitting for single-dish spectra. This task internally calls the
tasks, sdcal, sdsmooth, and sdbaseline and it can be used to run all the
three steps in one task execution.
%By setting calmode = 'none', one can run sdreduce on already calibrated data,
%for further selection, averaging and atmospheric optical depth correction.
Note that sdreduce is not fully verified. 


\subsection{Imaging}
\label{section:sd.sdguide.imaging}

\subsubsection{Convert back to Measurement}
Imaging the calibrated single dish dataset is done using a standard CASA 
task, which currently takes only MS for input.
Therefore the calibrated scantable must first be converted back to a MS.

\begin{verbatim}
CASA <#>: sdsave(infile = 'foo.PM01.bl', outfile = 'foo.PM01.
calibrated.ms',
                outform = 'MS2')
\end{verbatim}

\subsubsection{Concatenating the datasets}
Before imaging, the individually calibrated single dish datasets should now be combined into one.

\begin{verbatim}
CASA <#>: concat(vis = ['foo.PM01.bl','foo.PM02.bl'], concatvis = 'foo.combined.ms',
                 freqtol='50MHz')
\end{verbatim}
The individual calibrated MSs have slightly different observing
frequencies as the observing frequency is defined in topocentric
velocities.  The freqtol parameter sets the tolerance for assigning
the same SPW ID to datasets with different frequencies.  This value
should be set to something sensible, as to include all matching SPWs
in the individual MSs.

\subsubsection{Imaging}
Now we are ready to image the calibrated TP array dataset.  Here we
assume that the observation was performed at 115.27 GHz on the
$^{12}\mathrm{CO}(J=1-0)$ line, on a target with field ID=0 and SPW=9.

\begin{verbatim}
CASA <#>: sdimaging(infile = 'foo.combined.ms',
                    field=0, spw=9,
                    specunit='MHz', restfreq='115271.204MHz',
                    dochannelmap=True,
                    nchan=50, step=10, start=115000,
                    gridfunction='GJINC', imsize=[50,50],
                    cell=['10arcsec']
                    phasecenter='J2000 12h22m54.9 +15d49m15',
                    outfile='foo.cube.image'
\end{verbatim}
This will create an image cube with 50 channels starting from
115000MHz at 10MHz frequency resolution.  The phasecenter is set to
the coordinate of the source (or whatever center coordinate the user
wishes to be the center of the map).  If the phasecenter is left
blank, then the task will roughly calculate the center automatically
using the coordinates in the pointing table.  The cell parameter
specifies the size of 1 pixel, and should be chosen so that it is
about 1/4 to 1/3 of the beam size.  The gridfunction is the function
used to interpolate the observed positions on the sky to a regular
image grid.  The default is BOX, but the user may choose from several
options.
\begin{itemize}
\item SF : A prolate spheroidal function.  This function can minimize aliasing effects.
\item BOX : A pillbox (box-car) function, defaulting to a kernel box size of 1 pixel.
\item PB : Uses the primary beam, assuming an Airy disk.  If the dataset is from an ALMA 12m antenna, it will use an effective diameter of 10.7m, 
\item GAUSS : A gaussian function.
\item GJINC : A gaussian convolved with a Jinc function. This function can minimize broadening of the effective beam.
\end{itemize}
Additional subparameters can be specified for SF, GAUSS, and GJINC
which controls the size of the functions.  The user can choose what
velocity frame to create the images in, but in most cases the default
(conversion to LSR frame) should be fine.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Using The ASAP Toolkit within CASA}
\label{section:sd.asap}

ASAP is included with the CASA installation/build. It is loaded
upon start-up, and the ASAP functionality is under the
Python 'sd' tool.  {\bf Note:} This means that if you are following
the ASAP cookbook or documentation, all of the commands should be 
invoked with a '{\tt sd.}' before the native ASAP command.

The ASAP interface is essentially the same as that
of the CASA toolkit, that is, there are groups of functionality (aka
tools) which have the ability to operate on your data. Type:

\small
\begin{verbatim}
sd.AsapLogger              sd.asaplinefind            sd.mask_or
sd.__builtins__            sd.asaplog                 sd.matplotlib
sd.__class__               sd.asaplog_post_dec        sd.merge
sd.__date__                sd.asapmath                sd.new_asaplot
sd.__delattr__             sd.asapplotter             sd.opacity
sd.__dict__                sd.average_time            sd.opacity_model
sd.__doc__                 sd.calfs                   sd.os
sd.__file__                sd.calibrate               sd.page
sd.__format__              sd.calnod                  sd.parameters
sd.__getattribute__        sd.calps                   sd.plotter
sd.__hash__                sd.commands                sd.plotter2
sd.__init__                sd.coordinate              sd.pylab
sd.__name__                sd.dosigref                sd.quotient
sd.__new__                 sd.dototalpower            sd.rc
sd.__package__             sd.edgemarker              sd.rcParams
sd.__path__                sd.env                     sd.rcParamsDefault
sd.__reduce__              sd.fitter                  sd.rcp
sd.__reduce_ex__           sd.flagplotter             sd.sbseparator
sd.__repr__                sd.get_revision            sd.scantable
sd.__revision__            sd.gui                     sd.selector
sd.__setattr__             sd.inspect                 sd.setup_env
sd.__sizeof__              sd.interactivemask         sd.simplelinefinder
sd.__str__                 sd.ipysupport              sd.skydip
sd.__subclasshook__        sd.is_asap_cli             sd.splitant
sd.__version__             sd.is_casapy               sd.srctype
sd._asap                   sd.is_ipython              sd.sys
sd._is_sequence_or_number  sd.linecatalog             sd.toggle_verbose
sd._n_bools                sd.linefinder              sd.unique
sd._to_list                sd.list_files              sd.utils
sd.almacal                 sd.list_rcparameters       sd.version
sd.apexcal                 sd.list_scans              sd.welcome
sd.asapfitter              sd.logging                 sd.xyplotter
sd.asapgrid                sd.mask_and                
sd.asapgrid2               sd.mask_not                
\end{verbatim}
\normalsize

...to see the list of tools.

In particular, the following are essential for most reduction
sessions: 
\begin{itemize}
   \item {\tt sd.scantable} - the data structure for ASAP and the core
         methods for manipulating the data; allows importing data,
         making data selections, basic operations (averaging,
         baselines, etc.) and setting data characteristics (e.g.,
         frequencies, etc.).
   \item {\tt sd.selector} - selects a subset of data for subsequent operations
   \item {\tt sd.fitter} - fit data 
   \item {\tt sd.plotter} - plotting facilities (uses {\tt matplotlib})
\end{itemize}

The {\tt scantable} functions are used most often and can be applied
to both the initial scantable and to any spectrum from that scan
table.  Type
\small
\begin{verbatim}
     sd.scantable.<TAB>
\end{verbatim}
\normalsize
(using TAB completion) to see the full list. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Environment Variables}
\label{subsection:sd.asap.environ}

The {\tt asaprc} environment variables are stored in the Python
dictionary {\tt sd.rcParams} in CASA.  This contains a number
of parameters that control how ASAP runs, for both tools and
tasks.  You can see what these are set to by typing at the
CASA prompt:

\small
\begin{verbatim}
  CASA <2>: sd.rcParams
  Out[2]: 
{'insitu': True,
 'plotter.axesformatting': 'asap',
 'plotter.colours': '',
 'plotter.decimate': False,
 'plotter.ganged': True,
 'plotter.gui': True,
 'plotter.histogram': False,
 'plotter.linestyles': '',
 'plotter.panelling': 's',
 'plotter.papertype': 'A4',
 'plotter.stacking': 'p',
 'scantable.autoaverage': True,
 'scantable.freqframe': 'LSRK',
 'scantable.history': True,
 'scantable.parallactify': False,
 'scantable.reference': '.*(e|w|_R)$',
 'scantable.save': 'ASAP',
 'scantable.storage': 'memory',
 'scantable.verbosesummary': False,
 'useplotter': True,
 'verbose': False}
\end{verbatim}
\normalsize
%% $

The use of these parameters is described in detail in the
ASAP Users Guide.

These parameters can be changed through the {\tt sd.rc}
function.  Use is described in {\tt help sd.rc}:

\small
\begin{verbatim}
CASA <3>: help(sd.rc)
Help on function rc in module asap:

rc(group, **kwargs)
    Set the current rc params.  Group is the grouping for the rc, e.g.
    for scantable.save the group is 'scantable', for plotter.stacking, the
    group is 'plotter', and so on.  kwargs is a list of attribute
    name/value pairs, e.g.
    
      rc('scantable', save='SDFITS')
    
    sets the current rc params and is equivalent to
    
      rcParams['scantable.save'] = 'SDFITS'
    
    Use rcdefaults to restore the default rc params after changes.
\end{verbatim}
\normalsize

{\bf Important Note:}\\
User must use {\tt sd.rcParams[scantable.storage']='disk'} with care when 
you call any tool level functions since some functions may overwrite original data 
even if you set {\tt sd.rcParams['insitu']=False}, which tells the system not to 
overwrite original data (in contrast, setting {\tt sd.rcParams['insitu']} to True 
forces to overwrite original data). 
Relevant methods, which may overwrite original data in the above case, are as follows:
\small
\begin{itemize}
   \item {\tt sd.average\_time}
   \item {\tt sd.merge}
   \item four operations ({\tt +, -, *, /}) of {\tt sd.scantable} instance with scalar or array
   \item {\tt sd.scantable.add}
   \item {\tt sd.scantable.clip}
   \item {\tt sd.scantable.flag}
   \item {\tt sd.scantable.flag\_nans}
   \item {\tt sd.scantable.flag\_row}
   \item {\tt sd.scantable.scale}
   \item {\tt sd.scantable.recalc\_azel}
   \item any setter functions of {\tt sd.scantable} class (both {\tt set\_xxx} and {\tt \_setxxx} functions)
\end{itemize}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Import}
\label{subsection:sd.asap.import}

Single dish data sets can be loaded into ASAP using the {\tt scantable}
module. The ASAP module, {\tt scantable}, imports single dish data sets in
a variety of formats (the CASA Measurement Set, NRO data format, RPFITS,
and varieties of SDFITS). An example of import command is:

\small
\begin{verbatim}
  CASA <1>: scans = sd.scantable('foo.ms', average=False)
\end{verbatim}
\normalsize

Use the {\tt summary} function to examine the data and get basic information:

\begin{verbatim}
CASA <8>: scans.summary()
\end{verbatim}
The output is printed to the logger. For example,
\footnotesize
\begin{verbatim}
--------------------------------------------------------------------------------
 Scan Table Summary
--------------------------------------------------------------------------------
Project:       AGBT06A_018_01
Obs Date:      2006/01/19/01:45:58
Observer:      Joseph McMullin
Antenna Name:  GBT@GREENBANK
Data Records:  512 rows
Obs. Type:     OffOn:PSWITCHOFF:TPWCAL
Beams:         1   
IFs:           8   
Polarisations: 2   (circular)
Channels:      8192
Flux Unit:     K
Abscissa:      Channel
Selection:     none

Scan Source         Time range                           Int[s] Record SrcType FreqIDs MolIDs 
       Beam  Position (J2000)       
--------------------------------------------------------------------------------
  20 OrionS         2006/01/19/01:45:58.0 - 01:47:58.2   30.03     64  [PSOFF, PSOFF:CALON] [0, 1, 2, 3] [0]
       0      05:15:13.5 -05.24.08.6
  21 OrionS         2006/01/19/01:48:38.0 - 01:50:38.2   30.03     64  [PSON, PSON:CALON] [0, 1, 2, 3] [0]
       0      05:35:13.4 -05.24.07.8
  22 OrionS         2006/01/19/01:51:21.0 - 01:53:21.2   30.03     64  [PSOFF, PSOFF:CALON] [0, 1, 2, 3] [0]
       0      05:15:13.6 -05.24.08.5
  23 OrionS         2006/01/19/01:54:01.0 - 01:56:01.2   30.03     64  [PSON, PSON:CALON] [0, 1, 2, 3] [0]
       0      05:35:13.4 -05.24.08.1
  24 OrionS         2006/01/19/02:01:47.0 - 02:03:47.2   30.03     64  [PSOFF, PSOFF:CALON] [4, 5, 6, 7] [1]
       0      05:15:13.5 -05.24.08.5
  25 OrionS         2006/01/19/02:04:27.0 - 02:06:27.2   30.03     64  [PSON, PSON:CALON] [4, 5, 6, 7] [1]
       0      05:35:13.4 -05.24.08.1
  26 OrionS         2006/01/19/02:07:10.0 - 02:09:10.2   30.03     64  [PSOFF, PSOFF:CALON] [4, 5, 6, 7] [1]
       0      05:15:13.5 -05.24.08.4
  27 OrionS         2006/01/19/02:09:51.0 - 02:11:51.2   30.03     64  [PSON, PSON:CALON] [4, 5, 6, 7] [1]
       0      05:35:13.3 -05.24.08.1
--------------------------------------------------------------------------------
FREQUENCIES: 4
   ID  IFNO   Frame   RefVal          RefPix Increment      Channels POLNOs
    0    0     LSRK   4.5489351e+10 4095.5       6104.233      8192  [0, 1]
    1    1     LSRK   4.5300782e+10 4095.5       6104.233      8192  [0, 1]
    2    2     LSRK   4.4074926e+10 4095.5       6104.233      8192  [0, 1]
    3    3     LSRK   4.4166212e+10 4095.5       6104.233      8192  [0, 1]
    4   12     LSRK   4.3962123e+10 4095.5      6104.2336      8192  [0, 1]
    5   13     LSRK   4.2645417e+10 4095.5      6104.2336      8192  [0, 1]
    6   14     LSRK   4.1594977e+10 4095.5      6104.2336      8192  [0, 1]
    7   15     LSRK    4.342282e+10 4095.5      6104.2336      8192  [0, 1]
--------------------------------------------------------------------------------
MOLECULES: 
   ID   RestFreq          Name           
    0   [4.54903e+10] []
    1   [4.3963e+10] []
--------------------------------------------------------------------------------
\end{verbatim}
\normalsize

\subsubsection{General descriptions}
\label{subsubsection:sd.asap.import.gen}

The followings are some cautions when using import feature.

\begin{itemize}

\item It is important to specify the {\tt antenna} parameter when importing a Measurement Set.
 For example:

\begin{verbatim}
   CASA<1>: scans = sd.scantable( 'foo.ms', average=False, antenna=0 )
\end{verbatim}
 
 The value of the {\tt antenna} parameter can be either id (integer) or name
 (string). The default value for {\tt antenna} parameter is 0.

\item It is important to use the {\tt average=False} parameter
setting as the calibration routines supporting GBT data require all of
the individual times and phases.

\item GBT data may need some pre-processing prior to using
ASAP. In particular, the program which converts GBT raw data into CASA
Measurement Sets tends to proliferate the number of spectral windows
due to shifts in the tracking frequency; this is being worked on by
GBT staff. 
\item  ASAP identifies the observing modes of data sets and 
the source types, e.g., reference and target sources, by 
identification numbers. The identification numbers are stored 
at the SRCTYPE column in scantable.
For example, the ids of target sources of the position switched, Nod,
and frequency switched data are 0, 2, and 3, respectively. 
The ids of corresponding reference data of position switched
and frequency switched modes are 1 and 4, respectively. 

\item  Import of Nobeyama Radio Observatory (NRO) data (in both OTF and NEWSTAR format)
 is available.
\end{itemize}

\subsubsection{Handling ALMA data}

\begin{itemize}
\item Using {\tt importasdm} task, ASDM data can be imported to ASAP directly.
To do that, you should set {\tt singledish=True} and specify id or name of 
the antenna by the {\tt antenna} parameter 
(see \S~\ref{section:io.import.asdm}). This functionality is still under 
testing. You can use previous two step process (import ASDM as MS using 
{\tt importasdm} task first, then import MS as ASAP format) to import ASDM 
as ASAP format if you have any problem during direct import. 

\item If the MS data contain data from multiple single dish antennas you need either, 
to specify the {\tt antenna} parameter when importing data ({\tt sd.scantable}) or, 
to split the data by antenna using {\tt sd.splitant} for further processing in ASAP. 
This is because ASAP scantable stores data only from single antenna.
The method {\tt sd.splitant} splits a Measurement Set by antenna ID
and save the tables as scantables containing data from each antenna. 
The names of output scantables are defined as prefix specified by
users (with parameter {\tt outprefix}) followed by a period (\lq {\tt .}\rq), 
the corresponding antenna name, and the suffix \lq {\tt .asap}\rq. 
For example, if you split a Measurement Set, \lq foo.ms\rq, 
which contains data from antennas, antA and antB,
with {\tt outprefix=\lq splitted\rq}, 
i.e., {\tt sd.splitant(\lq foo.ms\rq, outprefix=\lq splitted\rq)}, 
the names of scantables are \lq splitted.antA.asap\rq and
\lq splitted.antB.asap\rq.  
The returned value of the method is a list of scantable names. 
\item {\bf From 4.1, ASAP does not convert the frequency 
reference frame to LSRK when importing data. 
The frequency reference frame of an imported scantable is the 
same as that of MS or ASDM (usually TOPO)}.
\item It is possible to read the 2-element interferometric
data taken by the ALMA telescopes 
as a single dish data to further examine it using ASAP Toolkit and
the SDtasks. The usage is the same as importing single
dish data. 
For example, to load the ALMA interferometry data, myOSFint.ms
\begin{verbatim} 
s=sd.scantable('myOSFint.ms', 'False')
\end{verbatim} 
It is still experimental and limited to data obtained with a
two-element array.

\item In ALMA, the system temperature (Tsys) is measured in specific
spectral windows for calibration. It is necessary to transfer Tsys to
the spectral windows for target scans. This can be done using {\tt filltsys}
module or {\tt sdcal2} task. Usage of {\tt filltsys} is as follows:
\begin{verbatim}
import filltsys
filltsys.fillTsys( filename='mydata.asap', specif=5, tsysif=1, mode='linear' )
\end{verbatim}
The parameter {\tt filename} specifies a name of the data to be
processed. Data must be in ASAP format. The spectral windows (=IFs) for
target scan and calibration scan should be set using {\tt specif} and
{\tt tsysif}, respectively. You can identify those information using
{\tt sdlist} task. The {\tt mode} is an interpolation mode along
frequency axis. Available options are \lq linear\rq, \lq nearest\rq, 
\lq zero\rq, \lq slinear\rq, \lq quadratic\rq, \lq cubic\rq, 
and any integer specifying an order of the spline interpolation.
Note that {\tt filltsys} will overwrite the data specified by
{\tt filename}. 
See \S~\ref{section:sd.sdtasks.tasks.sdcal2} if you want to use {\tt sdcal2}.
\end{itemize}

\subsubsection{Import of NRO data}

Importing NRO data is available. Here are some notes on import of NRO data.

\begin{itemize}
\item Both NEWSTAR and NOSTAR formats are supported.
\item Dual-polarization data is supported.
\item An individual IFNO is assigned to each of arrays to identify 
data from an array. Note that arrays are numbered by successive IFNOs. 
For example, if observation of three arrays, A01, A03, and A05, 
are stored in a data set, their IFNOs will be 0, 1, and 2, respectively.
\item Developments are mainly focused on recent data, especially for new correlator.
Although older data (using AOS) can be imported, there may be an inconsistency with original data.
\item The parameter, {\tt freqref}, controls how frequency reference frame is set. 
The default is 'rest'. The other option is 'vref'. 
If {\tt freqref} is 'vref', frequency reference frame takes 
from VREF field in input NRO data. 
This parameter is only available in tool level, i.e. {\tt sd.scantable}.
\item There is a problem on imaging multi-beam data. 
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Scantable Manipulation}
\label{subsection:sd.asap.scantable}

Within ASAP, data is stored in a {\tt scantable}, which holds all of the
observational information and provides functionality to manipulate the
data and information. The building block of a {\tt scantable} is an
integration which is a single row of a scantable. Each row contains
just one spectrum of a beam, IF and polarization.  

Once you have a {\tt scantable} in ASAP, you can select a subset of the
data based on scan numbers, or source names; note that each
of these selections returns a new 'scantable' with all of the 
underlying functionality: 

\small
\begin{verbatim}
  CASA <5>: scan27=scans.get_scan(27)                 # Get the 27th scan
  CASA <6>: scans20to24=scans.get_scan(range(20,25))  # Get scans 20 - 24
  CASA <7>: scansOrion=scans.get_scan('Ori*')         # Get all Orion scans
\end{verbatim}
\normalsize

To copy a scantable, do:

\small
\begin{verbatim}
  CASA <15>: ss=scans.copy()
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Data Selection}
\label{subsubsection:sd.asap.scantable.select}

In addition to the basic data selection above, data can be selected
based on IF, beam, polarization, scan number as well as values such as
Tsys.  To make a selection create a {\tt selector} object choose among various
selection functions, e.g., 

\small
\begin{verbatim}
  sel = sd.selector()      # initialize a selector object
                           # sel.<TAB> will list all options
  sel.set_ifs(0)           # select only the first IF of the data
  scans.set_selection(sel) # apply the selection to the data
  print scans              # shows just the first IF
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{State Information}
\label{subsubsection:sd.asap.scantable.state}

Some properties of a scantable apply to all of the data, such as
spectral units, frequency frame, or Doppler type. This
information can be set using the %{\tt scantable} \_set\_xxxx\_
{\tt scantable.set\_xxxx}
methods.  These are currently:
\small
\begin{verbatim}
CASA <1>: sd.scantable.set_<TAB>
sd.scantable.set_dirframe    sd.scantable.set_selection
sd.scantable.set_doppler     sd.scantable.set_sourcename
sd.scantable.set_feedtype    sd.scantable.set_sourcetype
sd.scantable.set_fluxunit    sd.scantable.set_spectrum
sd.scantable.set_freqframe   sd.scantable.set_tsys
sd.scantable.set_instrument  sd.scantable.set_unit
sd.scantable.set_restfreqs   
\end{verbatim}
\normalsize

For example, {\tt sd.scantable.set\_fluxunit} sets the default units
that describe the flux axis:
\small
\begin{verbatim}
  scans.set_fluxunit('K')  # Set the flux unit for data to Kelvin
\end{verbatim}
\normalsize
Choices are {\tt 'K'} or {\tt 'Jy'}.
Note: the {\tt scantable.set\_fluxunit} function only changes the {\bf name}
of the current fluxunit. To change fluxunit, use 
{\tt scantable.convert\_flux} as described in 
\S~\ref{subsubsection:sd.asap.calib.fluxunit}
instead (currently it is necessary to do some gymnastics for non-AT
telescopes).

Use {\tt sd.scantable.set\_unit} to set the units to be used on 
the spectral axis:
\small
\begin{verbatim}
  scans.set_unit('GHz')    # Use GHz as the spectral axis for plots
\end{verbatim}
\normalsize
The choices for the units are {\tt 'km/s'}, {\tt 'channel'}, or
{\tt '*Hz'} (e.g. {\tt 'GHz'}, {\tt 'MHz'}, {\tt 'kHz'}, {\tt 'Hz'}).
This does the proper conversion using the current frame and Doppler
reference as can be seen when the spectrum is plotted.

Set the frame in which the frequency (spectral) axis is defined by {\tt sd.scantable.set\_freqframe}:
\small
\begin{verbatim}
CASA <2>: help(sd.scantable.set_freqframe)
Help on method set_freqframe in module asap.scantable:

set_freqframe(self, frame=None) unbound asap.scantable.scantable method
    Set the frame type of the Spectral Axis.
    Parameters:
        frame:   an optional frame type, default 'LSRK'. Valid frames are:
                 'REST', 'TOPO', 'LSRD', 'LSRK', 'BARY',
                 'GEO', 'GALACTO', 'LGROUP', 'CMB'
    Examples:
        scan.set_freqframe('BARY')
\end{verbatim}
\normalsize
The most useful choices here are {\tt frame = 'LSRK'} 
and {\tt frame = 'TOPO'} (what ALMA actually observes in). 
Note that the {\tt 'REST'} option is not yet available.
The Doppler frame is set with {\tt sd.scantable.set\_doppler}:
\small
\begin{verbatim}
CASA <3>: help(sd.scantable.set_doppler)
Help on method set_doppler in module asap.scantable:

set_doppler(self, doppler='RADIO') unbound asap.scantable.scantable method
    Set the doppler for all following operations on this scantable.
    Parameters:
        doppler:    One of 'RADIO', 'OPTICAL', 'Z', 'BETA', 'GAMMA'
\end{verbatim}
\normalsize

Finally, there are a number of functions to query the state of the
scantable.  These can be found in the usual way:
\small
\begin{verbatim}
CASA <4>: sd.scantable.get\_<TAB>
sd.scantable.get_abcissa       sd.scantable.get_parangle
sd.scantable.get_antennaname   sd.scantable.get_restfreqs
sd.scantable.get_azimuth       sd.scantable.get_rms
sd.scantable.get_column_names  sd.scantable.get_row
sd.scantable.get_coordinate    sd.scantable.get_row_selector
sd.scantable.get_direction     sd.scantable.get_scan
sd.scantable.get_directionval  sd.scantable.get_selection
sd.scantable.get_elevation     sd.scantable.get_sourcename
sd.scantable.get_fit           sd.scantable.get_spectrum
sd.scantable.get_fluxunit      sd.scantable.get_time
sd.scantable.get_inttime       sd.scantable.get_tsys
sd.scantable.get_mask          sd.scantable.get_tsysspectrum
sd.scantable.get_mask_indices  sd.scantable.get_unit
sd.scantable.get_masklist      sd.scantable.get_weather
\end{verbatim}
\normalsize
These include functions to get the current values of the states
mentioned above, as well as
methods to query the number of scans, IFs, and polarizations
in the scantable and their designations.  See the
inline help of the individual functions for more information.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Masks}
\label{subsubsection:sd.asap.scantable.masks}

Several functions (fitting, baseline subtraction, statistics, etc.) may
be run on a range of channels (or velocity/frequency ranges). You can
create masks of this type using the {\tt create\_mask} function:

\small
\begin{verbatim}
  # spave = an averaged spectrum
  spave.set_unit('channel')
  rmsmask=spave.create_mask([5000,7000])   # create a region over channels 5000-7000
  rms=spave.stats(stat='rms',mask=rmsmask) # get rms of line free region

  rmsmask=spave.create_mask([3000,4000],invert=True) # choose the region 
                                                     # *excluding* the specified channels
\end{verbatim}
\normalsize

The mask is stored in a simple Python variable (a list) and so can be
manipulated using Python facilities. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Scantable Management}
\label{subsubsection:sd.asap.scantable.management}

{\tt scantables} can be listed via:

\small
\begin{verbatim}
  CASA <33>: sd.list_scans()
  The user created scantables are:
  ['scans20to24', 's', 'scan27']
\end{verbatim}
\normalsize

As every {\tt scantable} will consume memory usage, if you will not use it
any longer, you can explicitly remove it via:

\small
\begin{verbatim}
  del <scantable name>
\end{verbatim}
\normalsize
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Scantable Mathematics}
\label{subsubsection:sd.asap.scantable.scanmath}

It is possible to do simple mathematics directly on {\tt scantables}
from the CASA command line using the $+,-,*,/$ operators as well as
their cousins $+=, -=, *=, /=$.  

\small
\begin{verbatim}
  CASA <10>: scan2=scan1+2.0 # add 2.0 to data 
  CASA <11>: scan *= 1.05    # scale spectrum by 1.05 
\end{verbatim}
\normalsize

Operands can be
a numerical value and one- or two-dimensional Python list. For list
operand, its shape should be conform with the shape of spectral data stored in the scantable.
Mathematics between two scantables is also available. In that case,
scantables must be conform with each other.

{\bf NOTE:} In scantable mathematics, scantable must be put on the left.
For example:
\begin{verbatim}
  CASA<12>: scan2=scan1+2.0   # this works
  CASA<13>: scan2=2.0+scan1   # this causes an error
\end{verbatim}

%{\bf NOTE:} mathematics between two scantables is not currently
%available in ASAP.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Scantable Save and Export}
\label{subsubsection:sd.asap.scantable.export}

ASAP can export scantables in a variety of formats, suitable for reading
into other packages. The formats are: 

\begin{itemize}
    \item ASAP -- This is the internal format used for ASAP. It is the only
     format that allows the user to restore the data, fits, etc.,
     without losing any information. As mentioned before, the ASAP
     scantable is a CASA Table (memory-based table). This function
     just converts it to a disk-based table. You can access it with
     the CASA {\tt browsetable} task or any other CASA table tasks. 

   \item SDFITS -- The Single Dish FITS format. This format was designed
     for interchange between packages but few packages can actually
     read it. 

   \item ASCII -- A simple text based format suitable for the user to
     process using Python or other means. 

   \item Measurement Set (V2: CASA format) -- Saves the data in a
     Measurement Set. All CASA tasks which use an MS should work with this format.
\end{itemize}

Scantables are exported by the function, {\tt save}:
\small
\begin{verbatim}
  CASA <19>: scans.save(name='foo.output.ms',format='MS2')
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Calibration}
\label{subsection:sd.asap.calib}

For some observatories, the calibration happens transparently as the
input data contains the Tsys measurements taken during the
observations. The nominal 'Tsys' values may be in Kelvin or
Jansky. The user may wish to apply a Tsys correction or apply
gain-elevation and opacity corrections.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Tsys scaling}
\label{subsubsection:sd.asap.calib.tsys}

If the nominal Tsys measurement at the telescope is wrong due to
incorrect calibration, the {\tt scale} function allows it to be corrected.  

\small
\begin{verbatim}
  scans.scale(1.05,tsys=True) # by default only the spectra are scaled
                              # (and not the corresponding Tsys) unless tsys=True
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Flux and Temperature Unit Conversion}
\label{subsubsection:sd.asap.calib.fluxunit}

The function, {\tt convert\_flux}, is available for converting 
measurements in Kelvin to Jansky (and vice versa). 
It converts and scales data to the selected units. 
The user may need to supply the aperture
efficiency, telescope diameter, or the Jy/K factor

\small
\begin{verbatim}
  scans.convert_flux(eta=0.48, d=35.) # Unknown telescope
  scans.convert_flux(jypk=15) # Unknown telescope (alternative)
  scans.convert_flux() # known telescope (mostly AT telescopes)
  scans.convert_flux(eta=0.48) # if telescope diameter known
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Gain-Elevation and Atmospheric Optical Depth Corrections}
\label{subsubsection:sd.asap.calib.gain}

At higher frequencies, it is important to make corrections for
atmospheric opacity and gain-elevation effects. {\bf NOTE:} Currently,
the MS to scantable conversion does not adequately populate the
azimuth and elevation in the {\tt scantable}. As a result, one must
calculate these via:

\small
\begin{verbatim}
  scans.recalc_azel()
  Computed azimuth/elevation using 
  Position: [882590, -4.92487e+06, 3.94373e+06]
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   ...
\end{verbatim}
\normalsize


With the correct Az/El, the effect of atmospheric opacity can be corrected 
for a {\it given} opacity by:

\small
\begin{verbatim}
  scans.opacity(tau=0.09)  # Opacity from which the correction factor: 
                           # exp(tau*zenith-distance)
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Comprehensive calibration function}
A new function {\tt calibrate} is introduced for comprehensive
calibration. This function calls appropriate calibration scheme by
referring the antenna name in the meta-data. The user just specify input
scantable and calmode parameter that indicates calibration mode ('ps',
'nod', 'fs', 'otf', or 'otfraster'). 
For GBT data, {\tt calibrate} function calls one of
the functions listed in the next section depending upon the value of
{\tt calmode}. For APEX data, {\tt apexcal} function is called, while for ALMA
data, that contains string 'ALMA' or 'OSF' in its antenna name, {\tt almacal}
function is called. Calibration scheme for these two telescopes are
essentially same, and can be expressed as,

\begin{verbatim}
  Ta* = Tsys * (ON - OFF) / OFF,
\end{verbatim}

where OFF scans are interpolated in time if possible.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Calibration of GBT data}
\label{subsubsection:sd.asap.calib.gbt}

Data from the GBT are uncalibrated and come as sets of integrations
representing the different phases of a calibration cycle (e.g., on
source, calibration on, on source, calibration off, on reference,
calibration on; on reference, calibration off). Currently, there are a
number of routines emulating the standard GBT calibration (in GBTIDL):
\begin{itemize}
   \item {\tt calps} - calibrate position switched data
   \item {\tt calfs} - calibrate frequency switched data
   \item {\tt calnod} - calibration nod (beam switch) data
\end{itemize}

All these routines calibrate the spectral data to antenna temperature
adopting the GBT calibration method as described in the
GBTIDL calibration document available at: 
\begin{itemize}
   \item \url{http://wwwlocal.gb.nrao.edu/GBT/DA/gbtidl/gbtidl_calibration.pdf}
\end{itemize}
There are two basic steps:

First, determine system temperature using a noise tube calibrator
({\tt sd.dototalpower()}) 

For each integration, the system temperature is calculated from
CAL noise on/off data as:

$ T_{sys} = T_{cal}$ $\times$ 
$\frac{<ref_{caloff}>}{<ref_{calon} - ref_{caloff}>} + \frac{T_{cal}}{2} $

{\tt ref} which refers to reference data and the spectral data are averaged
across the bandpass.  Note that the central 80\% of the spectra are
used for the calculation.

Second, determine antenna temperature ({\tt sd.dosigref()})

The antenna temperature for each channel is calculated as:

$ T_a(\nu) = T_{sys}$ $\times$ 
$\frac{sig(\nu) - ref(\nu)}{ref(\nu)}$

where $sig = \frac{1}{2}(sig_{calon} + sig_{caloff})$, 
      $ref = \frac{1}{2}(ref_{calon} + ref_{caloff}).$


Each calibration routine may be used as:


\small
\begin{verbatim}
  scans=sd.scantable('inputdata',False)         # create a scantable called 'scans'
  calibrated_scans = sd.calps(scans,[scanlist]) # calibrate scantable with position-switched 
                                                # scheme
\end{verbatim}
\normalsize


{\bf Note:} For calps and calnod, the {\tt scanlist} must be scan pairs in
correct order as these routines only do minimal checking.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Averaging}
\label{subsubsection:sd.asap.averaging}

One can average polarizations in a scantable using the
{\tt sd.scantable.average\_pol} function:
\small
\begin{verbatim}
  averaged_scan = scans.average_pol(mask,weight)

  where:
    Parameters:
        mask:        An optional mask defining the region, where the
                     averaging will be applied. The output will have all
                     specified points masked.
        weight:      Weighting scheme. 'none' (default), 'var' (1/var(spec)
                     weighted), or 'tsys' (1/Tsys**2 weighted)

    Example:

  spave = stave.average_pol(weight='tsys')
\end{verbatim}
\normalsize

One can also average scans over time using {\tt sd.average\_time}:
\small
\begin{verbatim}
  sd.average_time(scantable,mask,scanav,weight,align)

  where:

    Parameters:
        one scan or comma separated  scans
        compel:   if True, enable averaging of multi-resolution spectra.
        mask:     an optional mask (only used for 'var' and 'tsys' weighting)
        scanav:   True averages each scan separately.
                  False (default) averages all scans together,
        weight:   Weighting scheme.
                    'none'     (mean no weight)
                    'var'      (1/var(spec) weighted)
                    'tsys'     (1/Tsys**2 weighted)
                    'tint'     (integration time weighted)
                    'tintsys'  (Tint/Tsys**2)
                    'median'   ( median averaging)
        align:    align the spectra in velocity before averaging. It takes
                  the time of the first spectrum in the first scantable
                  as reference time.
    Example:
  
  stave = sd.average_time(scans,weight='tintsys')
\end{verbatim}
\normalsize

Note that alignment of the velocity frame should be done before
averaging if the time spanned by the scantable is 
long enough.  This is done through the {\tt align=True} option in
{\tt sd.average\_time}, or explicitly through the
{\tt sd.scantable.freq\_align} function, e.g.,
\small
\begin{verbatim}
CASA <62>: sc = sd.scantable('foo.PM01.asap',False)
CASA <63>: sc.freq_align()
Aligned at reference Epoch 2006/01/19/01:49:23 (UTC) in frame LSRK
CASA <64>: av = sd.average_time(sc)
\end{verbatim}
\normalsize

The time averaging can also be applied to multiple scantables.  For example, such data
might have been taken on different days.  The
{\tt sd.average\_time} function takes multiple scantables as input.
However, if they are taken at significantly different times (different days for
example), then {\tt sd.scantable.freq\_align} must be used to align
the velocity scales to the same time, e.g.
\small
\begin{verbatim}
CASA <65>: sc1 = sd.scantable('foo.scan0.asap',False)
CASA <66>: sc2 = sd.scantable('foo.scan1.asap',False)
CASA <67>: sc1.freq_align()
Aligned at reference Epoch 2006/01/19/01:49:23 (UTC) in frame LSRK
CASA <68>: sc2.freq_align(reftime='2006/01/19/01:49:23')
Aligned at reference Epoch 2006/01/19/01:54:46 (UTC) in frame LSRK
CASA <69>: scav = sd.average_time(sc1,sc2)
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spectral Smoothing}
\label{subsection:sd.asap.smoothing}

Smoothing on data can be done as follows:

\small
\begin{verbatim}
  scantable.smooth(kernel,    # type of smoothing: 'hanning' (default), 'gaussian',
                              # 'boxcar', 'rmedian' or 'poly'
          width,              # width in pixels (ignored for hanning); FWHM for gaussian.
          order,              # the order of the polynomial (only valid when kernel='poly')
          plot,               # plot the original and the smoothed spectra
          insitu)             # if False (default), do smoothing in-situ; otherwise, 
                              # make new scantable

  Example:
  # spave is an averaged spectrum
  spave.smooth('boxcar',5)    # do a 5 pixel boxcar smooth on the spectrum
  sd.plotter.plot(spave)      # should see smoothed spectrum
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spectral Regridding}
\label{subsection:sd.asap.regridchannel}

Regridding of channels in spectra is available as follows:
\small
\begin{verbatim}
  scantable.regrid_channel(width,    # The channel width (float) of regridded spectra 
                                     # in the current spectral unit.
          insitsu)                   # if False (default), do smoothing in-situ;
                                     # otherwise, make new scantable

  Example:
  # spave is an averaged spectrum
  spave.set_unit('channel')   # Use channel width
  spave.regrid_channel(5)     # regrid 5 channels in each spectrum to one channel 
  sd.plotter.plot(spave)      # should see smoothed spectrum
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Baseline Fitting}
\label{subsection:sd.asap.BLfitting}

CASA offers a variety of functions for baseline fitting: polynomial, 
cubic spline, Chebyshev polynomial and sinusoid are available.
The available baseline functions in ASAP are,
\begin{itemize}
\item {\tt sd.scantable.poly\_baseline} and 
{\tt sd.scantable.auto\_poly\_baseline}
\item {\tt sd.scantable.cspline\_baseline} and 
{\tt sd.scantable.auto\_cspline\_baseline} 
\item {\tt sd.scantable.chebyshev\_baseline} and
{\tt sd.scantable.auto\_chebyshev\_baseline} 
\item {\tt sd.scantable.sinusoid\_baseline} and
{\tt sd.scantable.auto\_sinusoid\_baseline}
\item {\tt sd.scantable.sub\_baseline}
\end{itemize}


The function, {\tt sd.scantable.poly\_baseline}, carries out a
polynomial baseline fit, given a mask of channels (if desired):
\small
\begin{verbatim}
  msk=scans.create_mask([100,400],[600,900])
  scans.poly_baseline(msk,order=1)
\end{verbatim}
\normalsize
This example fits spectra by the first order polynomial to the selected
channels and subtract the polynomial from the full spectrum.

The full set of parameters available in {\tt sd.scantable.poly\_baseline} is:
\small
\begin{verbatim}
  scans.poly_baseline(mask,order,insitu,clipthresh,clipniter,plot,...):

    Parameters:
        mask:         an optional mask
        order:        the order of the polynomial (default is 0)
        insitu:       if False a new scantable is returned.
                      Otherwise, the scaling is done in-situ
                      The default is taken from .asaprc (False)
        clipthresh:   Clipping threshold. (default is 3.0, unit: sigma)
        clipniter:    maximum number of iteration of 'clipthresh'-sigma 
                      clipping (default is 0)
        plot:         plot the fit and the residual. In this each
                      individual fit has to be approved, by typing 'y'
                      or 'n'
        getresidual:  if False, returns best-fit values instead of
                      residual. (default is True)
        showprogress: show progress status for large data.
                      default is True.
        minnrow:      minimum number of input spectra to show.
                      default is 1000.
        outlog:       Output the coefficients of the best-fit
                      function to logger (default is False)
        blfile:       Name of a text file in which the best-fit
                      parameter values to be written
                      (default is "": no file/logger output)
        csvformat:    if True blfile is csv-formatted, default is False.
        bltable:      name of a baseline table where fitting results
                      (coefficients, rms, etc.) are to be written.
                      if given, fitting results will NOT be output to
                      scantable (insitu=True) or None will be 
                      returned (insitu=False). 
                      (default is "": no table output)
\end{verbatim}
\normalsize

The parameter {\tt order} defines the order of polynomial fit.
The other parameters are common to all baseline functions except for 
{\tt sd.scantable.sub\_baseline}.

Two types of operations are available in baseline functions, i.e.,
on-the-fly baseline subtraction and generation of a baseline table. 
When {\tt bltable} is not specified (as in the above example), 
baseline fits are subtracted from spectra on-the-fly and the results 
are stored as a scantable.
On the other hand, when {\tt bltable} is specified, the fit parameters
are stored in a baseline table, but not actually subtracted from spectra.
The baseline table is a CASA Table containing baseline function type, 
parameters, fitting results (coefficients, rms, etc.) and so on. 
The function, {\tt sd.scantable.apply\_bltable}, is available to apply
it to a scantable to invoke baseline subtraction. e.g.,
\small
\begin{verbatim}
  msk=scans.create_mask([100,400],[600,900])
  scans.poly_baseline(msk,order=1,bltable='foo.blcal')
  blscans = scans.apply_bltable(inbltable='foo.blcal',insitu=False)
\end{verbatim}
\normalsize


The function, {\tt auto\_poly\_baseline}, is available for automatic 
selection of line-free channels.
It detects the line-free emission in each spectrum and subtracts a 
polynomial fit to it from the spectrum. 
Line-free channels are selected using linefinder. Three additional
parameters are available to define criteria of line-free channels.
\small
\begin{verbatim}
        edge:       an optional number of channel to drop at
                    the edge of spectrum. If only one value is
                    specified, the same number will be dropped from
                    both sides of the spectrum. Default is to keep
                    all channels. Nested tuples represent individual
                    edge selection for different IFs (a number of spectral
                    channels can be different)
        threshold:  the threshold used by line finder. It is better to
                    keep it large as only strong lines affect the
                    baseline solution.
        chan_avg_limit:
                    the maximum number of consecutive spectral channels to
                    average during the search of weak and broad lines.
                    The default is no averaging (and no search for weak
                    lines). If such lines can affect the fitted baseline
                    (e.g. a high order polynomial is fitted), increase this
                    parameter (usually values up to 8 are reasonable). Most
                    users of this method should find the default value
                    sufficient.
\end{verbatim}
\normalsize
Note, these parameters are in common for all the baseline fitting functions 
that use linefinder ({\tt auto\_*\_baseline}). 

The functions, {\tt chebyshev\_baseline} and {\tt auto\_chebyshev\_baseline}, 
are for baselining using the Chebyshev polynomials with or without linefinder, 
respectively. 

The functions, {\tt cspline\_baseline} and {\tt auto\_cspline\_baseline}, 
are for cubic spline fitting with or without using linefinder, respectively. 
The unique parameters for these are as follows:

\small
\begin{verbatim}
        npiece:     Number of pieces. (default is 2)
\end{verbatim}
\normalsize

The functions, {\tt sinusoid\_baseline} and {\tt auto\_sinusoid\_baseline}, 
are for sinusoidal fitting with or without using linefinder, respectively. 
The unique parameters for these are as follows:

\small
\begin{verbatim}
        nwave:      the maximum wave number of sinusoids within a range 
                    of spectral width multiplied by maxwavelength.
                    The default is 3 (i.e., sinusoids with wave 
                    number of 0(=constant), 1, 2, and 3 are 
                    used for fitting). Also it is possible to 
                    explicitly specify all the wave numbers to 
                    be used, by giving a list including them 
                    (e.g., [0, 1, 2, 15, 16]).
        maxwavelength: the longest sinusoidal wavelength. The 
                    default is 1.0 (unit: spectral range)
\end{verbatim}
\normalsize

The function, {\tt sd.scantable.sub\_baseline}, allows user to specify
baseline function type and parameters per spectrum, e.g.,
\small
\begin{verbatim}
sub_baseline(blinfo=[{'row':0, 'blfunc':'poly', 'order':5,
                      'masklist':[[10,350],[352,510]]},
                     {'row':1, 'blfunc':'cspline', 'npiece':3,
                      'masklist':[[3,16],[19,404],[407,511]]}
                    ])
\end{verbatim}
\normalsize
In this example, the first spectrum (row=0) is fitted with polynomial
of order=5 and the next one (row=1) is fitted with cubic spline
consisting of 3 pieces.


The 'goodness' of baseline fitting can be evaluated. A new sd tool function {\tt sd.scantable.calc\_aic} is available to calculate several values known as model selection criteria for a given spectrum and a baseline function. It can calculate Akaike Information Criterion (AIC), the corrected Akaike Information Criterion (AICc), Bayesian Information Criterion (BIC) and the Generalised Cross Validation (GCV). 


Note the parameter {\tt plot} is ignored for cubic spline and sinusoidal
fitting. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Line Fitting}
\label{subsection:sd.asap.LINEfitting}

Multi-component Gaussian fitting is done by
creating a fitting object, specifying fit parameters and finally
fitting the data. Fitting can be done on a {\tt scantable} selection
or an entire {\tt scantable} using the {\tt auto\_fit} function.

\small
\begin{verbatim}
  #spave is an averaged spectrum
  f=sd.fitter()                           # create fitter object
  msk=spave.create_mask([3928,4255])      # create mask region around line
  f.set_function(gauss=1)                 # set a single gaussian component
  f.set_scan(spave,msk)                   # set the scantable and region
                                          # 
                                          # Automatically guess start values
  f.fit()                                 # fit 
  f.plot(residual=True)                   # plot residual
  f.get_parameters()                      # retrieve fit parameters
  #   0: peak = 0.786 K , centre = 4091.236 channel, FWHM = 70.586 channel
  #      area = 59.473 K channel
  f.store_fit('orions_hc3n_fit.txt')      # store fit
                                          #
                                          # To specify an initial guess:
  f.set_function(gauss=1)                 # set a single gaussian component
  f.set_gauss_parameters(0.4,4100,200\    # set initial guesses for Gaussian
        ,component=0)                     #   for first component (0)
                                          #   (peak,center,fwhm)
                                          #
                                          # For multiple components set
                                          # initial guesses for each, e.g.,
  f.set_function(gauss=2)                 # set two gaussian components
  f.set_gauss_parameters(0.4,4100,200\    # set initial guesses for Gaussian
        ,component=0)                     #   for first component (0)
  f.set_gauss_parameters(0.1,4200,100\    # set initial guesses for Gaussian
        ,component=1)                     #   for second component (1)

\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Plotting}
\label{subsection:sd.asap.plotting}

\subsubsection{ASAP plotter}
The ASAP plotter uses the same Python matplotlib library as in CASA
(for x-y plots). It is accessed via the: 

\small
\begin{verbatim}
sd.plotter<TAB> # see all functions (omitted here)
sd.plotter.plot(scans) # the workhorse function
sd.plotter.set<TAB>
sd.plotter.set_abcissa     sd.plotter.set_layout      sd.plotter.set_ordinate
sd.plotter.set_colors      sd.plotter.set_legend      sd.plotter.set_panelling
sd.plotter.set_colours     sd.plotter.set_linestyles  sd.plotter.set_range
sd.plotter.set_data        sd.plotter.set_margin      sd.plotter.set_selection
sd.plotter.set_font        sd.plotter.set_mask        sd.plotter.set_stacking
sd.plotter.set_histogram   sd.plotter.set_mode        sd.plotter.set_title
\end{verbatim}
\normalsize

Spectra can be plotted at any time when {\tt refresh = True} (default) is
selected, and it will attempt to do the correct layout depending on
whether it is a set of scans or a single scan. 
You can switch off verbose plotting by {\tt refresh = False} in
tool parameters for faster plotting in scripts: 


\begin{verbatim}
sd.plotter.set_data(scan,refresh=False)  # set scantable to plot
                                        # this should be done at first.
sd.plotter.set_mode(stacking='time',panelling='if',refresh=False)
sd.plotter.set_range(ystart=-1.0,yend=5.0,refresh=False)
sd.plotter.plot()                         # actual plotting
\end{verbatim}

The details of the plotter display (matplotlib) are detailed in
the earlier section.

\subsubsection{Line Catalog}
ASAP allows loading a custom line catalog in ASCII format.
The ASCII text file must have at least 4 columns with Molecule name, 
frequency in MHz, frequency error and intensity (any units).
If the molecule name contains any spaces, they must be wrapped in quotes "".
A sample of the ASCII catalog is shown below.

\small
\begin{verbatim}
     H2D+    3955.2551 228.8818  -7.1941  
     H2D+   12104.7712 177.1558  -6.0769  
     H2D+   45809.2731 118.3223  -3.9494  
     CH       701.6811    .0441  -7.1641  
     CH       724.7709    .0456  -7.3912  
     CH      3263.7940    .1000  -6.3501  
     CH      3335.4810    .1000  -6.0304
\end{verbatim}
\normalsize
You can load the ASCII line catalog, for example, if
it is called my\_custom\_linecat.txt,
by following command:

\small
\begin{verbatim}
  mycatlog = sd.linecatlog('my_custom_linecat.txt')
\end{verbatim}
\normalsize

Use {\tt sd.plotter.plot\_line} to overlay the line catalog on 
the plot. (Currently over-plotting line catalog works only spectra plotted
in frequency.)

\small
\begin{verbatim}
  scans.set_unit('GHz')
  sd.plotter.plot(scans)
  sd.plotter.plot_lines(mycatlog)
\end{verbatim}
\normalsize

The following are some useful functions to control the line catalog
access. See ASAP User Guide for more complete descriptions.

\small
\begin{verbatim}
  mycatlog.save('my_custom_linecat.tbl') # save to the internal table format
  mycatlog.set_frequency_limits(100,115,'GHz') #set a frequency range for line selection
  mycatlog.set_name('*OH') # select all alcohols
\end{verbatim}
\normalsize

\subsubsection{Plotter2}
Plotter2 is a generic PGPLOT-based plotter newly available from this release. 
Developed as a light-weight plotter to be used in the ALMA SD pipeline, plotter2 can also be used by general CASA users to draw a graph containing multiple viewports in a flexible manner. It can be accessed via: 

\small
\begin{verbatim}
sd.plotter2<TAB> # see all functions (omitted here)
sd.plotter2.plot # the workhorse function
sd.plotter2.set<TAB>

sd.plotter2.set_autorange  sd.plotter2.set_vpbgcolor     sd.plotter2.set_yautorange
sd.plotter2.set_data       sd.plotter2.set_xautorange    sd.plotter2.set_yautotics
sd.plotter2.set_fontsize   sd.plotter2.set_xautotics     sd.plotter2.set_ylabel
sd.plotter2.set_line       sd.plotter2.set_xlabel        sd.plotter2.set_ynuminterval
sd.plotter2.set_output     sd.plotter2.set_xmask         sd.plotter2.set_ynumlocation
sd.plotter2.set_point      sd.plotter2.set_xnuminterval  sd.plotter2.set_yrange
sd.plotter2.set_range      sd.plotter2.set_xnumlocation  sd.plotter2.set_ytics
sd.plotter2.set_title      sd.plotter2.set_xrange
sd.plotter2.set_vp         sd.plotter2.set_xtics
\end{verbatim}
\normalsize

To simply plot a set of data point given as {\tt x=[}$ x_1, x_2, ...${\tt ]} and {\tt y=[}$ y_1, y_2, ...${\tt ]} on the screen, just type the following lines: 

\small
\begin{verbatim}
p = sd.plotter2()
p.set_data(x, y)
p.plot()
\end{verbatim}
\normalsize

If you want to save the above plot as a file 'foo.png', run '{\tt p.save("foo.png")}' instead of '{\tt p.plot()}'. 

A bit more complicated plot can be made by using functions of plotter2. Figure~\ref{fig:plotter2} shows an example. This figure is generated by the following commands: 

\small
\begin{verbatim}
s = sd.scantable(filename='foo.PM01.asap', average=False)
s_fit = s.cspline_baseline(npiece=5,insitu=False,showprogress=False,getresidual=False)
s_res = s.cspline_baseline(npiece=5,insitu=False,showprogress=False,getresidual=True)

x = range(s.nchan())

p = sd.plotter2()  # create a plotter2 object

for i in range(5):
  for j in range(5):
    # get y-value of data ------
    rowid = i*5+j
    y1 = s.get_spectrum(rowid)      # raw spectrum
    y2 = s_fit.get_spectrum(rowid)  # baseline computed by cubic spline fitting
    y3 = s_res.get_spectrum(rowid)  # baseline-subtracted spectrum

    # position of viewports ----
    vp_xmin1 = 0.2*j+0.03
    vp_xmax1 = 0.2*j+0.115
    vp_xmin2 = vp_xmax1
    vp_xmax2 = 0.2*j+0.2
    vp_ymin  = 0.2*(4-i)+0.012
    vp_ymax  = 0.2*(4-i)+0.18

    # setup left panels --------
    # set data and line attributes
    p.set_vp(vp_xmin1, vp_xmax1, vp_ymin, vp_ymax)
    p.set_data(x, y1)     # set first data
    p.set_line("blue")    # to be connected with blue line
    p.set_data(x, y2)     # set second data
    p.set_line("red", 4)  # to be connected with thick red line
    (ymin, ymax) = p.get_yrange()  # get y-range of left panel

    # channel-masked regions
    p.set_xmask(100, 108, "orange", "outline", 1)
    p.set_xmask(100, 108, "orange", "hatched", 1, 0.3)
    p.set_xmask(353, 401, "orange", "outline", 1)
    p.set_xmask(353, 401, "orange", "hatched", 1, 0.3)

    # labels and title
    p.set_fontsize(0.4)
    p.set_xlabel("channel", "normal", 0.45, vp_xmin1, 0.2*(4-i))
    p.set_ylabel("Intensity (arbitrary)", "normal", 0.45, \
                 vp_xmin1-0.02, 0.5*(vp_ymin+vp_ymax))
    p.set_title("Fit: row = "+str(rowid), "normal", 0.48, \
                0.5*(vp_xmin1+vp_xmax1), vp_ymax+0.005)

    # change background color
    if rowid in [4, 13, 14]: p.set_vpbgcolor("lightgray")
    # hide some panels
    if rowid in [7, 21, 22, 23, 24]: p.hide_vp()

    # setup right panels -------
    p.set_vp(vp_xmin2, vp_xmax2, vp_ymin, vp_ymax)
    p.set_yrange(ymin, ymax)  # make y-range common with left panel

    p.set_data(x, y3)
    p.set_line("blue")

    p.set_fontsize(0.4)
    p.set_ynumlocation("")  # no numbering in y-axis

    p.set_title("Reduced: row = "+str(rowid), "normal", 0.48, \
                0.5*(vp_xmin2+vp_xmax2), vp_ymax+0.005)

    # change background color
    if rowid in [4, 13, 14]: p.set_vpbgcolor("lightgray")
    # hide some panels
    if rowid in [7, 21, 22, 23, 24]: p.hide_vp()

p.save("foo.png")

del s, s_fit, s_res, p
\end{verbatim}
\normalsize

For details, see inline help of each plotter2 function. 

\begin{figure}[h!]
\begin{center}
\pnghigh{plotter2_sample}{5}
\caption{\label{fig:plotter2} An example of figure using plotter2.}
\hrulefill
\end{center}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Setting/Getting Rest Frequencies}
\label{subsection:sd.asap.restfreqs}

The rest frequencies used in the data can be retrieved by 
{\tt sd.scantable.get\_restfreqs()} and set to new values by 
{\tt sd.scantable.set\_restfreqs()}.
The CASA version of ASAP now can store multiple rest frequencies 
for each IF.

\small
\begin{verbatim}
  scans.get_restfreqs()         #retrieve current rest frequencies
  #{0: [45490258000.0]}
\end{verbatim}
\normalsize

All of the rest frequencies currently set to the data are listed in
python dictionary for each MOLECULE\_ID.

Here is an example of setting multiple rest frequencies for spectra of a particular IF:

\small
\begin{verbatim}
  #Select IFs, then set rest frequencies,
  sel=sd.selector()
  sel.setifs(0)
  scans.set_selection(sel)
  scans.set_restfreqs([45490258000.0,45590258000.0,45690258000.0])
\end{verbatim}
\normalsize

{\bf NOTE:} there is no functionality yet to select a specific rest frequency 
to apply to a specific line, etc. Currently, the first one in the list
of the rest frequencies is used for such calculation.

 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Single Dish Spectral Analysis Use Case With ASAP Toolkit}
\label{subsection:sd.asap.usecase}

Below is a script that illustrates how to reduce single dish data
using ASAP within CASA.  First a summary of the dataset is given and
then the script.

\small
\begin{verbatim}
#           MeasurementSet Name:  /home/rohir3/jocular/SD/OrionS_rawACSmod      MS Version 2
#
# Project: AGBT06A_018_01
# Observation: GBT(1 antennas)
#
#Data records: 256       Total integration time = 1523.13 seconds
#   Observed from   01:45:58   to   02:11:21
#
#Fields: 4
#  ID   Name          Right Ascension  Declination   Epoch
#  0    OrionS        05:15:13.45      -05.24.08.20  J2000
#  1    OrionS        05:35:13.45      -05.24.08.20  J2000
#  2    OrionS        05:15:13.45      -05.24.08.20  J2000
#  3    OrionS        05:35:13.45      -05.24.08.20  J2000
#
#Spectral Windows:  (8 unique spectral windows and 1 unique polarization setups)
#  SpwID  #Chans Frame Ch1(MHz)    Resoln(kHz) TotBW(kHz)  Ref(MHz)    Corrs
#  0        8192 LSRK  45464.3506  6.10423298  50005.8766  45489.3536  RR  LL HC3N
#  1        8192 LSRK  45275.7825  6.10423298  50005.8766  45300.7854  RR  LL HN15CO
#  2        8192 LSRK  44049.9264  6.10423298  50005.8766  44074.9293  RR  LL CH3OH
#  3        8192 LSRK  44141.2121  6.10423298  50005.8766  44166.2151  RR  LL HCCC15N
#  12       8192 LSRK  43937.1232  6.10423356  50005.8813  43962.1261  RR  LL HNCO
#  13       8192 LSRK  42620.4173  6.10423356  50005.8813  42645.4203  RR  LL H15NCO
#  14       8192 LSRK  41569.9768  6.10423356  50005.8813  41594.9797  RR  LL HNC18O
#  15       8192 LSRK  43397.8198  6.10423356  50005.8813  43422.8227  RR  LL SiO

# Scans: 21-24  Setup 1 HC3N et al
# Scans: 25-28  Setup 2 SiO et al

casapath=os.environ['AIPSPATH']

#ASAP script                            # COMMENTS                                      
#-------------------------------------- ----------------------------------------------- 
import asap as sd                       #import ASAP package into CASA                  
                                        #Orion-S (SiO line reduction only)
                                        #Notes:
                                        #scan numbers (zero-based) as compared to GBTIDL

                                        #changes made to get to OrionS_rawACSmod
                                        #modifications to label sig/ref positions
os.environ['AIPSPATH']=casapath         #set this environment variable back - ASAP changes it


s=sd.scantable('OrionS_rawACSmod',False)#load the data without averaging                
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{scantable}{5}
\caption{\label{fig:scantable} Multi-panel display of the
  scantable. Sub-panels are displayed per scan. There are two 
  spectra in each scan indicating two polarization (RR and LL).} 
\hrulefill
\end{figure}
 
\small
\begin{verbatim}
s.summary()                             #summary info                                   
s.set_fluxunit('K')                     # make 'K' default unit
scal=sd.calps(s,[20,21,22,23])          # Calibrate HC3N scans                          
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{scal}{5}
\caption{\label{fig:scal} Two panel plot of the calibrated
  spectra. The GBT data have a separate scan for the SOURCE and
  REFERENCE positions so scans 20,21,22 and 23 result in these two
  spectra.} 
\hrulefill
\end{figure}

\small
\begin{verbatim}
scal.recalc_azel()                      # recalculate az/el to                          
scal.opacity(0.09)                      # do opacity correction                         
sel=sd.selector()                       # Prepare a selection
sel.set_ifs(0)                          # select HC3N IF
scal.set_selection(sel)                 # get this IF
stave=sd.average_time(scal,weight='tintsys')    # average in time
spave=stave.average_pol(weight='tsys')  # average polarizations;Tsys-weighted (1/Tsys**2) average
sd.plotter.plot(spave)                  # plot

spave.smooth('boxcar',5)                # boxcar 5                                      
spave.auto_poly_baseline(order=2)       # baseline fit order=2                          
sd.plotter.plot(spave)                  # plot                                          

spave.set_unit('GHz')                                                                   
sd.plotter.plot(spave)
sd.plotter.set_histogram(hist=True)       # draw spectrum using histogram                 
sd.plotter.axhline(color='r',linewidth=2) # zline                                       
sd.plotter.save('orions_hc3n_reduced.eps')# save postscript spectrum                    
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{spave}{5}
\caption{\label{fig:spave} Calibrated spectrum with a line at zero (using histograms).}
\hrulefill
\end{figure}
 
\small
\begin{verbatim}
spave.set_unit('channel')                                                               
rmsmask=spave.create_mask([5000,7000])        # get rms of line free regions                  
base_rms=spave.stats(stat='rms',mask=rmsmask) #  rms
                                        
linemask=spave.create_mask([3900,4200])       # LINE
line_max=spave.stats('max',linemask)          #  IF[0] = 0.918
line_sum=spave.stats('sum',linemask)          #  IF[0] = 64.994
line_median=spave.stats('median',linemask)    #  IF[0] = 0.091
line_mean=spave.stats('mean',linemask)        #  IF[0] = 0.210
                                                                                        
                                                                                        
                                        # Fitting
spave.set_unit('channel')               # set units to channel                          
sd.plotter.plot(spave)                  # plot spectrum
f=sd.fitter()
msk=spave.create_mask([3928,4255])      # create region around line                     
f.set_function(gauss=1)                 # set a single gaussian component               
f.set_scan(spave,msk)                   # set the data and region for the fitter        
f.fit()                                 # fit                                           
f.plot(residual=True)                   # plot residual
\end{verbatim}
\normalsize

% \begin{figure}[h!]
% \pngname{gaussfit}{4}
% \caption{\label{fig:gaussfit} Plot of fit and residual.}
% \hrulefill
% \end{figure}

\small
\begin{verbatim}
f.get_parameters()                      # retrieve fit parameters
#   0: peak = 0.786 K , centre = 4091.236 channel, FWHM = 70.586 channel
#      area = 59.473 K channel
f.store_fit('orions_hc3n_fit.txt')      # store fit                                     
# Save the spectrum
spave.save('orions_hc3n_reduced','ASCII',True)  # save the spectrum                     
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Single Dish Imaging}
\label{section:sd.imaging}

Single dish imaging is supported within CASA using standard
tasks and tools. The data must be in the Measurement Set format. Once
there, you can use the {\tt im} (imager) tool
to create images:

Tool example:

\small
\begin{verbatim}
  scans.save('outputms','MS2')                    # Save your data from ASAP into an MS

  im.open('outputms')                             # open the data set
  im.selectvis(nchan=901,start=30,step=1,         # choose a subset of the data   
     spwid=0,field=0)                             # (just the key emission channels) 
  dir='J2000 17:18:29 +59.31.23'                  # set map center                
  im.defineimage(nx=150,cellx='1.5arcmin',        # define image parameters
     phasecenter=dir,mode='channel',start=30,     # (note it assumes symmetry if ny,celly 
     nchan=901,step=1)                            #  aren't specified)
                                                                       
  im.setoptions(ftmachine='sd',cache=1000000000)  # choose SD gridding                
  im.setsdoptions(convsupport=4)                  # use this many pixels to support the 
                                                  # gridding function used
                                                  # (default=prolate spheroidal wave function)
  im.makeimage(type='singledish',                 # make the image
     image='FLS3a_HI.image') 
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Single Dish Imaging Use Case With ASAP Toolkit}
\label{subsection:sd.imaging.usecase}

The data summary and the script are given below. 

\small
\begin{verbatim}
# Project: AGBT02A_007_01
# Observation: GBT(1 antennas)
# 
#   Telescope Observation Date    Observer       Project
#   GBT       [                   4.57539e+09, 4.5754e+09]Lockman        AGBT02A_007_01
#   GBT       [                   4.57574e+09, 4.57575e+09]Lockman        AGBT02A_007_02
#   GBT       [                   4.5831e+09, 4.58313e+09]Lockman        AGBT02A_031_12
# 
# Thu Feb 1 23:15:15 2007    NORMAL ms::summary:
# Data records: 76860       Total integration time = 7.74277e+06 seconds
#    Observed from   22:05:41   to   12:51:56
# 
# Thu Feb 1 23:15:15 2007    NORMAL ms::summary:
# Fields: 2
#   ID   Name          Right Ascension  Declination   Epoch
#   0    FLS3a         17:18:00.00      +59.30.00.00  J2000
#   1    FLS3b         17:18:00.00      +59.30.00.00  J2000
# 
# Thu Feb 1 23:15:15 2007    NORMAL ms::summary:
# Spectral Windows:  (2 unique spectral windows and 1 unique polarization setups)
#   SpwID  #Chans Frame Ch1(MHz)    Resoln(kHz) TotBW(kHz)  Ref(MHz)    Corrs
#   0        1024 LSRK  1421.89269  2.44140625  2500        1420.64269  XX  YY
#   1        1024 LSRK  1419.39269  2.44140625  2500        1418.14269  XX  YY


# FLS3 data calibration
# this is calibration part of FLS3 data
#
casapath=os.environ['AIPSPATH']
import asap as sd
os.environ['AIPSPATH']=casapath

print '--Import--'

s=sd.scantable('FLS3_all_newcal_SP',false)         # read in MeasurementSet

print '--Split--'

# splitting the data for each field
s0=s.get_scan('FLS3a*')                            # split the data for the field of interest
s0.save('FLS3a_HI.asap')                           # save this scantable to disk (asap format)
del s0                                             # free up memory from scantable

print '--Calibrate--'
s=sd.scantable('FLS3a_HI.asap')                    # read in scantable from disk (FLS3a)
s.set_fluxunit('K')                                # set the brightness units to Kelvin
scanns = s.getscannos()                            # get a list of scan numbers
sn=list(scanns)                                    # convert it to a list
print "No. scans to be processed:", len(scanns)

res=sd.calfs(s,sn)                                 # calibrate all scans listed using frequency 
                                                   # switched calibration method

print '--Save calibrated data--'
res.save('FLS3a_calfs', 'MS2')                     # Save the dataset as a MeasurementSet

print '--Image data--'
                                                                
im.open('FLS3a_calfs')                             # open the data set
im.selectvis(nchan=901,start=30,step=1,            # choose a subset of the data   
spwid=0,field=0)                                   # (just the key emission channels)                 
dir='J2000 17:18:29 +59.31.23'                     # set map center                
im.defineimage(nx=150,cellx='1.5arcmin',           # define image parameters
phasecenter=dir,mode='channel',start=30,           # (note it assumes symmetry if ny,celly 
nchan=901,step=1)                                  #  aren't specified)
                                                                       
im.setoptions(ftmachine='sd',cache=1000000000)     # choose SD gridding                
im.setsdoptions(convsupport=4)                     # use this many pixels to support the 
                                                   # gridding function used       
                                                   # (default=prolate spheroidal wave function)  
im.makeimage(type='singledish',image='FLS3a_HI.image') # make the image
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{HI_cube}{5.5}
\caption{\label{fig:HI_cube} FLS3a HI emission. The display
  illustrates the visualization of the data cube (left) and the
  profile display of the cube at the cursor location (right); the
  Tools menu of the Viewer Display Panel has a Spectral Profile button
  which brings up this display. By default, it grabs the left-mouse
  button. Pressing down the button and moving in the display will show
  the profile variations. }
\hrulefill
\end{figure}

\pagebreak


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Known Issues, Problems, Deficiencies and Features}
\label{section:sd.issues}


The Single-Dish calibration and analysis package within CASA is still
very much under development.  Not surprisingly,
there are a number of issues with ASAP and the SDtasks that are known and
under repair.  Some of these are non-obvious "features" by the way
ASAP and {\tt sd} are implemented, or limitations of the current Python
tasking environment.  Some are functions that have yet to be
implemented.  These currently include: 

\begin{enumerate}

\item {\tt sd.plotter}

  The method, {\tt sd.plotter.set\_range()} sets the same range for
  multiple panels, while we would like it to be able to set the
  range for each independently, including the default ranges.

  The {\tt sd.plotter} object remembers things throughout the session and
  thus can easily get confused. For example, one must reset the
  range {\tt sd.plotter.set\_range()} if set manually. This behaviour is
  not always expected, but is a consequence of having {\tt sd.plotter} be
  its own object that is fed data and commands.

  Eventually we would like the capability to interactively
  set things using the plots, like select frequency ranges,
  identify lines, start fitting. 

\item {\tt sd.selector}

  The selector object only allows one selection of each type.  It would be 
  nice to be able to make a union of selections (without resorting to query)
  for the {\tt set\_name}.  Note that the others like scans and IFs work off
  lists, which is fine.  We should make {\tt set\_name} work off lists of names.

\item {\tt sd.scantable}

% 2012/04/12 TN inline help for scantable constructor seems to be available
%  There is no useful inline help on the scantable constructor
%  in {\tt help sd.scantable} and {\tt help sd}.
% 2012/04/12 TN verbose parameter doesn't exist 
%  The inline help for {\tt scantable.summary} claims that there is
%  a verbose parameter, but there is not.  
  The {\tt scantable.verbosesummary}
  asaprc parameter (e.g. in {\tt sd.rcParams}) does nothing.

  GBT data has an undefined parameter fluxunit ({\tt ''} that should be {\tt 'K'}), an 
  incorrect freqframe ({\tt 'LSRK'} that is is really {\tt 'TOPO'}), and reference
  frequency (set to that of the first IF only).

  %%You cannot set the rest frequencies for GBT data.
  %%THIS IS THE MOST SERIOUS BUG RIGHT NOW.

  The {\tt sd.scantable.freq\_align} does not yet work correctly.


\item {\tt sd} general issues

  There should be a {\tt sdhelp} equivalent of {\tt toolhelp}
  and {\tt tasklist} for the sd tools and tasks.

  The current output of ASAP is verbose and controlled by
  setting {\tt sd.rcParams['verbose']=False} (or {\tt True}).
  We will make some of the output less cryptic.

  We will strip off leading and trailing whitespace on string parameters.

\item SDtasks general issues

  The SDtasks work with files saved onto disk in one of the 
  scantable supported formats.  It might be useful to
  work with scantables in memory (passing the objects) but this
  would require changes to the tasking system.  Note that this
  behavior is consistent throughout the casapy tasks.


\item {\tt sdcal} (and {\tt sdreduce})

  {\tt averageall=True} is still experimental since the test was insufficient 
  because of a lack of test data.

% \item {\tt sdreduce}
% 
%   Can crash if {\tt timeaverage=True} and/or {\tt polaverage=True}
%   and you give a
%   list of scans that contain a combination of IFs.  We need to make
%   the tools smarter about this, but in the meantime you should restrict
%   your scanlist and iflist to scans with the same set of IFs.

\item {\tt sdfit}

%  Handles multiple IFs poorly (a general problem currently in the package).
%
%  No way to input guesses.
Only way to handle multi-IFs is to set {\tt fitmode='auto'}
(linefinder is applied for each spectra and derives initial guesses).
For {\tt fitmode='list'}, there are no way to give initial guesses for each IFs by hand.

\item {\tt sdplot}

  Only handles the included JPL line catalog.  Also, see {\tt sd.plotter} issues above.

\item GBT raw SDFITS data

  The SDtasks and {\tt sd.scantable} are able to handle GBT raw SDFITS data format (version 1.3) data 
  since the data filler is available. However, the functionality is not well 
  tested yet, so that there may be unknown bugs.  

% FIXED for Patch 4
%\item {\tt sdstat}
%
%  Cannot return the location (channel, frequency, or velocity) of the
%  maximum or minimum.

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Single Dish Analysis Tasks}
\label{section:sd.sdtasks}

A set of single dish tasks is available for simplifying basic
reduction activities.  The list currently includes:

\begin{itemize}
 
\item {\bf sdcal} --- select, calibrate, and average SD data

\item {\bf sdcal2} --- generate sky and tsys caltables for SD data, and apply them 

\item {\bf sdsmooth} --- smooth SD spectra

\item {\bf sdbaseline} --- fit/remove spectral baselines from SD data

\item {\bf sdreduce} --- {\tt sdcal}, {\tt sdsmooth}, and {\tt sdbaseline} combined to perform standard single dish processing all at once 

\item {\bf sdcoadd} --- merge/co-add multiple SD data

\item {\bf sdflag} --- channel/row flagging of SD spectra

\item {\bf sdflag2} --- channel/row flagging of SD spectra (keeps all records in scantable)

\item {\bf sdflagmanager} --- enable list, save, restore, delete and rename flag version files

\item {\bf sdfit} --- line fitting to SD spectra

\item {\bf sdgrid} --- convolve map data onto regularly spaced grid

\item {\bf sdimaging} --- create an image from the total power or spectral data

\item {\bf sdlist} --- print a summary of a SD dataset

\item {\bf sdmath} --- do simple arithmetic for SD spectra 

\item {\bf sdplot} --- plotting of SD spectra, including overlay of line
catalog data

\item {\bf sdsave} --- save SD data to different format

\item {\bf sdscale} --- scale SD data
 
\item {\bf sdstat} --- compute statistics of regions of SD spectra

\item {\bf sdtpimaging} --- do a simple calibration and create an image from the total power raster scans

\item {\bf sdimprocess} --- remove the 'scanning noise' from raster scanned image  

\item {\bf msmoments} --- compute moments from spectral data

\end{itemize}

All of the SDtasks, except  those related to imaging  ({\tt sdtpimaging}, {\tt sdimaging}, and {\tt sdimprocess}), 
work from a file on disk rather than from
a scantable in memory as the ASAP toolkit does (see 
\S~\ref{section:sd.asap}).  Inside the tasks we invoke a call
to {\tt sd.scantable} to read the data.  The scantable objects
do not persist within CASA after completion of the tasks and
are destroyed to free up memory. 

Three tasks {\tt sdcal}, {\tt sdsmooth}, and {\tt sdbaseline} are the
workhorses for the calibration, selection,
averaging, baseline fitting, and smoothing. The output datasets for
each task are written to a file on disk.
Alternatively, one can use the task {\tt sdreduce} to perform all of the steps in
the three tasks described. 
Its operation is
controlled by three main "mode" parameters: {\tt calmode} (which selects
the type of calibration, if any, to be applied), {\tt kernel} (which selects
the smoothing), and {\tt blfunc} (which selects baseline fitting).  There
are also parameters controlling the selection such as {\tt scanlist}, 
{\tt iflist}, {\tt field}, {\tt scanaverage}, {\tt timeaverage}, and
{\tt polaverage}.  Note that {\tt sdreduce} can be
run with {\tt calmode='none'} to allow re-selection or writing out of data
that is already calibrated.  There is a "wiring diagram" of the dataflow and control inputs for
{\tt sdreduce} shown in Figure~\ref{fig:sdreduce}.

\begin{figure}[h!]
\begin{center}
%\pnghigh{sdcal_wiring_diagram}{7}
\pnghigh{sdreduce_wiring_diagram}{7}
\caption{\label{fig:sdreduce} Wiring diagram for the SDtask {\tt sdreduce}.
The stages of processing within the task are shown, along with the
parameters that control them. }
\hrulefill
\end{center}
\end{figure}

The SDtasks support the import and export file formats supported
by ASAP itself.  For import, this includes:  ASAP (scantables), 
MS (CASA Measurement Set), RPFITS, SDFITS (version 1.3) and NRO data format.  
For export, this includes: ASAP (scantables), MS (CASA Measurement Set),
ASCII (text file), SDFITS (a flavor of SD FITS).
The {\tt sdsave} task is available exclusively for exporting with these
data selection options.  The {\tt sdcoadd} task is available to merge data in separate data files
into one.  A brief summary of the data in a file is found in the {\tt sdlist}
task help.

Plotting of spectra is handled in the {\tt sdplot} task.  It also offers
some selection, averaging, and smoothing options in case you are
working from a dataset that has not been split or averaged.  Note that
there is some rudimentary plotting capability in many of SDtasks, 
controlled through the {\tt plotlevel} parameter, 
to aid in the assessment of the performance of these tasks.

Scaling of the spectra and Tsys is available in the {\tt sdscale}.
For arithmetic operations of spectra in separate scantables, {\tt sdmath}
has been added. 

Calculation of statistics on spectral regions is available in the {\tt sdstat} task.
%%Results are passed in a Python dictionary return variable {\tt xstat}.
Results are passed by a Python dictionary return variable.
The statistics of spectra can also be calculated via {\tt msmoments} task.
The input of {\tt msmoments} task must be in CASA Measurement Set format.
The task newly creates Measurement Set to store statistics values.

Basic Gaussian line-fitting is handled by the {\tt sdfit} task.  It can deal
with the simpler cases, and offers some automation as well as interactive 
selection of fitting region, but more complicated
fitting is best accomplished through the toolkit ({\tt sd.fitter}).

Basic interactive and non-interactive channel and row flagging are available 
in the {\tt sdflag}  and {\tt sdflag2} tasks. 
The flags in the input file is updated by default, i.e., {\tt outfile=''} 
and {\tt overwrite=True}. Otherwise, a new file is created to store dataset
with updated flag information.

Limited total power data analysis functionality is available through 
the task {\tt sdtpimaging}. A single dish image data cube can be created
using  {\tt sdimaging}, which also handles total power imaging.
These tasks directly access the Measurement Set without converting it to scantable format.
The {\tt sdimprocess} is intended to remove the 'scanning noise' from single dish
images by either the 'Basket-Weaving' or 'Pressed-out' methods.

The task {\tt sdgrid}, which convolves map data onto regularly 
spaced grid, is available. The task can be used as imaging tool although 
output of this task is not an image but a scantable. Also, it can be 
regarded as a data averaging tool with various weight. 

Although the Measurement Set can store data from multiple antennas
even if it consists of only single-dish spectra (auto-correlation data),
the scantable cannot distinguish data from multiple antennas. It causes
a problem when the user processes the Measurement Set using SDtasks.
Therefore, id or name of the antenna that the user want to process
must be explicitly specified if the input dataset for SDtasks is
Measurement Set. This can be done by {\tt antenna} parameter. By default
({\tt antenna}=0), data associate with antenna id 0 is imported.
The {\tt antenna} parameter takes no effect for other input data formats.

%\newpage 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{SDtask Summaries}
\label{section:sd.sdtasks.tasks}

The following are the list of parameters and
brief descriptions of each of the SDtasks.
These descriptions are also contained in {\tt help <taskname>}.

\subsubsection{{\tt sdcal}}
\label{section:sd.sdtasks.tasks.sdcal}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
fluxunit -- units for line flux
        options: 'K','Jy',''
        default: '' (keep current fluxunit)
        WARNING: For GBT data, see description below.

    >>> fluxunit expandable parameter
         telescopeparm -- the telescope characteristics
                 options: (str) name or (list) list of gain info
                 default: '' (none set)
                 example: if telescopeparm='', it tries to get the telescope
                          name from the data.
                          Full antenna parameters (diameter,ap.eff.) known
                          to ASAP are
                          'ATPKSMB', 'ATPKSHOH', 'ATMOPRA', 'DSS-43',
                          'CEDUNA','HOBART'. For GBT, it fixes default fluxunit
                          to 'K' first then convert to a new fluxunit.
                          telescopeparm=[104.9,0.43] diameter(m), ap.eff.
                          telescopeparm=[0.743] gain in Jy/K
                          telescopeparm='FIX' to change default fluxunit
                          see description below

specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz'
        default: '' (=current)
        example: this will be the units for masklist
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
calmode -- calibration mode
        options: 'ps','nod','otf','otfraster',
                 'fs','fsotf','quotient','none'
        default: 'none'
        example: choose mode 'none' if you have
                 already calibrated and want to
                 try averaging
        WARNING: 'fsotf' is not implemented yet
    >>> calmode expandable parameter
         fraction -- Edge marker parameter of 'otf' and 'otfraster'.
                    Specify a number of OFF integrations (at each
                    side of the raster rows in 'otfraster' mode)
                    as a fraction of total number of integrations.
                    In 'otfraster' mode, number of integrations 
                    to be marked as OFF, n_off, is determined by 
                    the following formula,

                       n_off = floor(fraction * n),

                    where n is number of integrations per raster 
                    row. Note that n_off from both sides will be  
                    marked as OFF so that twice of specified 
                    fraction will be marked at most. For example, 
                    if you specify fraction='10%', resultant 
                    fraction of OFF integrations will be 20% at 
                    most.
                    In 'otf' mode, n_off is given by,

                       n_off = floor(fraction * n),

                    where n is number of total integrations.
                    n_off is used as criterion of iterative marking
                    process. Therefore, resulting total number of 
                    OFFs will be larger than n_off. In practice,
                    fraction is a geometrical fraction of edge
                    region. Thus, if integrations are concentrated
                    on edge region (e.g. some of Lissajous
                    patterns), then resulting n_off may be 
                    unexpectedly large.
                 default: '10%'
                 options: '20%' in string style or float value less 
                          than 1.0 (e.g. 0.15).
                          'auto' is available only for 'otfraster'. 
         noff -- Edge marking parameter for 'otfraster'.
                 It is used to specify a number of OFF scans near 
                 edge directly. Value of noff comes before setting 
                 by fraction. Note that n_off from both sides will 
                 be marked as OFF so that twice of specified noff 
                 will be marked at most.
                 default: -1 (use fraction)
                 options: any positive integer
         width -- Edge marking parameter for 'otf'.
                  Pixel width with respect to a median spatial 
                  separation between neighboring two data in time.
                  Default will be fine in most cases.
                 default: 0.5
                 options: float value
         elongated -- Edge marking parameter for 'otf'.
                      Set True only if observed area is elongetad 
                      in one direction.
                 default: False
         markonly -- Set True if you want to save data just after 
                     edge marking (i.e. uncalibrated data) to see 
                     how OFF scans are defined.
                 default: False
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field, iflist, and pollist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, and pollist
iflist -- list of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to scanlist, field, and pollist
pollist -- list of polarization id numbers to select
        default: [] (use all polarizations)
        example: [1]
        this selection is in addition to scanlist, field, and iflist
channelrange -- channel range selection
        default: [] (use all channel)
        example: [0,5000]
        Note that specified values are recognized as 'channel'
        regardless of the value of specunit 
scanaverage -- average integrations within scans
        options: (bool) True,False
        default: False
timeaverage -- average times for multiple scan cycles
        options: (bool) True,False
        default: False
        example: if True, this happens after calibration

    >>>timeaverage expandable parameter
         tweight -- weighting for time average
                 options: 'none' 
                          'var'   (1/var(spec) weighted)
                          'tsys'  (1/Tsys**2 weighted)
                          'tint'  (integration time weighted)
                          'tintsys'  (Tint/Tsys**2)
                          'median'  ( median averaging)
                 default: 'none'

         averageall -- average multi-resolution spectra
                       spectra are averaged by referring 
                       their frequency coverage
                 default: False

polaverage -- average polarizations
        options: (bool) True,False
        default: False

    >>>polaverage expandable parameter
         pweight -- weighting for polarization average
                 options: 'none'
                          'var'  (1/var(spec) weighted)
                          'tsys' (1/Tsys**2 weighted)
                 default: 'none'

tau -- atmospheric optical depth
        default: 0.0 (no correction)
verify -- interactively verify the results of calibration. Only
          effective if calmode = 'ps' (but not for ALMA data),
          'otf', and 'nod'.
          When verify = True, spectra before and after calibration
          are displayed in a plot for six spectra in scantable.
          At the prompt there are two choices of action:
          'Y' (accept the calibration) and 'N' (reject the calibration).
          Note that when calibration is rejected by 'N', no
          calibration is done to the whole scantable.
        options: (bool) True,False
        default: False
outfile -- Name of output file
        default: '' (<infile>_cal)
outform -- format of output file
        options: 'ASCII','SDFITS','MS','ASAP'
        default: 'ASAP'
        example: the ASAP format is easiest for further sd
                 processing; use MS for CASA imaging.
                 If ASCII, then will append some stuff to
                 the outfile name
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
        WARNING: if outform='ASCII', this parameter is ignored
plotlevel -- control for plotting of results
        options: (int) 0=none, 1=some, 2=more, <0=hardcopy
        default: 0 (no plotting)
        example: plotlevel<0 as abs(plotlevel), e.g.
                 -1 => hardcopy of final plot (will be named
                 <outfile>_calspec.eps)
        WARNING: be careful plotting in fsotf mode!
\end{verbatim}

DESCRIPTION:

--------
OVERVIEW
--------
Task {\tt sdcal} performs data selection, calibration for single-dish
spectra.  By setting {\tt calmode}='none', one can run {\tt sdcal} on already 
calibrated data, for further selection , averaging and atmospheric 
optical depth correction. To save the output spectra in a certain
range of channels, you set the range in channelrange.

If you give multiple IFs in {\tt iflist}, then your scantable will have
multiple IFs by default. Averaging of multi-resolution (multi-IFs)
spectra can be achieved by setting a sub-parameter in {\tt timeaverage}, 
{\tt averageall}, to True. It handles multi-IFs by selecting overlaps in 
frequency coverages and assigning new IFs in the output spectra.

--------------------
FLUX UNIT CONVERSION
--------------------
The task is able to convert flux unit between K and Jy. To do that,
{\tt fluxunit} and its subparameter {\tt telescopeparm} must be properly set.
The {\tt fluxunit} should be 'Jy' or 'K' depending on what unit input
data is and what unit you want to convert. If given {\tt fluxunit} is
different from the unit of input data, unit conversion is performed.
The {\tt telescopeparm} is used to specify conversion factor. There are
three ways to specify {\tt telescopeparm}: 1) set Jy/K conversion factor,
2) set telescope diameter, D, and aperture efficiency, eta,
separately, and 3) 'FIX' mode (only change the unit without
converting spectral data). If you give {\tt telescopeparm} as a list,
then if the list has a single float it is assumed to be the gain
in Jy/K (case 1), if two or more elements they are assumed to be
telescope diameter (m) and aperture efficiency respectively
(case 2).
See the above parameter description as well as note on 'FIX' mode
below for details.
  
There are two special cases that don't need {\tt telescopeparm} for unit
conversion. Telescope name is obtained from the data.
1) ASAP (sd tool) recognizes the conversion factor (actually D and
   eta) for the "AT" telescopes, namely ATNF MOPRA telescope, until
   2004.
2) The task does know D and eta for GBT telescope.
If you wish to change the {\tt fluxunit}, by leaving the sub-parameter
{\tt telescopeparm} unset ({\tt telescopeparm}=''), it will use internal
telescope parameters for flux conversion for the data from AT
telescopes and it will use an approximate aperture efficiency
conversion for the GBT data.

Note that {\tt sdcal} assumes that the {\tt fluxunit} is set correctly in
the data already. If not, then set {\tt telescopeparm}='FIX' and it
will set the default units to {\tt fluxunit} without conversion.
Note also that, if the data in infile is an ms from GBT and the
default flux unit is missing, this task automatically fixes the
default {\tt fluxunit} to 'K' before the conversion.

---------------------
HOW TO CHOOSE CALMODE
---------------------
For position switching calibration, the user should choose
appropriate calibration mode depending on the data. Use case
for each mode is as follows:

    'ps': position switch (including OTF) with explicit
          reference (OFF) scans
    'otf': non-raster OTF scan without explicit OFFs
           (e.g. Lissajous, double circle, etc.)
           intends to calibrate fast scan data
    'otfraster': raster OTF scan without explicit OFFs

So, if the data contains explicit reference scans, 'ps' should
be used. Otherwise, 'otfraster' and 'otf' are appropriate for
raster OTF and non-raster OTF, respectively. In 'otf' and
'otfraster' modes, the task first try to find several integrations 
near edge as OFF scans, then the data are calibrated using those 
OFFs. If the observing pattern is raster, you 
should use the 'otfraster' mode to calibrate data. Otherwise, the 
'otf' mode should be used. For detail about edge marking, see 
inline help of sd.edgemarker module and its methods.
Those modes are designed for OTF observations without 
explicit OFF scans. However, these modes should work even if
explicit reference scans exist. In this case, explicit reference
scans will be ignored and scans near edges detected by edge
marker will be used as reference.

Except for how to choose OFFs, the procedure to derive calibrated
spectra is common for the
above three modes. Selected (or preset) OFF integrations are
separated by its continuity in time domain, averaged in
each segment, then interpolated to timestamps for ON integrations.
Effectively, it means that OFF integrations are averaged by each
OFF scans for 'ps' mode, averaged by either ends of each raster
row for 'otfraster' mode, averaged by each temporal segments of
detected edges for 'otf' mode. The formula for calibrated spectrum
is

    Tsys * (ON - OFF) / OFF. 

The 'fs' mode is for frequency switch calibration. Currently,
only GBT frequency switch data is supported.

The 'quotient' mode is special mode for "AT" telescopes, namely
ANNF MOPRA. It assumes that observing sequence looks like
"target, reference, target, reference,..." and it derives
calibrated spectrum as

    Tsys * ON / OFF,

slightly different from position switch modes.
  
-------
WARNING
-------
For the GBT raw SDFITS format data as input:
SDtasks are able to handle GBT raw SDFITS format data since the 
data filler is available. However, the functionality is not well 
tested yet, so that there may be unknown bugs. 

{\bf Notes:}
 \begin{itemize}
  \item Direction information is not considered when data is averaged. 
Use {\tt sdgrid} task if you want to take care of direction information 
when averaging.
  \item Calibration of frequency switching data is now fully implemented, including folding.
  \item Additional calibration algorithms are implemented. These are the
'Chopper-Wheel' calibration and the one adopted in APEX telescope (an advanced version of classical 'Chopper-Wheel' method). 
\end{itemize}


\subsubsection{{\tt sdcal2}}
\label{section:sd.sdtasks.tasks.sdcal2}

\begin{verbatim}
Keyword arguments:
infile -- Name of input SD dataset
calmode -- Calibration mode. If you want to generate calibration 
           table or apply existing calibration tables, set calmode 
           to simple string. On the other hand, if you want to 
           calibrate data on-the-fly, you have to set calmode 
           to a composite calmode string separated by comma.
           So far, sky calibration has three types, 'ps', 'otf',
           and 'otfraster'. If observation is configured to 
           observe reference position, calmode must be 'ps'. 
           Otherwise, 'otf' or 'otfraster' should be used
           depending on observing pattern. If observing pattern
           is raster scan, calmode must be 'otfraster' while 
           'otf' must be used when observing pattern is non-
           raster (e.g., Lissajous).
        options: 'ps','otf','otfraster','tsys','apply'
        default: 'ps'
        example: Here is an example for composite calmode.
                 'ps,apply' (do sky cal and apply)
                 'ps,tsys,apply' (do sky and Tsys cal and apply)
    >>> calmode expandable parameter
         fraction -- Edge marker parameter of 'otf' and 'otfraster'.
                     Specify a number of OFF integrations (at each
                     side of the raster rows in 'otfraster' mode)
                     as a fraction of total number of integrations.
                     In 'otfraster' mode, number of integrations 
                     to be marked as OFF, n_off, is determined by 
                     the following formula,

                        n_off = floor(fraction * n),

                     where n is number of integrations per raster 
                     row. Note that n_off from both sides will be  
                     marked as OFF so that twice of specified 
                     fraction will be marked at most. For example, 
                     if you specify fraction='10%', resultant 
                     fraction of OFF integrations will be 20% at 
                     most.
                     In 'otf' mode, n_off is given by,

                        n_off = floor(fraction * n),
 
                     where n is number of total integrations.
                     n_off is used as criterion of iterative marking
                     process. Therefore, resulting total number of 
                     OFFs will be larger than n_off. In practice,
                     fraction is a geometrical fraction of edge
                     region. Thus, if integrations are concentrated
                     on edge region (e.g. some of Lissajous
                     patterns), then resulting n_off may be 
                     unexpectedly large.
                 default: '10%'
                 options: '20%' in string style or float value less 
                          than 1.0 (e.g. 0.15).
                          'auto' is available only for 'otfraster' 
         noff -- Edge marking parameter for 'otfraster'.
                 It is used to specify a number of OFF scans near 
                 edge directly. Value of noff comes before setting 
                 by fraction. Note that n_off from both sides will 
                 be marked as OFF so that twice of specified noff 
                 will be marked at most.
                 default: -1 (use fraction)
                 options: any positive integer
         width -- Edge marking parameter for 'otf'.
                  Pixel width with respect to a median spatial 
                  separation between neighboring two data in time.
                  Default will be fine in most cases.
                 default: 0.5
                 options: float value
         elongated -- Edge marking parameter for 'otf'.
                      Set True only if observed area is elongated 
                      in one direction.
                 default: False
         tsysiflist -- List of IFNOs for Tsys calibration. It does 
                       no effect if you don't want to do Tsys 
                       calibration.
                 default: []
         applytable -- List of sky/Tsys calibration tables you want to 
                       apply.
                 default: ''
         interp -- Interpolation method in time and frequency axis. 
                   Set comma separated method strings if you want 
                   to use different interpolation in time and 
                   frequency. 
                 options: 'linear', 'cspline', 'nearest', 
                          any numeric string indicating an order 
                          of polynomial.
                 default: '' (linear in time and frequency)
                 example: 'linear,cspline' (linear in time, cubic 
                                            spline in frequency)
                          'linear,3' (linear in time, third order 
                                      polynomial in frequency)
                          'nearest' (nearest in time and frequency)
         ifmap -- Dictionary defining transfer of Tsys calibration. 
                  Key must be IFNO for Tsys and its value must be 
                  a list of IFNOs for science target.
                 default: {}
                 example: {1: [5,6], 3: [7,8]}
                          Tsys in IFNO1 is transferred to IFNO5, 6 
                          while Tsys in IFNO3 is to IFNO7, 8.
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field, iflist, and pollist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
                 default: '' (linear in time and frequency)
                 example: 'linear,cspline' (linear in time, cubic 
                                            spline in frequency)
                          'linear,3' (linear in time, third order 
                                      polynomial in frequency)
                          'nearest' (nearest in time and frequency)
         ifmap -- Dictionary defining transfer of Tsys calibration. 
                  Key must be IFNO for Tsys and its value must be 
                  a list of IFNOs for science target.
                 default: {}
                 example: {1: [5,6], 3: [7,8]}
                          Tsys in IFNO1 is transferred to IFNO5, 6 
                           while Tsys in IFNO3 is to IFNO7, 8.
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field, iflist, and pollist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, and pollist
iflist -- list of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to scanlist, field, and pollist
pollist -- list of polarization id numbers to select
        default: [] (use all polarizations)
        example: [1]
        this selection is in addition to scanlist, field, and iflist
outfile -- Name of output file. If you omit, behavior of the task 
           depends on calmode. If calmode includes 'apply', then 
           omitting outfile indicates that infile is overwritten 
           by the calibrated data. In this case, you have to set 
           overwrite to True. If calmode doesn't include 'apply', 
           omitting outfile indicates that the task will use default 
           outfile name based on infile and predefined suffix 
           ('_sky' for sky, '_tsys' for Tsys).
        default: '' (<infile>_<suffix> for calibration 
                     while overwrite infile for apply mode)
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False

\end{verbatim}

DESCRIPTION:

Task {\tt sdcal2} is an implementation of a calibration scheme like as 
interferometry, i.e., generate caltables and apply them. Available 
calibration modes are 'ps', 'otf', 'otfraster', and 'tsys'. Those 
modes generates caltables for sky or Tsys calibration. Those 
caltables can be applied to the data by using {\tt calmode} 'apply'.

The above three calibration modes, 'ps', 'otf', and 'otfraster',
generate sky calibration tables. The user should choose
appropriate calibration mode depending on the data. Use case
for each mode is as follows:

    'ps': position switch (including OTF) with explicit
          reference (OFF) scans
    'otf': non-raster OTF scan without explicit OFFs
           (e.g. Lissajous, double circle, etc.)
           intends to calibrate fast scan data
    'otfraster': raster OTF scan without explicit OFFs

So, if the data contains explicit reference scans, 'ps' should
be used. Otherwise, 'otfraster' and 'otf' are appropriate for
raster OTF and non-raster OTF, respectively. In 'otf' and
'otfraster' modes, the task first try to find several integrations 
near edge as OFF scans, then the data are calibrated using those 
OFFs. If the observing pattern is raster, you 
should use the 'otfraster' mode to calibrate data. Otherwise, the 
'otf' mode should be used. For detail about edge marking, see 
inline help of sd.edgemarker module and its methods.
Those modes are designed for OTF observations without 
explicit OFF scans. However, these modes should work even if
explicit reference scans exist. In this case, explicit reference
scans will be ignored and scans near edges detected by edge
marker will be used as reference.

Except for how to choose OFFs, the procedure to derive calibrated
spectra is common for the
above three modes. Selected (or preset) OFF integrations are
separated by its continuity in time domain, averaged in
each segment, then interpolated to timestamps for ON integrations.
Effectively, it means that OFF integrations are averaged by each
OFF scans for 'ps' mode, averaged by either ends of each raster
row for 'otfraster' mode, averaged by each temporal segments of
detected edges for 'otf' mode. The formula for calibrated spectrum
is

    Tsys * (ON - OFF) / OFF. 
  
You can calibrate data on-the-fly like {\tt sdcal} task by setting 
{\tt calmode} to a composite calmode string separated by comma. 
For example, {\tt calmode}='ps,apply' means doing sky calibration and 
apply it on-the-fly. In this case, caltable is generated as a 
temporary plain table and will be deleted at the end.
Allowed calibration modes in this task are as follows:
  
    ps
        generate sky caltable using 'ps' mode
    otf
        generate sky caltable using 'otf' mode
    otfraster
        generate sky caltable using 'otfraster' mode
    tsys
        generate tsys caltable
    apply
        apply caltables specified by applytable parameter
    ps,apply
        generate temporary sky caltable using 'ps' mode and
        apply it. also apply caltables specified by applytable 
    ps,tsys,apply
        generate temporary sky caltable using 'ps' mode as well
        as temporary tsys caltable, and apply them. 
    otf,apply
        generate temporary sky caltable using 'otf' mode and
        apply it. also apply caltables specified by applytable 
    otf,tsys,apply
        generate temporary sky caltable using 'otf' mode as well
        as temporary tsys caltable, and apply them. 
    otfraster,apply
        generate temporary sky caltable using 'otfraster' mode
        and apply it. also apply caltables specified by applytable 
    otfraster,tsys,apply
        generate temporary sky caltable using 'otfraster' mode
        as well as temporary tsys caltable, and apply them. 

There are several control parameters for sky/Tsys calibration and 
application of caltables. See the above parameter description.

\subsubsection{{\tt sdsmooth}}
\label{section:sd.sdtasks.tasks.sdsmooth}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
scanaverage -- average integrations within scans
        options: (bool) True,False
        default: False
        example: if True, this happens in read-in
                 For GBT, set False!
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field, iflist, and pollist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist,pollist
iflist -- list of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to scanlist, field, and pollist
pollist -- list of polarization id numbers to select
        default: [] (use all polarizations)
        example: [1]
        this selection is in addition to scanlist, field, and iflist
kernel -- type of spectral smoothing
        options: 'hanning','gaussian','boxcar','regrid'
        default: 'hanning'

    >>>kernel expandable parameter
         kwidth -- width of spectral smoothing kernel
                 options: (int) in channels 
                 default: 5
                 example: 5 or 10 seem to be popular for boxcar
                          ignored for hanning (fixed at 5 chans)
                          (0 will turn off gaussian or boxcar)
         chanwidth -- channel width of regridded spectra
                 default: '5' (in channels)
                 example: '500MHz', '0.2km/s'

verify -- interactively verify the results of smoothing for each
          spectrum.
          When verify = True, for each input spectrum, spectra
          before and after the smoothing are displayed in a plot
          window. At the prompt there are four choices of action:
          'Y' (accept the smoothing and continue to the next input
          spectrum), 'N' (reject the smoothing and continue to the
          next input spectrum), 'A' (accept the current smoothing
          and continue non-interactively), and 'R' (reject the
          current smoothing and exit from smoothing).
          Note that when the smoothing is rejected by 'N' or 'R',
          no smoothing is done to the spectrum/spectra. 
        options: (bool) True,False
        default: False
        Note: verification is not yet available for kernel='regrid'
outfile -- Name of output ASAP format(scantable) file
        default: '' (<infile>_sm)
outform -- format of output file
        options: 'ASCII','SDFITS','MS','ASAP'
        default: 'ASAP'
        example: the ASAP format is easiest for further sd
                 processing; use MS for CASA imaging.
                 If ASCII, then will append some stuff to
                 the outfile name
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
        WARNING: if outform='ASCII', this parameter is ignored
plotlevel -- control for plotting of results
        options: (int) 0=none, 1=some, 2=more, <0=hardcopy
        default: 0 (no plotting)
        example: plotlevel<0 as abs(plotlevel), e.g.
                 -1 => hardcopy of final plot (will be named
                 <outfile>_smspec.eps)
\end{verbatim}

    DESCRIPTION:

Task {\tt sdsmooth} performs smoothing of the single-dish spectra.
Set {\tt plotlevel >= 1} to plot the spectrum before and after smoothing.
    
See the {\tt sdcal} description for note on GBT raw SDFITS format data.

 
\subsubsection{{\tt sdbaseline}}
\label{section:sd.sdtasks.tasks.sdbaseline}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
fluxunit -- units for line flux
        options: 'K','Jy',''
        default: '' (keep current fluxunit)
        WARNING: For GBT data, see description below.
    >>> fluxunit expandable parameter
         telescopeparm -- the telescope characteristics
                options: (str) name or (list) list of gain info
                default: '' (none set)
                example: if telescopeparm='', it tries to get the telescope
                         name from the data.
                         Full antenna parameters (diameter,ap.eff.) known
                         to ASAP are
                         'ATPKSMB', 'ATPKSHOH', 'ATMOPRA', 'DSS-43',
                         'CEDUNA','HOBART'. For GBT, it fixes default fluxunit
                         to 'K' first then convert to a new fluxunit.
                         telescopeparm=[104.9,0.43] diameter(m), ap.eff.
                         telescopeparm=[0.743] gain in Jy/K
                         telescopeparm='FIX' to change default fluxunit
                         see description below
specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz',''
        default: '' (=current)
        example: this will be the units for masklist
    >>> specunit expandable parameters
         restfreq -- rest frequency
                 available type includes float, int, string, list of float, 
                 list of int, list of string, and list of dictionary. the 
                 default unit of restfreq in case of float, int, or string 
                 without unit is Hz. string input can be a value only 
                 (treated as Hz) or a value followed by unit for which 'GHz',
                 'MHz','kHz',and 'Hz' are available. 
                 a list can be used to set different rest frequencies for 
                 each IF. the length of list input must be nIF. dictionary 
                 input should be a pair of molecule name and frequency with 
                 keys of 'name' and 'value', respectively. values in the 
                 dictionary input follows the same manner as for single 
                 float or string input. 
                 example: 345.796
                          '1420MHz'
                          [345.8, 347.0, 356.7]
                          ['345.8MHz', '347.0MHz', '356.7MHz']
                          [{'name':'CO','value':345}]
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field, iflist, and pollist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, and pollist
iflist -- list of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to scanlist, field, and pollist
pollist -- list of polarization id numbers to select
        default: [] (use all polarizations)
        example: [1]
        this selection is in addition to scanlist, field, and iflist
tau -- atmospheric optical depth
        default: 0.0 (no correction)
masklist -- list or string of mask regions to INCLUDE in BASELINE fit
            a string masklist allows per IF selection of channels.
        default: [] (entire spectrum)
        example: [[1000,3000],[5000,7000]]
                 '0:1000~3000;5000~7000, 1:200~350;450~600'
                 when maskmode is 'auto' or 'interact', this mask 
                 will be applied first before fitting as base mask
maskmode -- mode of setting additional channel masks
        options: (str) 'auto','list','interact'
        default: 'auto'
        example: maskmode='auto' runs linefinder to detect line regions 
                 to be excluded from fitting. this mode requires three 
                 expandable parameters: thresh, avg_limit, and edge.
                 USE WITH CARE! May need to tweak the expandable parameters.
                 maskmode='list' uses the given masklist only: no additional 
                 masks applied.
                 maskmode='interact' allows users to manually modify the 
                 mask regions by dragging mouse on the spectrum plotter GUI.
                 use LEFT or RIGHT button to add or delete regions, 
                 respectively.
       
    >>> maskmode expandable parameters
         thresh -- S/N threshold for linefinder
                 default: 5
                 example: a single channel S/N ratio above which the channel is
                          considered to be a detection
         avg_limit -- channel averaging for broad lines
                 default: 4
                 example: a number of consecutive channels not greater than
                          this parameter can be averaged to search for broad lines
         edge -- channels to drop at beginning and end of spectrum
                 default: 0
                 example: [1000] drops 1000 channels at beginning AND end
                          [1000,500] drops 1000 from beginning and 500 from end
         Note: For bad baselines threshold should be increased,
         and avg_limit decreased (or even switched off completely by
         setting this parameter to 1) to avoid detecting baseline
         undulations instead of real lines.
blfunc -- baseline model function
        options: (str) 'poly','chebyshev','cspline','sinusoid'
        default: 'poly'
        example: blfunc='poly' uses a single polynomial line of 
                 any order which should be given as an expandable 
                 parameter 'order' to fit baseline. 
                 blfunc='chebyshev' uses Chebyshev polynomials. 
                 blfunc='cspline' uses a cubic spline function, a piecewise 
                 cubic polynomial having C2-continuity (i.e., the second 
                 derivative is continuous at the joining points). 
                 blfunc='sinusoid' uses a combination of sinusoidal curves. 
    >>> blfunc expandable parameters
         order -- order of baseline polynomial
                 options: (int) (<0 turns off baseline fitting)
                 default: 5
                 example: typically in range 2-9 (higher values
                          seem to be needed for GBT)
         npiece -- number of the element polynomials of cubic spline curve
                 options: (int) (<0 turns off baseline fitting)
                 default: 2
         applyfft -- automatically set wave numbers of sinusoidal functions 
                 for fitting by applying some method like FFT.
                 options: (bool) True, False
                 default: True
         fftmethod -- method to be used when applyfft=True. Now only 
                 'fft' is available and it is the default.
         fftthresh -- threshold to select wave numbers to be used for 
                 sinusoidal fitting. both (float) and (str) accepted.
                 given a float value, the unit is set to sigma.
                 for string values, allowed formats include:
                   'xsigma' or 'x' (= x-sigma level. e.g., '3sigma'), or
                   'topx' (= the x strongest ones, e.g. 'top5').
                 default is 3.0 (unit: sigma).
         addwn -- additional wave number(s) of sinusoids to be used 
                 for fitting. 
                 (list) and (int) are accepted to specify every
                 wave numbers. also (str) can be used in case
                 you need to specify wave numbers in a certain range,
                 e.g., 'a-b' (= a, a+1, a+2, ..., b-1, b),
                       '<a'  (= 0,1,...,a-2,a-1),
                       '>=a' (= a, a+1, ... up to the maximum wave
                              number corresponding to the Nyquist
                              frequency for the case of FFT).
                 default: [0] (i.e., constant is subtracted at least)
         rejwn -- wave number(s) of sinusoid NOT to be used for fitting.
                 can be set just as addwn but has higher priority:
                 wave numbers which are specified both in addwn
                 and rejwn will NOT be used. 
                 default: []
         clipthresh -- clipping threshold for iterative fitting
                 default: 3
         clipniter -- maximum iteration number
                 default: 0 (no iteration, i.e., no clipping)
verify -- interactively verify the results of baseline fitting for each spectrum.
          When verify = True, for each input spectrum the baseline
          fit function and spectra before and after the fit are 
          displayed in a plot window. At the prompt there are four
          choices of action: 'Y' (accept the fit and continue to the
          next input spectrum), 'N' (reject the fit and continue to the
          next input spectrum), 'A' (accept the current fit and continue
          non-interactively), and 'R' (reject the current fit and exit
          from baseline fitting).
          Note that when the baseline fit is rejected by 'N' or 'R',
          no baseline fit is applied to the spectrum/spectra. 
        options: (bool) True,False
        default: False
        NOTE: Currently available only when blfunc='poly'
verbose -- output fitting results to logger
        default: True
        example: If False, the fitting results including coefficients, 
                 residual rms, etc., are not output to the CASA logger, 
                 while the processing speed gets faster
bloutput -- output fitting results to a text file
        default: True
        example: If False, the fitting results including coefficients, 
                 residual rms, etc., are not output to a text file 
                 (<outfile>_blparam.txt), while the processing 
                 speed gets faster
blformat -- format of the logger output and text file specified with bloutput
        options: '', 'csv'
        default: '' (same as in the past, easy to read but huge)
showprogress -- show progress status for large data
        default: True
minnrow -- minimum number of input spectra to show progress status
        default: 1000
outfile -- Name of output file
        default: '' (<infile>_bs)
outform -- format of output file
        options: 'ASCII','SDFITS','MS','ASAP'
        default: 'ASAP'
        example: the ASAP format is easiest for further sd
                 processing; use MS for CASA imaging.
                 If ASCII, then will append some stuff to
                 the outfile name
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
        WARNING: if outform='ASCII', this parameter is ignored
plotlevel -- control for plotting of results
        options: (int) 0=none, 1=some, 2=more, <0=hardcopy
        default: 0 (no plotting)
        example: plotlevel<0 as abs(plotlevel), e.g.
                 -1 => hardcopy of final plot (will be named
                <outfile>_bspec.eps)
        WARNING: be careful plotting in fsotf mode!

\end{verbatim}

DESCRIPTION:

Task {\tt sdbaseline} performs baseline fitting/removal for single-dish spectra.
The fit parameters, terms and rms of baseline are saved to an ASCII
file, {\tt <outfile>\_blparam.txt}.

See the {\tt sdcal} description for information on {\tt fluxunit} 
conversion and the {\tt telescopeparm} parameter.
Also, see the {\tt sdcal} description for note on GBT raw SDFITS format data.

%%%%% Additional description %%%%%
By setting {\tt maskmode='interact'}, you can set/unset mask regions interactively using
mouse buttons. Current mask regions will be shown with yellow shading.
Baseline fit parameters and rms of fitted spectra are saved to an
ASCII file, {\tt <outfile>\_blparam.txt}, when {\tt verbose=True}.

The parameter {\tt masklist} accepts per IF selection of mask regions. 
See \S~\ref{section:io.selection.spw.channel} for details. 
Note, the mask regions should be specified in unit of {\tt specunit} 
in this task.

Available functions for baseline subtraction include polynomial, Chebyshev polynomials, 
cubic spline, and sinusoid. 
Also, iterative n-$\sigma$ clipping becomes available with cubic spline and sinusoid. 


\subsubsection{{\tt sdreduce}}
\label{section:sd.sdtasks.tasks.sdreduce}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
fluxunit -- units for line flux
        options: 'K','Jy',''
        default: '' (keep current fluxunit)
        WARNING: For GBT data, see description below.
    >>> fluxunit expandable parameter
         telescopeparm -- the telescope characteristics
                options: (str) name or (list) list of gain info
                default: '' (none set)
                example: if telescopeparm='', it tries to get the telescope
                         name from the data.
                         Full antenna parameters (diameter,ap.eff.) known
                         to ASAP are
                         'ATPKSMB', 'ATPKSHOH', 'ATMOPRA', 'DSS-43',
                         'CEDUNA','HOBART'. For GBT, it fixes default fluxunit
                         to 'K' first then convert to a new fluxunit.
                         telescopeparm=[104.9,0.43] diameter(m), ap.eff.
                         telescopeparm=[0.743] gain in Jy/K
                         telescopeparm='FIX' to change default fluxunit
                         see description below

specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz',''
        default: '' (=current)
        example: this will be the units for masklist
    >>> specunit expandable parameters
         restfreq -- rest frequency
                 available type includes float, int, string, list of float, 
                 list of int, list of string, and list of dictionary. the 
                 default unit of restfreq in case of float, int, or string 
                 without unit is Hz. string input can be a value only 
                 (treated as Hz) or a value followed by unit for which 'GHz',
                 'MHz','kHz',and 'Hz' are available. 
                 a list can be used to set different rest frequencies for 
                 each IF. the length of list input must be nIF. dictionary 
                 input should be a pair of molecule name and frequency with 
                 keys of 'name' and 'value', respectively. values in the 
                 dictionary input follows the same manner as for single 
                 float or string input. 
                 example: 345.796
                          '1420MHz'
                          [345.8, 347.0, 356.7]
                          ['345.8MHz', '347.0MHz', '356.7MHz']
                          [{'name':'CO','value':345}]
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
calmode -- calibration mode
        options: 'ps','nod','fs','fsotf','quotient','none'
        default: 'none'
        example: choose mode 'none' if you have
                 already calibrated and want to
                 try baselines or averaging
    >>> calmode expandable parameter
         fraction -- Edge marking parameter for 'otf' and 'otfraster'.
                     specify a number of OFF scans as a fraction of 
                     total number of data points. 
                 default: '10%'
                 options: '20%' in string style or float value less 
                          than 1.0 (e.g. 0.15).
                          'auto' is available only for 'otfraster'. 
         noff -- Edge marking parameter for 'otfraster'.
                 It is used to specify a number of OFF scans near 
                 edge directly. Value of noff comes before setting 
                 by fraction.
                 default: -1 (use fraction)
                 options: any positive integer
         width -- Edge marking parameter for 'otf'.
                  Pixel width with respect to a median spatial 
                  separation between neighboring two data in time.
                  Default will be fine in most cases.
                 default: 0.5
                 options: float value
         elongated -- Edge marking parameter for 'otf'.
                      Set True only if observed area is elongated 
                      in one direction.
                 default: False
         markonly -- Set True if you want to save data just after 
                     edge marking (i.e. uncalibrated data) to see 
                     how OFF scans are defined.
                 default: False
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field, iflist, and pollist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, and pollist
iflist -- list of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to scanlist, field, and pollist
pollist -- list of polarization id numbers to select
        default: [] (use all polarizations)
        example: [1]
        this selection is in addition to scanlist, field, and iflist
channelrange -- channel range selection
        default: [] (use all channel)
        example: [0,5000]
        Note that specified values are recognized as 'channel' 
        regardless of the value of specunit 
average -- averaging on spectral data 
        options: (bool) True,False
        default: False

    >>>average expandable parameter
         scanaverage -- average integrations within scans
                 options: (bool) True,False
                 default: False
                 example: if True, this happens in read-in
                 For GBT, set False!
         timeaverage -- average times for multiple scan cycles
                 options: (bool) True,False
                 default: False
                 example: if True, this happens after calibration
         tweight -- weighting for time average
                 options: 'none'
                          'var'   (1/var(spec) weighted)
                          'tsys'  (1/Tsys**2 weighted)
                          'tint'  (integration time weighted)
                          'tintsys'  (Tint/Tsys**2)
                          'median'  ( median averaging)
                 default: 'none'
         averageall -- average multi-resolution spectra
                       spectra are averaged by referring 
                       their frequency coverage
                 default: False
         polaverage -- average polarizations
                 options: (bool) True,False
                 default: False
         pweight -- weighting for polarization average
                 options: 'none'
                          'var'  (1/var(spec) weighted)
                          'tsys' (1/Tsys**2 weighted)

tau -- atmospheric optical depth
        default: 0.0 (no correction)
kernel -- type of spectral smoothing
        options: 'none','hanning','gaussian','boxcar','regrid'
        default: 'none' (no smoothing)

    >>>kernel expandable parameter
         kwidth -- width of spectral smoothing kernel
                 options: (int) in channels
                 default: 5
                 example: 5 or 10 seem to be popular for boxcar
                          ignored for hanning (fixed at 5 chans)
                          (0 will turn off gaussian or boxcar)
         chanwidth -- channel width of regridded spectra
                 default: '5' (in channels)
                 example: '500MHz', '0.2km/s'
masklist -- list or string of mask regions to INCLUDE in BASELINE fit
            a string masklist allows per IF selection of channels.
        default: [] (entire spectrum)
        example: [[1000,3000],[5000,7000]]
                 '0:1000~3000;5000~7000, 1:200~350;450~600'
                 when maskmode is 'auto' or 'interact', this mask 
                 will be applied first before fitting as base mask
maskmode -- mode of setting additional channel masks for baselining
        options: (str) 'auto','list','interact'
        default: 'auto'
        example: maskmode='auto' runs linefinder to detect line regions 
                 to be excluded from fitting. this mode requires three 
                 expandable parameters: thresh, avg_limit, and edge.
                 USE WITH CARE! May need to tweak the expandable parameters.
                 maskmode='list' uses the given masklist only: 
                 no additional masks applied.
                 maskmode='interact' allows users to manually modify the 
                 mask regions by dragging mouse on the spectrum plotter GUI.
                 use LEFT or RIGHT button to add or delete regions, 
                 respectively.

    >>> maskmode expandable parameters
         thresh -- S/N threshold for linefinder
                 default: 5
                 example: a single channel S/N ratio above which the channel is
                          considered to be a detection
         avg_limit -- channel averaging for broad lines
                 default: 4
                 example: a number of consecutive channels not greater than
                          this parameter can be averaged to search for broad lines
         edge -- channels to drop at beginning and end of spectrum
                 default: 0
                 example: [1000] drops 1000 channels at beginning AND end
                          [1000,500] drops 1000 from beginning and 500 from end

         Note: For bad baselines threshold should be increased,
         and avg_limit decreased (or even switched off completely by
         setting this parameter to 1) to avoid detecting baseline
         undulations instead of real lines.

blfunc -- baseline model function
        options: (str) 'none','poly','chebyshev','cspline','sinusoid'
        default: 'none' (no baselining)
        example: blfunc='poly' uses a single polynomial line of 
                 any order which should be given as an expandable 
                 parameter 'order' to fit baseline. 
                 blfunc='chebyshev' uses Chebyshev polynomials. 
                 blfunc='cspline' uses a cubic spline function, a piecewise 
                 cubic polynomial having C2-continuity (i.e., the second 
                 derivative is continuous at the joining points).
                 blfunc='sinusoid' uses a combination of sinusoidal curves. 
    >>> blfunc expandable parameters
         order -- order of baseline polynomial
                 options: (int) (<0 turns off baseline fitting)
                 default: 5
                 example: typically in range 2-9 (higher values
                          seem to be needed for GBT)
         npiece -- number of the element polynomials of cubic spline curve
                 options: (int) (<0 turns off baseline fitting)
                 default: 2
         applyfft -- automatically set wave numbers of sinusoidal functions
                 for fitting by applying some method like FFT.
                 options: (bool) True, False
                 default: True
         fftmethod -- method to be used when applyfft=True. Now only
                 'fft' is available and it is the default.
         fftthresh -- threshold to select wave numbers to be used for
                 sinusoidal fitting. both (float) and (str) accepted.
                 given a float value, the unit is set to sigma.
                 for string values, allowed formats include:
                     'xsigma' or 'x' (= x-sigma level. e.g., '3sigma'), or
                     'topx' (= the x strongest ones, e.g. 'top5').
                 default is 3.0 (unit: sigma).
         addwn -- additional wave number(s) of sinusoids to be used
                 for fitting.
                 (list) and (int) are accepted to specify every
                 wave numbers. also (str) can be used in case
                 you need to specify wave numbers in a certain range,
                 e.g., 'a-b' (= a, a+1, a+2, ..., b-1, b),
                       '<a'  (= 0,1,...,a-2,a-1),
                       '>=a' (= a, a+1, ... up to the maximum wave
                              number corresponding to the Nyquist
                              frequency for the case of FFT).
                 default: []
         rejwn -- wave number(s) of sinusoid NOT to be used for fitting.
                 can be set just as addwn but has higher priority:
                 wave numbers which are specified both in addwn
                 and rejwn will NOT be used.
                 default: []
         clipthresh -- clipping threshold for iterative fitting
                 default: 3
         clipniter -- maximum iteration number
                 default: 0 (no iteration, i.e., no clipping)

verifycal -- interactively verify the results of calibration
          See description of verify parameter in the task, sdcal,
          for details.
        options: (bool) True,False
        default: False
verifysm -- interactively verify the results of smoothing for each
            spectrum.
          See description of verify parameter in the task, sdsmooth,
          for details.
        options: (bool) True,False
        default: False
        Note: verification is not yet available for kernel='regrid'
verifybl -- interactively verify the results of baseline fitting for
            each spectrum.
          See description of verify parameter in the task, sdbaseline,
          for details.
        options: (bool) True,False
        default: False
        NOTE: Currently available only when blfunc='poly'
verbosebl -- output fitting results to logger
        default: True
        example: If False, the fitting results including coefficients, 
                 residual rms, etc., are not output to the CASA logger, 
                 while the processing speed gets faster
bloutput -- output fitting results to a text file
        default: True
        example: If False, the fitting results including coefficients, 
                 residual rms, etc., are not output to a text file 
                 (<outfile>_blparam.txt), while the processing 
                 speed gets faster
blformat -- format of the logger output and text file specified with bloutput
        options: '', 'csv'
        default: '' (same as in the past, easy to read but huge)
showprogress -- show progress status for large data
        default: True
minnrow -- minimum number of input spectra to show progress status
        default: 1000
outfile -- Name of output file
        default: '' (<infile>_cal)
outform -- format of output file
        options: 'ASCII','SDFITS','MS','ASAP'
        default: 'ASAP'
        example: the ASAP format is easiest for further sd
                 processing; use MS for CASA imaging.
                 If ASCII, then will append some stuff to
                 the outfile name
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
        WARNING: if outform='ASCII', this parameter is ignored
plotlevel -- control for plotting of results
        options: (int) 0=none, 1=some, 2=more, <0=hardcopy
        default: 0 (no plotting)
        example: plotlevel<0 as abs(plotlevel), e.g.
                 -1 => hardcopy of final plot (will be named
                 <outfile>_calspec.eps)
        WARNING: be careful plotting in fsotf mode!
\end{verbatim}
    
DESCRIPTION:

Task {\tt sdreduce} performs data selection, calibration, and/or spectral
baseline fitting for single-dish spectra. This task internally calls the
tasks, {\tt sdcal}, {\tt sdsmooth}, and {\tt sdbaseline} and it can be used to run all the
three steps in one task execution.
By setting {\tt calmode='none'}, one can run {\tt sdreduce} on already calibrated data,
for further selection, averaging and atmospheric optical depth correction.
To save the output spectra in a certain range of channels, you set the 
range in {\tt channelrange}.

If you give multiple IFs in iflist, then your scantable will have
multiple IFs by default. Averaging of multi-resolution (multi-IFs)
spectra can be achieved by setting a sub-parameter of {\tt average}, 
{\tt averageall}, to {\tt True}. It handles multi-IFs by selecting overlaps in 
frequency coverages and assigning new IFs in the output spectra.

See the {\tt sdcal} description for information on the {\tt fluxunit} 
conversion and the {\tt telescopeparm} parameter.
Also, see the {\tt sdcal} description for note on GBT raw SDFITS format data.

%%%%% Additional Descriptions %%%%%
The {\tt verifycal}, {\tt verifysm}, and {\tt verifybl}  parameters correspond to parameter
{\tt  verify} in {\tt sdcal}, {\tt sdsmooth}, and {\tt sdbaseline}, respectively. 
    

The parameter {\tt masklist} accepts per IF selection of mask regions. 
See \S~\ref{section:io.selection.spw.channel} for details. 
Note, the mask regions should be specified in unit of {\tt specunit} 
in this task.



\subsubsection{{\tt sdcoadd}}
\label{section:sd.sdtasks.tasks.sdcoadd}

\begin{verbatim}
Keyword arguments:
infiles -- list of names of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
fluxunit -- units for line flux
        options: 'K','Jy',''
        default: '' (keep current fluxunit of the first data in the infiles)

    >>> fluxunit expandable parameter
         telescopeparm -- the telescope characteristics
                 options: (str) name or (list) list of gain info
                 default: '' (none set)
                 example: if telescopeparm='', it tries to get the telescope
                          name from the data.
                          Full antenna parameters (diameter,ap.eff.) known
                          to ASAP are
                          'ATPKSMB', 'ATPKSHOH', 'ATMOPRA', 'DSS-43',
                          'CEDUNA','HOBART'. For GBT, it fixes default fluxunit
                          to 'K' first then convert to a new fluxunit.
                          telescopeparm=[104.9,0.43] diameter(m), ap.eff.
                          telescopeparm=[0.743] gain in Jy/K
                          telescopeparm='FIX' to change default fluxunit
                          see description below

specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz'
        default: '' (=current)
        example: this will be the units for masklist
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
scanaverage -- average integrations within scans
        options: (bool) True,False
        default: False
        example: if True, this happens in read-in
        For GBT, set False!
timeaverage -- average times for multiple scan cycles
        options: (bool) True,False
        default: False
        example: if True, this happens after calibration

    >>>timeaverage expandable parameter
         tweight -- weighting for time average
                 options: 'none' 
                          'var'   (1/var(spec) weighted)
                          'tsys'  (1/Tsys**2 weighted)
                          'tint'  (integration time weighted)
                          'tintsys'  (Tint/Tsys**2)
                          'median'  ( median averaging)
                 default: 'none'

polaverage -- average polarizations
        options: (bool) True,False
        default: False

    >>>polaverage expandable parameter
         pweight -- weighting for polarization average
                 options: 'none'
                          'var'  (1/var(spec) weighted)
                          'tsys' (1/Tsys**2 weighted)
                 default: 'none'

outfile -- Name of output file
        default: '' (scantable)
        example:
outform -- format of output file
        options: 'ASCII','SDFITS','MS','ASAP'
        default: 'ASAP'
        example: the ASAP format is easiest for further sd
                 processing; use MS for CASA imaging.
                 If ASCII, then will append some stuff to
                 the outfile name
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
        WARNING: if outform='ASCII', this parameter is ignored 
\end{verbatim}

DESCRIPTION:

Task {\tt sdcoadd} merges multiple single dish spectral data given by
a list of spectral data file names in any of the following formats,
ASAP, MS2, and SDFITS.
The units of line flux, the units of spectral axis, frame, and doppler
are assumed to be those of the first one in the {\tt infiles} if not
specified.
The {\tt timaverage} and {\tt polaverage} are used to perform time
and polarization averaging over scans on the merged scantable to 
obtained co-added spectra before saving to a file on disk.

See the {\tt sdcal} description for note on GBT raw SDFITS format data.


\subsubsection{{\tt sdflag}}
\label{section:sd.sdtasks.tasks.sdflag}

{\bf Note:} {\tt sdflag} and {\tt sdflag2}\\
A new experimental task, {\tt sdflag2}, is available in CASA 4.2. 
Note the behavior of new task to data selection differs from {\tt sdflag}.

Task {\tt sdflag} is the traditional task to modify flag information of
single dish datasets. The task filters data records in input data if one
of the meta-data selection parameters are set, i.e., {\tt scanlist}, 
{\tt iflit}, {\tt pollist}, or {\tt field}. 
The records in input data appear in output dataset only if they match
all of the meta-data selections. The meta-data selection parameters should
be used with caution since this behavior in combination with the default 
setting of overwriting input file will end up with complete
loss of unselected records from your dataset.

The new task, {\tt sdflag2}, keeps all records in putdata. 
The meta-data selection parameters {\tt scans}, {\tt timerange}, 
{\tt ifs}, {\tt pols}, {\tt field} are used just for selecting data to modify
flag information.


\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz',''
        default: '' (=current)
        example: this will be the units for maskflag
    >>> specunit expandable parameters
         restfreq -- rest frequency
                 available type includes float, int, string, list of float, 
                 list of int, list of string, and list of dictionary. the 
                 default unit of restfreq in case of float, int, or string 
                 without unit is Hz. string input can be a value only 
                 (treated as Hz) or a value followed by unit for which 'GHz',
                 'MHz','kHz',and 'Hz' are available. 
                 a list can be used to set different rest frequencies for 
                 each IF. the length of list input must be nIF. dictionary 
                 input should be a pair of molecule name and frequency with 
                 keys of 'name' and 'value', respectively. values in the 
                 dictionary input follows the same manner as for single 
                 float or string input. 
                 example: 345.796
                          '1420MHz'
                          [345.8, 347.0, 356.7]
                          ['345.8MHz', '347.0MHz', '356.7MHz']
                          [{'name':'CO','value':345}]
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
scanlist -- list of scan numbers to be considered for flagging and output
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field and iflist
field -- field name for selecting scans to be considered for flagging and output
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, and pollist
iflist -- list of IF id numbers to be considered for flagging and output
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to scanlist, field, and pollist
pollist -- list of polarization id numbers to be considered for flagging and output
        default: [] (use all polarizations)
        example: [1]
        this selection is in addition to scanlist, field, and iflist
maskflag -- list of mask regions to apply flag/unflag 
            Note, this parameter is ignored if one or more rows are 
            given in flagrow, or clip=True.
        default: [] (entire spectrum)
        example: [[1000,3000],[5000,7000]]
flagrow -- list of row numbers to apply flag/unflag
           Note, this parameter is effective only when one or more row 
           numbers are given explicitly and also clip=False
        default: [] (no row selection)
        example: [0, 2, 3]
clip -- flag data that are outside a specified range
        options: (bool)True,False
        default: False
     >>> clip expandable parameters
        clipminmax -- range of data that will NOT be flagged
                default: [] means do not use clip option
                example: [0.0,1.5]
        clipoutside -- clip OUTSIDE the range ?
                options: (bool)True,False
                default: True
                example: clipoutside=False means flag data WITHIN the range.
flagmode -- flag mode
        default: 'flag'
        options: 'flag','unflag'
interactive -- determines interactive flagging
        options: (bool) True,False
        default: False
     >>> interactive expandable parameters
        showflagged -- show flagged data on plots
                default: False
outfile -- Name of output file
        default: ''
        Note: by default (outfile=''), actual output file name is set as follows: 
              (1) if overwrite=True (default), infile (input) will be overwritten.
              WARNING: If the formats of input and output files are different, 
                       this causes complete loss of input file.
              (2) if overwrite=False, outfile will be <infile>_f. 
outform -- format of output file
        options: 'ASCII','SDFITS','MS','ASAP'
        default: 'ASAP'
        example: the ASAP format is easiest for further sd
                 processing; use MS for CASA imaging.
        WARNING: Be sure outform is same as the input file format when you 
                 overwrite the input file by overwrite=True and outfile='' (default).
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: True
        WARNING: input file is overwritten if overwrite=True and outfile='' (default). 
                 This causes the complete loss of input file if the formats of
                 input and output files are different.
plotlevel -- control for plotting of results
        options: (int) 0=none, 1=some, 2=more, <0=hardcopy
        default: 0 (no plotting)
        example: plotlevel<0 as abs(plotlevel), e.g.
                 -1 => hardcopy of final plot (will be named
                 <outfile>_flag.eps)
        WARNING: be careful plotting in fsotf mode!

\end{verbatim}


DESCRIPTION:

Task {\tt sdflag} performs both interactive and non-interactive channel/row 
based flagging on spectra.
Currently, the available ways of non-interactive flagging include: 
(1) channel based flagging by specifying a range of spectral values 
with {\tt clip=True}, (2) row based flagging by specifying a list of row 
numbers to the {\tt flagrow} parameter, and (3) channel based flagging by 
specifying regions in channel to the {\tt maskflag} parameter. 
These three ways of flagging cannot be executed simultaneously. 
If more than one parameter above are specified, the task looks for 
them in the above order and operates the first specified way of 
flagging operation.

Interactive flagging is available when {\tt interactive=True}. 
The available ways of interactive flagging include: 
(1) row based flagging by selecting 'panel' and (2) channel
based flagging by selecting 'region's of channels on Flag plotter. 
Note that the Flag plotter is loaded after carrying out the 
non-interactive flag operation if any specified. 
See the following instruction for
details of how to select channel regions and spectra on the plotter.

If {\tt plotlevel} $ \ge 1 $, the task asks you if you really apply the 
flags before it is actually written to the data with a plot 
indicating flagged regions.
Please note that this task is still experimental.

WARNING for {\tt overwrite} option:\\
Be sure {\tt outform} is the same as data format of input file when you
overwrite it. Since CASA 3.1, the default value of the option {\tt overwrite}
has been changed to True, thereby the current dataset ({\tt infile}) is 
overwritten unless a different file name is set to {\tt outfile}. 
There is a known issue in overwriting {\tt infile}. If {\tt outform} differs to the
data format of {\tt infile}, the data is overwritten with the new data format 
(specified by {\tt outform}) and the data in the original format will be lost.

See the {\tt sdcal} description for note on GBT raw SDFITS format data.



\bigskip
{\bf Interactive flag operations on the Flag plotter}

When {\tt sdflag} is executed with {\tt interactive=True}, 
interactive flag operation is available on a plotter, {\tt Flag Plotter}, 
as shown in Figure \ref{fig:flagplotter}.
{\tt Flag Plotter} uses the {\tt matplotlib} plotting library to display 
its plots. You can find information on {\tt matplotlib} at
\url{http://matplotlib.sourceforge.net/}.
Note the plotter is loaded after non-interactive flag operation, 
if any of {\tt maskflag}, {\tt flagrow}, or {\tt clip} is specified.

\begin{figure}[h!]
\begin{center}
\pngname{sdflag_flagplotter}{4.5}
\caption{\label{fig:flagplotter} 
  The {\tt Flag plotter}.
  The {\bf bottom set of buttons} are the standard {\tt matplotlib} toolbar. 
  See the caption of Figure \ref{fig:matplotlib} for detailed descriptions.
  The {\bf upper set of buttons in the lower left} are:
  1) {\bf region}. Press this to begin marking regions (rather than
  zooming or panning).  
  2) {\bf panel}. Press this to begin marking panels to select the whole 
  spectrum.
  3,4,5,6) {\bf clear, flag, unflag, statistics}.  Click on these to clear, 
  flag, unflag, or calculate statistics of the data within the marked 
  regions and spectra.  
  7) {\bf notation}. Press this to begin editing notes on the plotter. 
  8,9) $ {\bf +} $, $ {\bf -} $. Click to move to the next or previous page in a series 
  of iterated plots. The page counter on their left shows the current page 
  number. Finally, the {\bf Quit} is on the bottom right.}
\hrulefill
\end{center}
\end{figure}

The {\tt Flag Plotter} has two rows of buttons at the bottom to 
control its operation -- in particular, to determine flagging and 
unflagging behaviors. 
When no button in the toolbar is depressed, 
the {\tt Flag Plotter} is in spectral value mode. 
Click on a spectrum to select it and drag the mouse to print 
the spectral value at the channel position of mouse. The value is printed 
to the bottom right corner of plotter window.

The buttons on the lower row are the standard 
{\tt matplotlib} navigation buttons. 
See \S~\ref{section:edit.plot.plotxy.control} about details of their 
capabilities.

In a row above it, there are a set of the other buttons (left to right):
\begin{itemize}
\item {\bf region} --- If depressed lets you mark channel regions
  in the panels. This is done by left-clicking the mouse twice at start 
  and end channels of a region to mark. The marked regions are indicated 
  with gray boxes. Clicking the button again will un-depress it and go back 
  to the default spectral value mode.
  You can Mark multiple regions before doing something.
\item {\bf panel} --- If depressed lets you mark spectra in the panels.
  This is done by left-clicking the mouse on panels you want to mark the 
  whole spectrum. The marked panels are colored in gray.
  Clicking the button again will un-depress it and go back 
  to the default spectral value mode.
  You can Mark multiple spectra before doing something.
\item {\bf clear} --- Click this to forget marked regions and spectra.
\item {\bf flag} --- Click this to Flag the points in marked regions and spectra.
\item {\bf unflag} --- Click this to Unflag any flagged point that
  would be in marked regions and spectra (even if invisible).
\item {\bf statistics} --- Click this to print out statics of marked regions 
  and spectra to the logger.
\item {\bf notation} --- If depressed lets you edit texts on the plotter. 
  Clicking the button again will un-depress it and go back 
  to the default spectral value mode.
  See \S~\ref{section:sd.sdtasks.tasks.sdplot} for details.
\item $ {\bf +} $ and $ {\bf -} $ --- Step to the next or previous plot 
  in an iteration. The page counter on their left shows the current page
  number.
\item {\bf Quit} --- Click this to close {\tt Flag Plotter}.
\end {itemize}

To operate flagging and unflagging interactively,
press {\bf region} button (which will appear to depress), 
then mark channel regions by left-clicking the mouse at start 
and end channels of the region (each selection will add an additional region), 
and/or press {\bf panel} button (which will appear to depress),
then mark spectra by left-clicking on their panels (each selection 
will add an additional spectrum).
You can get rid of all your regions and spectra by clicking {\bf clear} 
button.
Once regions and spectra are marked, click on one of {\bf flag},
{\bf unflag}, and {\bf statistics} button to take the action.


\subsubsection{{\tt sdflag2}}
\label{section:sd.sdtasks.tasks.sdflag2}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz',''
        default: '' (=current)
        example: this will be the units for maskflag
    >>> specunit expandable parameters
         restfreq -- rest frequency
                 available type includes float, int, string, list of float, 
                 list of int, list of string, and list of dictionary. the 
                 default unit of restfreq in case of float, int, or string 
                 without unit is Hz. string input can be a value only 
                 (treated as Hz) or a value followed by unit for which 'GHz',
                 'MHz','kHz',and 'Hz' are available. 
                 a list can be used to set different rest frequencies for 
                 each IF. the length of list input must be nIF. dictionary 
                 input should be a pair of molecule name and frequency with 
                 keys of 'name' and 'value', respectively. values in the 
                 dictionary input follows the same manner as for single 
                 float or string input. 
                 example: 345.796
                          '1420MHz'
                          [345.8, 347.0, 356.7]
                          ['345.8MHz', '347.0MHz', '356.7MHz']
                          [{'name':'CO','value':345}]
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
mode -- type of flag operation
        options: (str) 'manual', 'clip', 'interactive', 'rowid'
        default: 'manual'

     >>> common data selection parameters for all modes except mode='rowid'
        scans -- list of scan numbers to process
                default: [] (use all scans)
                example: [21,22,23,24]
                this selection is in addition to field, timerange,
                ifs and pols
        field -- selection string for selecting scans by name
                default: '' (no name selection)
                example: 'FLS3a*'
                this selection is in addition to scans, timerange,
                ifs, and pols
        timerange -- Select data based on time range:
            default = '' (all); example,
            timerange = 'YYYY/MM/DD/hh:mm:ss~YYYY/MM/DD/hh:mm:ss'
            Note: YYYY/MM/DD can be dropped as needed:
            timerange='09:14:0~09:54:0' # this time range
            timerange='09:44:00' # data within one integration of time
            timerange='>10:24:00' # data after this time
            timerange='09:44:00+00:13:00' #data 13 minutes after time
        ifs -- list of IF id numbers to select
                default: [] (use all IFs)
                example: [15]
                this selection is in addition to scans, field,
                timerange, ifs, and pols
        pols -- list of polarization id numbers to select
                default: [] (use all polarizations)
                example: [1]
                this selection is in addition to scans, field,
                timerange, and ifs

     >>> mode='manual' expandable parameters
        maskflag -- list of mask regions to apply flag/unflag 
                    Note, this parameter is ignored if one or more rows are 
                    given in flagrow, or clip=True.
                default: [] (entire spectrum)
                example: [[1000,3000],[5000,7000]]

     >>> mode='clip' expandable parameters
        clipminmax -- range of data that will NOT be flagged
                default: [] (means no clip operation)
                example: [0.0,1.5]
        clipoutside -- clip OUTSIDE the range ?
                options: (bool)True,False
                default: True
                example: clipoutside=False means flag data WITHIN the range.
     >>> mode='interactive' expandable parameters
        showflagged -- show flagged data on plots
                default: False
     >>> mode='rowid' expandable parameters
        rows -- a list of row IDs to apply flag/unflag in the input scannable
                Note, this parameter is effective only when one or more row 
                IDs are given explicitly
                default: [] (means no selection)
                example: [0, 2, 3]
unflag -- flag or unflag
        default: False (flag selected data)
        options: (bool) True, False
outfile -- Name of output file
        default: ''
        Note: by default (outfile=''), actual output file name is set as follows: 
              (1) if overwrite=True (default), infile (input) will be overwritten.
              WARNING: If the formats of input and output files are different, 
                       this causes complete loss of input file.
              (2) if overwrite=False, outfile will be <infile>_f. 
outform -- format of output file
        options: 'ASCII','SDFITS','MS','ASAP'
        default: 'ASAP'
        example: the ASAP format is easiest for further sd
                 processing; use MS for CASA imaging.
        WARNING: Be sure outform is same as the input file format when you 
                 overwrite the input file by overwrite=True and outfile='' (default).
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: True
        WARNING: input file is overwritten if overwrite=True and outfile='' (default). 
                 This causes the complete loss of input file if the formats of
                 input and output files are different.
plotlevel -- control for plotting of results
        options: (int) 0=none, 1=some, 2=more, <0=hardcopy
        default: 0 (no plotting)
        example: plotlevel<0 as abs(plotlevel), e.g.
                 -1 => hardcopy of final plot (will be named
                 <outfile>_flag.eps)
        WARNING: be careful plotting in fsotf mode!

\end{verbatim}


DESCRIPTION:

Task {\tt sdflag2} performs either interactive or non-interactive channel/row 
based flagging on spectra. 
Currently, there are three ways of non-interactive flagging available: 
(1) channel or row based flagging by selecting spectra by field,
lists of scan numbers, IF numbers, and polarization indices in {\tt mode='manual'},
(2) channel based flagging by specifying a range of spectral values in
{\tt mode='clip'}, and 
(3) row based flagging by specifying a list of row numbers in 
{\tt mode='rowid'}. Note this is an EXPERT mode.

In {\tt mode='manual'}, the channel based flagging are invoked when regions
in channel, frequency, or velocity are specified to {\tt maskflag} parameter. 
Otherwise, the whole channels are flagged for the selected spectra.
Note the {\tt mode='rowid'} is an EXPERT mode since it might not be straight
forward for general users to select data by row IDs in scantable.

Interactive flagging is available when {\tt mode='interactive'}. 
The available ways of interactive flagging include: 
(1) row based flagging by selecting 'panel' and (2) channel
based flagging by selecting 'region's of channels on Flag plotter. 
%See the cookbook for details of how to select channel regions and spectra
%on the plotter.
See the article, ``Interactive flag operations on the Flag plotter'', 
in the previous section (\S \ref{section:sd.sdtasks.tasks.sdflag}) for details of how to select channel regions and spectra on the plotter loaded when {\tt mode='interactive'}.


NOTE the task {\tt sdflag2} only modifies flag information, FLAGROW and FLAGTRA, 
in the input scantable, and does not filter rows in the dataset unlike
{\tt sdflag} task.

If {\tt plotlevel} $ \ge 1 $, the task asks you if you really apply the 
flags before it is actually written to the data with a plot 
indicating flagged regions.
Please note that this task is still experimental.

WARNING for {\tt overwrite} option:
Be sure {\tt 'outform'} is the same as data format of input file when you
overwrite it. The default value of the option {\tt overwrite}
is {\tt True} in this task, thereby the current dataset ({\tt infile}) is 
overwritten unless a different file name is set to {\tt outfile}. 
There is a known issue in overwriting {\tt infile}. If {\tt outform} differs to the
data format of {\tt infile}, the data is overwritten with the new data format 
(specified by {\tt outform}) and the data in the original format will be lost.

See the {\tt sdcal} description for note on GBT raw SDFITS format data.


\medskip
{\bf R4.2 New Features:}\\
This is a new experimental task to flag scantable. 
The task, {\tt sdflag2}, keeps all rows in the input datasets.
The data selection parameters, {\tt scans}, {\tt field},
{\tt timerange}, {\tt ifs}, {\tt pols}, and {\tt rows},
are effective only for selecting data to modify flag information.
To the contrary, the traditional flag task, {\tt sdflag},
filters data rows selected by {\tt scanlist}, {\tt iflit},
{\tt pollist}, and {\tt field}, i.e., 
all rows which do not match all of these selection criteria are
removed from output table.


\subsubsection{{\tt sdflagmanager}}
\label{section:sd.sdtasks.tasks.sdflagmanager}

\begin{verbatim}
Keyword arguments:
infile -- Name of input SD dataset
        default: ''. example: infile='ngc5921.asap'
mode -- Flag version operation
        default: 'list'; to list existing flagtables
        'save' will save flag column from infile to a specified flag file
        'restore' will place the specified flag file into infile
        'delete' will delete specified flag file
        'rename' will rename a specified flag file

    >>> mode expandable parameters             
         versionname -- Flag version name
                 default: none; example: versionname='original_data'
                 No imbedded blanks in the versionname
         comment -- Short description of a versionname, when mode is 'save' 
                    or 'rename'
                 default: ''; example: comment='Clip above 1.85'
                 comment = versionname
         oldname -- When mode='rename', the flag file to rename
         merge -- Merge operation
                 Options: 'or','and', but not recommended for now.

\end{verbatim}

DESCRIPTION:

These flag version files are copies of the flag column for a
Measurement Set.  They can be restored to the data set to obtain
a previous flag version.  It is wise to
save a flagversion at the beginning or after serious editing.    


\subsubsection{{\tt sdfit}}
\label{section:sd.sdtasks.tasks.sdfit}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
        default: none - must input file name
        example: 'mysd.asap'
                 See sdreduce for allowed formats.
antenna -- antenna name or id (only effective for MS input). 
fluxunit -- units for line flux
        options: (str) 'K','Jy',''
        default: '' (keep current fluxunit)
        WARNING: For GBT data, see description below.
    >>> fluxunit expandable parameter
         telescopeparm -- the telescope characteristics
                options: (str) name or (list) list of gain info
                default: '' (none set)
                example: if telescopeparm='', it tries to get the telescope
                         name from the data.
                         Full antenna parameters (diameter,ap.eff.) known
                         to ASAP are
                         'ATPKSMB', 'ATPKSHOH', 'ATMOPRA', 'DSS-43',
                         'CEDUNA','HOBART'. For GBT, it fixes default fluxunit
                         to 'K' first then convert to a new fluxunit.
                         telescopeparm=[104.9,0.43] diameter(m), ap.eff.
                         telescopeparm=[0.743] gain in Jy/K
                         telescopeparm='FIX' to change default fluxunit
                         see description below

specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz',''
        default: '' (=current)
        example: this will be the units for maskline
    >>> specunit expandable parameters
         restfreq -- rest frequency
                 available type includes float, int, string, list of float, 
                 list of int, list of string, and list of dictionary. the 
                 default unit of restfreq in case of float, int, or string 
                 without unit is Hz. string input can be a value only 
                 (treated as Hz) or a value followed by unit for which 'GHz',
                 'MHz','kHz',and 'Hz' are available. 
                 a list can be used to set different rest frequencies for 
                 each IF. the length of list input must be nIF. dictionary 
                 input should be a pair of molecule name and frequency with 
                 keys of 'name' and 'value', respectively. values in the 
                 dictionary input follows the same manner as for single 
                 float or string input. 
                 example: 345.796
                          '1420MHz'
                          [345.8, 347.0, 356.7]
                          ['345.8MHz', '347.0MHz', '356.7MHz']
                          [{'name':'CO','value':345}]
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, and pollist
iflist -- list of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
pollist -- list of polarization id numbers to select
        default: [] (use all polarizations)
        example: [1]
fitfunc -- function for fitting
        options: (str) 'gauss','lorentz'
        default: 'gauss'
fitmode -- mode for fitting
        options: (str) 'list','auto','interact'
        default: 'auto'
        example: 'list' will use maskline to define regions to
                        fit for lines with nfit in each
                 'auto' will use the linefinder to fit for lines
                        using the following parameters
                 'interact' allows adding and deleting mask 
                        regions by drawing rectangles on the plot 
                        with mouse. Draw a rectangle with LEFT-mouse 
                        to ADD the region to the mask and with RIGHT-mouse 
                        to DELETE the region. 

    >>> fitmode expandable parameters             
         thresh -- S/N threshold for linefinder
                 default: 5
                 example: a single channel S/N ratio above which the channel is
                          considered to be a detection
	 min_nchan -- minimum number of consecutive channels for linefinder
       	         default: 3
                 example: minimum number of consecutive channels
                          required to pass threshold
         avg_limit -- channel averaging for broad lines
                 default: 4
                 example: a number of consecutive channels not greater than
                          this parameter can be averaged to search for broad lines
         box_size -- running mean box size
                 default: 0.2
                 example: a running mean box size specified as a fraction
                          of the total spectrum length
         edge -- channels to drop at beginning and end of spectrum
                 default: 0
                 example: [1000] drops 1000 channels at beginning AND end
                          [1000,500] drops 1000 from beginning and 500 from end

         Note: For bad baselines threshold should be increased,
         and avg_limit decreased (or even switched off completely by
         setting this parameter to 1) to avoid detecting baseline
         undulations instead of real lines.

maskline -- list of mask regions to INCLUDE in LINE fitting
        default: all
        example: maskline=[[3900,4300]] for a single region, or
                 maskline=[[3900,4300],[5000,5400]] for two, etc.
invertmask -- invert mask (EXCLUDE masklist instead)
        options: (bool) True, False
        default: False
        example: invertmask=True, then will make one region that is
                 the exclusion of the maskline regions
nfit -- list of number of gaussian/lorentzian lines to fit in in
                 maskline region (ignored when fitmode='auto')
        default: 0 (no fitting)
        example: nfit=[1] for single line in single region,
                 nfit=[2] for two lines in single region,
                 nfit=[1,1] for single lines in each of two regions, etc.
outfile -- name of output file for fit results
        default: no output fit file
        example: 'mysd.fit'
overwrite -- overwrite the outfile if already exists
        options: (bool) True, False
        default: False
plotlevel -- control for plotting of results
        options: (int) 0=none, 1=some, 2=more
        default: 0 (no plotting)
        example: plotlevel=1 plots fit
                 plotlevel=2 plots fit and residual 
                 no hardcopy available for fitter
        WARNING: be careful plotting OTF data with lots of fields

-------------------------------------------------------------------
Returns a Python dictionary of line statistics
        keys:    'peak','cent','fwhm','nfit'
        example: each value is a list of lists with one list of
                 2 entries [fitvalue,error] per component.
                 e.g. xstat['peak']=[[234.9, 4.8],[234.2, 5.3]]
                 for 2 components.

\end{verbatim}

DESCRIPTION:

Task {\tt sdfit} is a basic line-fitter for single-dish spectra.
It assumes that the spectra have been calibrated in {\tt sdcal}
or {\tt sdreduce}.

Furthermore, it assumes that any selection of scans, IFs,
polarizations, and time and channel averaging/smoothing has
also already been done (in other sd tasks) as there are no controls
for these.  Note that you can use {\tt sdsave} to do selection and write
out a new scantable.

Note that multiple scans and IFs can in principle be handled, but
we recommend that you use scanlist, field, and iflist to give a
single selection for each fit.

Currently you can choose Gaussian or Lorentzian profile as a fitting model.
    
Interactive mask selection for spectral line fitting is enabled with
{\tt fitmode='interact'}. 
    
For complicated spectra, {\tt sdfit} does not do a good job of
"auto-guessing" the starting model for the fit.  We recommend
you use {\tt sd.fitter} in the toolkit which has more options, such
as fixing components in the fit and supplying starting guesses
by hand.

See the {\tt sdcal} description for information on {\tt fluxunit} 
conversion and the {\tt telescopeparm} parameter.
Also, see the {\tt sdcal} description for note on GBT raw SDFITS format data.

\subsubsection{{\tt sdgrid}}
\label{section::sd.sdtasks.tasks.sdgrid}

\begin{verbatim}
Keyword arguments:
infiles -- name of input SD dataset. can be list.
        example: 'testimage.asap' 
                 ['testimage1.asap','testimage2.asap']
antenna -- select data based on antenna name(s) or id(s)
        default: -1
        example: 0, 'DV01'
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
ifno -- IFNO to be gridded
        default: -1 (only process IFNO in the first row)
        example: 1
pollist -- POLNO to be gridded
        default: [] (all polarizations)
        example: 1,[0,1]
gridfunction -- gridding function 
        options: 'BOX' (Box-car), 'SF' (Spheroidal), 
                 'GAUSS' (Gaussian), 'PB' (Primary-beam)
        default: 'BOX'
        example: 'SF'
    >>> gridfunction expandable parameter:
       width -- width of convolution kernel, not available 
                for BOX gridding
           default: -1 (use default for each gridfunction)
           example: 3
weight -- weight type (both lower-case and upper-case are 
          acceptable)
        options: 'UNIFORM',
                 'TSYS'  (1/Tsys**2 weighted)
                 'TINT'  (integration time weighted)
                 'TINTSYS'  (Tint/Tsys**2)
        default: 'UNIFORM'
clipminmax -- do min/max clipping if True
        default: False
outfile -- output data name
        default: '' (outfile will be set to infile+'.grid')
        example: 'mydata.asap.grid'
overwrite -- overwrite option for outfile
        default: False (not overwrite)
        options: True, False
        example: if True, existing file will be overwritten
npix -- x and y image size in pixels, symmetric for single value
        default: -1 (automatically calculated from cell size and 
                     the data)
        example: npix=200 (equivalent to [200,200])
cell -- x and y cell size. default unit arcsec
        default: '' (automatically calculated from npix if it is 
                     set, otherwise '1.0arcmin')
        example: cell=['0.2arcmin, 0.2arcmin']
                 cell='0.2arcmin' (equivalent to example above)
                 cell=12.0 (interpreted as '12.0arcsec'='0.2arcmin')
center -- grid center
        default: '' (automatically calculated from the data)
        example: 'J2000 13h44m00 -17d02m00'
                 ['05:34:48.2', '-05.22.17.7'] (in J2000 frame)
                 [1.46, -0.09] (interpreted as radian in J2000 frame)
plot -- Plot result or not
        default: False (not plot)
        example: if True, result will be plotted
\end{verbatim}

DESCRIPTION:

The sdgrid task performs spatial gridding according to the user 
specification of spatial grid, convolution function, etc.

For grid configuration, the task supplements necessary information 
by referring input data if any of gridding parameter ({\tt npix}, 
{\tt cell}, or {\tt center}) is not specified by the user. 
If {\tt center} is 
default value (empty string), central position of the grid will be 
set to the center of observed area, i.e. 
$ x \, = \, 0.5 \, (x_{\rm max} + x_{\rm min}) $, 
$ y \, = \, 0.5 \, (y_{\rm max} + y_{\rm min}) $. 
If either {\tt cell} or {\tt npix} is set, unspecified 
one will be calculated from the others. In that case, total extent of 
the grid will be set to cover all observed position. If neither {\tt cell}
nor {\tt npix} is set, cell size will be set to 1.0 arcmin and number of 
pixel will be calculated based on that cell size.
 
Currently, only J2000 frame is supported.
 
The parameter {\tt gridfunction} sets gridding function for imaging. 
Currently, the task supports {\tt 'BOX'} (Box-car), {\tt 'SF'} (Prolate 
Spheroidal Wave Function), {\tt 'GAUSS'} (Gaussian). and {\tt 'PB'} 
(Primary Beam, not implemented yet). For {\tt 'PB'}, correct 
antenna information should be included in input file. 
The {\tt width} parameter specifies width of the convolution kernel 
in pixel unit. For Gaussian gridding, {\tt width} is treated as HWHM 
and actual width (the width that convolution function has non-zero 
value) is set to $ 4 \, {\rm HWHM} $ to take into account contribution from 
Gaussian tail. Otherwise, {\tt width} is treated as actual width of the 
convolution function. 

The parameter gridfunction sets gridding function for imaging. 
Currently, the task supports 'BOX' (Box-car), 'SF' (Prolate 
Spheroidal Wave Function), 'GAUSS' (Gaussian), 'GJINC' (Gaussian*
Jinc), where 
${\rm Jinc}(x) = {\rm J}_1 \left( \frac{\pi x}{c})/(\frac{\pi x}{c} \right)$ 
with a first order 
Bessel function $J_1$, and 'PB' (Primary Beam, not implemented yet). 
For 'PB', correct antenna informations should be included in input 
file. 

There are four subparameters for gridfunction: convsupport, truncate, 
gwidth, and jwidth. The convsupport is an integer specifying cut-off 
radius for 'SF' in units of pixel. By default (convsupport=-1), 
the cut-off radius is set to 3 pixels. The truncate is a cut-off 
radius for 'GAUSS' or 'GJINC'. It accepts integer, float, and 
string values of numeric plus unit. Allowed units are angular 
units such as 'deg', 'arcmin', 'arcsec', and 'pixel'. Default unit 
is 'pixel' so that string without unit or numerical values (integer 
or float) will be interpreted as radius in pixel. Default value 
for truncate, which is used when negative radius is set, is 3*HWHM 
for 'GAUSS' and radius at first null for 'GJINC'. The gwidth is 
the HWHM of gaussian for 'GAUSS' and 'GJINC'. Default value is 
$\sqrt{\log 2}$ pixel for 'GAUSS' and $2.52 \sqrt{\log 2}$ pixel for 
'GJINC'. The jwidth specifies width of the jinc function (parameter 
'c' in the definition above). Default is 1.55 pixel. Both gwidth 
jwidth allows integer, float, or string of numeric plus unit. 
Default values for gwidth and jwidth are taken from Mangum et al. 
(2007). Formula for 'GAUSS' and 'GJINC' are taken from Table 1 in 
the paper, and are written as below using gwidth and jwidth: 

   GAUSS: $ \exp \left[ - \left( \frac{|r|}{\rm gwidth} \right)^2 \right] $

   GJINC: $ \frac{ {\rm J}_1 \left( \pi |r| / {\rm jwidth} \right)}{\left( \pi |r| / {\rm jwidth} \right)} \exp \left[ - \left( \frac{|r|}{\rm gwidth} \right)^2 \right] $  


Boolean parameter {\tt plot} controls whether gridded result is plotted 
or not. If {\tt True}, color map of gridded data will be shown. Pixel 
center and observed position are overlaid as blue dot and red dot, 
respectively. Currently, channel averaged value will be plotted.

Reference: Mangum, et al. 2007, A\&A, 474, 679-687 


\subsubsection{{\tt sdimaging}}
\label{section:sd.sdtasks.tasks.sdimaging}

List of parameter changes in CASA 4.2:
\begin{itemize}
\item {\tt infile} $ \rightarrow $ {\tt infiles} (renamed and takes a list of file names)
\item {\tt spw} (takes a list of integer)
\item {\tt outframe} (added)
\item {\tt minweight} (added)
\item {\tt imsize} (default value changed)
\item {\tt cell} (default value changed)
\end{itemize}


\begin{verbatim}
Keyword arguments:
infiles -- a list of names of input SD (MS) datasets
        example: 'm100.PM01.ms'
                 ['m100.PM01.ms','m100.PM03.ms']; multiple MSes
specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz'
        default: 'channel'
        example: this will be the units for nchan, start, and step
restfreq -- rest frequency
        default: '' (refer input data)
        example: 1.0e11, '100GHz'
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field and spw
field -- field id or selection string for selecting scans by name
        default: -1 (all fields)
        example: 'FLS3a', 0
        this selection is in addition to scanlist and spw
spw -- a list of spectral window id
        default: 0
        example: 1
                 [1, 3, 5]
        this selection is in addition to scanlist and field
antenna -- select data based on antenna name(s) or id(s)
        default: -1 (all baselines, i.e. all antenna in case of auto data)
        example: 0, 'DV01'
stokes -- select data based on stokes or polarization type 
        default: '' (use all polarizations)
        example: 'XX'
gridfunction -- gridding function for imaging
        options: 'BOX' (Box-car), 'SF' (Spheroidal), 
                 'PB' (Primary-beam), 'GAUSS' (Gaussian),
                 'GJINC' (Gaussian*Jinc)
        default: 'BOX'
        example: 'SF'
    >>> gridfunction expandable parameter:
       convsupport -- convolution support for 'SF' 
           default: -1 (use default for each gridfunction)
           example: 3
       truncate -- truncation radius of convolution kernel.
                   effective only for 'GAUSS' and 'GJINC'.
           default: '-1' (use default for each gridfunction)
           example: 3, '20arcsec', '3pixel'
       gwidth -- HWHM for gaussian. Effective only for 
                 'GAUSS' and 'GJINC'.
           default: '-1' (use default for each gridfunction)
           example: 3, '20arcsec', '3pixel'
       jwidth -- Width of jinc function. Effective only for 
                 'GJINC'.
           default: '-1' (use default for each gridfunction)
           example: 3, '20arcsec', '3pixel'
minweight -- Minimum weight ratio to the median of weight used in 
             weight correction and weight based masking
        default: 0.1
        example: minweight = 0.
outfile -- output image name
        default: none
        example: 'mySDimage.im'
overwrite -- overwrite option for outfile
        default: False (not overwrite)
        options: True, False
        example: if True, existing file will be overwritten
imsize -- x and y image size in pixels, symmetric for single value
        default: [] (=cover all pointings in MS)
        example: imsize=200 (equivalent to [200,200])
cell -- x and y cell size. default unit arcmin
        default: '' (=1/3 PB)
        example: cell=['0.2arcmin, 0.2arcmin']
                 cell='0.2arcmin' (equivalent to example above)
dochannelmap -- channel map image or total power image
        default: False (total power)
        options: True (channel map), False
    >>> dochannelmap=True expandable parameters
       nchan -- number of spectral channel for created image
           default: 1 
           example: 100
       start -- reference value of start channel (in units of specunit)
           default: 0 (0th channel if specunit='channel')
           example: 100
       step -- width of each spectral channel for created image
           default: 1 (width of 1 channel if specunit='channel')
           example: 100
outframe -- Velocity reference frame of output image
        Options: '','LSRK','LSRD','BARY','GEO','TOPO','GALACTO',
                 'LGROUP','CMB'
        default: ''; same as input data or 'LSRK' for multiple-MS inputs
        example: frame='bary' for Barycentric frame 
phasecenter -- image phase center: direction measure or fieldid 
        default: 0
        example: 'J2000 13h44m00 -17d02m00', 'AZEL -123d48m29 15d41m41'
ephemsrcname -- ephemeris source name for moving source
        default: ''
        if the source name in the data matches one of the known 
        solar objects by the system, this task automatically set 
        the source name. 
        example: 'moon' 
pointingcolumn -- pointing data column to use
        option: 'direction', 'target', 'pointing_offset', 'source_offset', 'encoder' 
        default: 'direction'

\end{verbatim}

DESCRIPTION:

Task {\tt sdimaging} create an image from input single-dish data.
The input can be either total power and spectral data. Currently,
this task directly accesses the Measurement Set data only because of 
the data access efficiency. So it differs from other single-dish 
tasks that mostly operate on the ASAP scantable data format.
 
Units of spectral axis can be specified via a parameter {\tt specunit}.
Allowed values for specunit are {\tt 'channel'}, {\tt 'GHz'}, {\tt 'MHz'}, {\tt 'kHz'}, {\tt 'Hz'}, 
and {\tt 'km/s'}. This parameter is also used as the units of the parameter 
{\tt start} and {\tt step} that specify reference value of start channel and 
width of each spectral channel for channel map, respectively. 
The parameter nchan specifies number of channels for created image. 
%If you set {\tt nchan} as -1, the task selects existing all channels and 
%combine those data into one channel to create continuum image.

You can specify field id or name directly. By default, {\tt field} is set 
to {\tt -1} that means the task selects all fields in the data.

Selection of the antennas can be made by setting antenna id(s) or 
antenna name(s) in string (e.g. {\tt '0'}, {\tt 'DV01'},etc.) or integer 
(e.g. {\tt 0}). Default value, {\tt -1}, means that the task selects data from 
all baseline, i.e., data from all antenna when data only contains 
auto-correlation.


The parameter gridfunction sets gridding function for imaging. 
Currently, the task supports {\tt 'BOX'} (Box-car), {\tt 'SF'} (Prolate 
Spheroidal Wave Function), {\tt 'GAUSS'} (Gaussian), {\tt 'GJINC'} (Gaussian*
Jinc), where 
${\rm Jinc}(x) = {\rm J}_1 \left( \frac{\pi x}{c})/(\frac{\pi x}{c} \right)$ 
with a first order 
Bessel function $J_1$, and {\tt 'PB'} (Primary Beam, not implemented yet). 
For {\tt 'PB'}, correct antenna information should be included in input 
file. 

There are four subparameters for gridfunction: {\tt convsupport}, {\tt truncate}, 
{\tt gwidth}, and {\tt jwidth}. The {\tt convsupport} is an integer specifying cut-off 
radius for {\tt 'SF'} in units of pixel. By default ({\tt convsupport=-1}), 
the cut-off radius is set to 3 pixels. The truncate is a cut-off 
radius for {\tt 'GAUSS'} or {\tt 'GJINC'}. It accepts integer, float, and 
string values of numeric plus unit. Allowed units are angular 
units such as 'deg', 'arcmin', 'arcsec', and 'pixel'. Default unit 
is 'pixel' so that string without unit or numerical values (integer 
or float) will be interpreted as radius in pixel. Default value 
for {\tt truncate}, which is used when negative radius is set, is 3*HWHM 
for {\tt 'GAUSS'} and radius at first null for {\tt 'GJINC'}. The gwidth is 
the HWHM of gaussian for {\tt 'GAUSS'} and {\tt 'GJINC'}. Default value is 
$\sqrt{\log 2}$ pixel for 'GAUSS' and $2.52 \sqrt{\log 2}$ pixel for 
{\tt 'GJINC'}. The jwidth specifies width of the jinc function (parameter 
'c' in the definition above). Default is 1.55 pixel. Both {\tt gwidth} 
{\tt jwidth} allows integer, float, or string of numeric plus unit. 
Default values for {\tt gwidth} and {\tt jwidth} are taken from Mangum et al. 
(2007). Formula for {\tt 'GAUSS'} and {\tt 'GJINC'} are taken from Table 1 in 
the paper, and are written as below using {\tt gwidth} and {\tt jwidth}: 


   GAUSS: $ \exp \left[ - \left( \frac{|r|}{\rm gwidth} \right)^2 \right] $

   GJINC: $ \frac{ {\rm J}_1 \left( \pi |r| / {\rm jwidth} \right)}{\left( \pi |r| / {\rm jwidth} \right)} \exp \left[ - \left( \frac{|r|}{\rm gwidth} \right)^2 \right] $  

Reference: Mangum, et al. 2007, A\&A, 474, 679-687 

The parameter {\tt minweight} defines a threshold of weight values 
to mask. The pixels in outfile whose weight is smaller than
{\tt minweight} $ \cdot $ median(weight) are masked out. The task also creates
a weight image with the name {\tt outfile.weight}.


\medskip
{\bf R4.2 New Feature:}
\begin{itemize}
\item the task accepts more than one input MSes. 
The parameter name to specify input files is changed to {\tt infiles}.
\item the task accepts more than one spectral widows in {\tt spw} parameter.
\item auto calculation of the number of pixels ({\tt imsize}) and
pixel size ({\tt cell}) of the image by default.
\item a new parameter, {\tt outframe}, to specify the frequency frame
of the image.
\item the task sets mask to the image. A new parameter, {\tt minweight}, 
is available to define a threshold of weight mask. 
Pixels in the image whose weight values are smaller than 
$ M \cdot {\tt minweight} $ are masked out, where $ M $ is the median of weight. 
The task also creates weight image for future reference and modification 
of mask.
\item the brightness unit of image is set to 'K' when input MSes are in the unit.
\end{itemize}
 


\subsubsection{{\tt sdlist}}
\label{section:sd.sdtasks.tasks.sdlist}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
scanaverage -- average integrations within scans
        options: (bool) True,False
        default: False
        example: if True, this happens in read-in
        For GBT, set False!
outfile -- Name of output file for summary list
        default: '' (no output file)
        example: 'mysd_summary.txt'
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
\end{verbatim}
    
DESCRIPTION:
    
Task {\tt sdlist} lists the scan summary of the dataset after importing
as a scantable into ASAP.  It will optionally output this summary
as file.
    
%%     Note that if your {\tt PAGER} environment variable is set to 'less' and
%%     the {\tt 'verbose'} ASAP environment variable to True
%%     (the default), then the screen version of the summary will page.
%%     You can disable this for sdlist by setting
%%          {\tt sd.rcParams['verbose']=False}
%%     before running {\tt sdlist}.  Set it back afterward if you want lots
%%     of information.

See the {\tt sdcal} description for note on GBT raw SDFITS format data.

\subsubsection{{\tt sdmath}}
\label{section:sd.sdtasks.tasks.sdmath}

\begin{verbatim}
Keyword arguments:
expr -- Mathematical expression using scantables 
varlist -- Dictionary of variables in expr and their values.
           Keys must be coincide with variables used in expr.
           Values are substituted in each value in expr.
antenna -- antenna name or id (only effective for MS input). 
fluxunit -- units for line flux
        options: 'K','Jy',''
        default: '' (keep current fluxunit)
        WARNING: For GBT data, see description below.
    >>> fluxunit expandable parameter
         telescopeparm -- the telescope characteristics
                options: (str) name or (list) list of gain info
                default: '' (none set)
                example: if telescopeparm='', it tries to get the telescope
                         name from the data.
                         Full antenna parameters (diameter,ap.eff.) known
                         to ASAP are
                         'ATPKSMB', 'ATPKSHOH', 'ATMOPRA', 'DSS-43',
                         'CEDUNA','HOBART'. For GBT, it fixes default fluxunit
                         to 'K' first then convert to a new fluxunit.
                         telescopeparm=[104.9,0.43] diameter(m), ap.eff.
                         telescopeparm=[0.743] gain in Jy/K
                         telescopeparm='FIX' to change default fluxunit
                         see description below

specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz'
        default: '' (=current)
        example: this will be the units for masklist
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field, iflist, and pollist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, and pollist
iflist -- list of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to scanlist, field, and pollist
pollist -- list of polarization id numbers to select
        default: [] (use all polarizations)
        example: [1]
        this selection is in addition to scanlist, field, and iflist
outfile -- Name of output file
        default: '' (<infile>_cal)
outform -- format of output file
        options: 'ASCII','SDFITS','MS','ASAP'
        default: 'ASAP'
        example: the ASAP format is easiest for further sd
                 processing; use MS for CASA imaging.
                 If ASCII, then will append some stuff to
                 the outfile name
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
        WARNING: if outform='ASCII', this parameter is ignored
\end{verbatim}

DESCRIPTION:

Task {\tt sdmath} executes a mathematical expression for single dish spectra.
The spectral data file can be any of the formats supported by
ASAP (scantable, MS, rpfits, and SDFITS). In the expression, 
these file names should be put inside of single or double quotes.
You can use variables in the expression. If you want to use, you must
define {\tt varlist} dictionary. Name of variables should be simple, e.g.
V0, V1, etc., to avoid unexpected error. Keys of {\tt varlist} must be name
of variables that you used in the expression, and their values will
be substituted for variables in the expression. Allowed type for value
is numerical values, one- or two-dimensional lists (either Python list
or numpy.ndarray), and filename strings that indicate spectral data
or ASCII text, which is space-separated list of numerical values
consisting of adequate number of rows and columns.
     
The {\tt fluxunit}, {\tt specunit}, and {\tt frame} can be set, otherwise, the current
settings of the first spectral data in the expression are used.  
Other selections (e.g. scan No, IF, Pol) also apply to all 
the spectral data in the expression, so if any of the data are
not selected, the task will produce no output. 
     
See the {\tt sdcal} description for note on GBT raw SDFITS format data.

Example:
\begin{verbatim}
     # do on-off/off calculation
     expr='("orion_on_data.asap"-"orion_off_data.asap")/"orion_off_data.asap"
     outfile='orion_cal.asap'
     sdmath()
     
     # do on-off/off calculation using varlist
     expr='V0/V1-V2'
     varlist['V0']='orion_on_data.asap'
     varlist['V1']='orion_off_data.asap'
     varlist['V2']=1.0
     outfile='orion_cal.asap'
     sdmath()
     
     # interpretation of ASCII file value for varlist
     If the contents of input ASCII file is shown as,

       0.5 0.3 0.2
       1.0 0.2 0.9

     it is interpreted as a list,  [[0.5,0.3,0.2],[1.0,0.2,0.9]].
\end{verbatim}


\subsubsection{{\tt sdplot}}
\label{section:sd.sdtasks.tasks.sdplot}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
fluxunit -- units for line flux
        options: 'K','Jy',''
        default: '' (keep current fluxunit)
        WARNING: For GBT data, see description below.
    >>> fluxunit expandable parameter
         telescopeparm -- the telescope characteristics
                options: (str) name or (list) list of gain info
                default: '' (none set)
                example: if telescopeparm='', it tries to get the telescope
                         name from the data.
                         Full antenna parameters (diameter,ap.eff.) known
                         to ASAP are
                         'ATPKSMB', 'ATPKSHOH', 'ATMOPRA', 'DSS-43',
                         'CEDUNA','HOBART'. For GBT, it fixes default fluxunit
                         to 'K' first then convert to a new fluxunit.
                         telescopeparm=[104.9,0.43] diameter(m), ap.eff.
                         telescopeparm=[0.743] gain in Jy/K
                         telescopeparm='FIX' to change default fluxunit
                         see description below

specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz'
        default: '' (=current)
        example: this will be the units for masklist
    >>> specunit expandable parameter
         restfreq -- rest frequency
                 default: '' (use current setting)
                 example: 4.6e10 (float value in Hz),
                          '46GHz' (string with unit),
                          ['345.8GHz', 347.0e9, 356.7e9] (for each IF)
                          [{'name':'CO','value':345e9}] (a value with name)
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
scanlist -- list or string of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24], or "21~24"
        this selection is in addition to field, iflist, pollist,
        and beamlist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, pollist,
        and beamlist
iflist -- list or string of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to scanlist, field, pollist,
        and beamlist
pollist -- list or string of polarization id numbers to select
        default: [] (use all polarizations)
        example: [1]
        this selection is in addition to scanlist, field, iflist,
        and beamlist
beamlist -- list or string of beam id numbers to select
        default: [] (use all beams)
        example: [1]
        this selection is in addition to scanlist, field, iflist,
        and pollist
scanaverage -- average integs within scans
        options: (bool) True,False
        default: False
timeaverage -- average times for multiple scan cycles
        options: (bool) True,False
        default: False
        example: if True, this happens after calibration
        >>>timeaverage expandable parameter
         tweight -- weighting for time average
                 options: 'var'   (1/var(spec) weighted)
                          'tsys'  (1/Tsys**2 weighted)
                          'tint'  (integration time weighted)
                          'tintsys'  (Tint/Tsys**2)
                          'median'  ( median averaging)
                 default: 'tintsys'
polaverage -- average polarizations
        options: (bool) True,False
        default: False
        >>>polaverage expandable parameter
         pweight -- weighting for polarization average
                 options: 'var'  (1/var(spec) weighted)
                          'tsys' (1/Tsys**2 weighted)
                 default: 'tsys'
kernel -- type of spectral smoothing
        options: 'hanning','gaussian','boxcar', 'none'
        default: 'none'
        >>>kernel expandable parameter
         kwidth -- width of spectral smoothing kernel
                 options: (int) in channels
                 default: 5
                 example: 5 or 10 seem to be popular for boxcar
                          ignored for hanning (fixed at 5 chans)
                          (0 will turn off gaussian or boxcar)
plottype -- type of plot
         options: 'spectra','totalpower','pointing','azel','grid'
         default: 'spectra'
    >>> plottype expandable parameters
        stack -- code for stacking on single plot for spectral plotting
                options: 'p','b','i','t','s','r' or
                         'pol', 'beam', 'if', 'time', 'scan', 'row'
                default: 'p'
                example: maximum of 16 stacked spectra
                         stack by pol, beam, if, time, scan
                Note stack selection is ignored when panel='r'.
        panel -- code for splitting into multiple panels for spectral plotting
                options: 'p','b','i','t','s','r' or
                         'pol', 'beam', 'if', 'time', 'scan', 'row'
                default: 'i'
                example: maximum of 16 panels
                         panel by pol, beam, if, time, scan
                Note panel selection is ignored when stack='r'.
        flrange -- range for flux axis of plot for spectral plotting
                options: (list) [min,max]
                default: [] (full range)
                example: flrange=[-0.1,2.0] if 'K'
                         assumes current fluxunit
        sprange -- range for spectral axis of plot
                options: (list) [min,max]
                default: [] (full range)
                example: sprange=[42.1,42.5] if 'GHz'
                         assumes current specunit
        linecat -- control for line catalog plotting for spectral plotting
                options: (str) 'all','none' or by molecule
                default: 'none' (no lines plotted)
                example: linecat='SiO' for SiO lines
                         linecat='*OH' for alcohols
                         uses sprange to limit catalog
                WARNING: specunit must be in frequency (*Hz)
                         to plot from the line catalog!
                         and must be 'GHz' or 'MHz' to use
                         sprange to limit catalog
        linedop -- doppler offset for line catalog plotting (spectral plotting)
                options: (float) doppler velocity (km/s)
                default: 0.0
                example: linedop=-30.0
        center -- the central direction of gridding
                default: '' (map center)
                example: 'J2000 19h30m00 -40d00m00'
                Note currently only supports 'J2000' as direction frame
        cell -- x and y cell size of gridding
                default: [] (map extent divided by # of subplots in x and y)
                example: cell=['1.0arcmin','1.0arcmin']
                         cell='1.0arcmin' (equivalent to the example above)
                Note default number of subplots is 1 x 1 in plottype='grid'.
        subplot -- number of subplots (row and column) on a page
                   NOTICE plotter will slow down when a large number is specified
                   default: -1 (auto. for plottype='spectra', 1x1 for plottype='grid')
                   example: 23 (2 rows by 3 columns)
        colormap -- the colours to be used for plot lines. 
                default: None
                example: colormap="green red black cyan magenta" (html standard)
                         colormap="g r k c m" (abbreviation)
                         colormap="#008000 #00FFFF #FF0090" (RGB tuple)
                         The plotter will cycle through these colours 
                         when lines are overlaid (stacking mode).
        linestyles -- the linestyles to be used for plot lines. 
                default: None
                example: linestyles="line dashed dotted dashdot dashdotdot dashdashdot". 
                         The plotter will cycle through these linestyles 
                         when lines are overlaid (stacking mode). 
                WARNING: Linestyles can be specified only one color has been set. 
        linewidth -- width of plotted lines. 
                default: 1
                example: linewidth=1 (integer)
                         linewidth=0.75 (double)
        histogram -- plot histogram
                options: (bool) True, False
                default: False
        scanpattern -- plot additional lines on the plot to indicate scan patterns
                       when plottype='pointing'
                options: (bool) True, False
                default: False
header -- print header information on the plot
        options: (bool) True, False
        default: True
        The header information is printed only on the logger when 
        plottype = 'azel' and 'pointing'. 
    >>> header expandable parameter
        headsize -- header font size
                options: (int)
                default: 9
plotstyle -- customise plot settings
        options: (bool) True, False
        default: False
    >>> plotstyle expandable parameter
        margin -- a list of subplot margins in figure coordinate (0-1), 
                  i.e., fraction of the figure width or height.
                  The order of elements should be:
                  [left, bottom, right, top, horizontal space btw panels,
                  vertical space btw panels]
                example: margin = [0.125, 0.1, 0.9, 0.9, 0.2, 0.2]
        legendloc -- legend location on the axes (0-10)
                   options: (integer) 0 -10 
                            see help of "sd.plotter.set_legend" for 
                            the detail of location. Note that 0 ('best')
                            is very slow. 
                   default: 1 ('upper right')
outfile -- file name for hardcopy output
        options: (str) filename.eps,.ps,.png
        default: '' (no hardcopy)
        example: 'specplot.eps','specplot.png'
        Note this autodetects the format from the suffix (.eps,.ps,.png).
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
\end{verbatim}

DESCRIPTION:
    
Task {\tt sdplot} displays single-dish spectra, total power, or
pointing direction of input data.  It assumes that the spectra have
been calibrated.  It does allow selection of scans, IFs,
polarizations, and some time and channel averaging/smoothing options
also, but does not write out this data.

This task adds an additional toolbar to Matplotlib plotter. 
See the cookbook for details of its capability.

*** Data selection ***\\
This task allows data selection via field name, scan, IF, polarization
and beam IDs. Selection of field allows pattern matching using
asterisk, e.g., {\tt `FLS3a*'}. Selection of scans, IFs,
polarizations, and beams, is possible either by a list of IDs or by a
CASA type selection syntax using a string of comma separated numbers
with operators, i.e., `{\tt \~{}}', `{\tt >}', `{\tt >=}', `{\tt <}',
and `{\tt <=}'.
For example, the following two selections are equivalent:\\
{\tt scanlist = [0, 1, 2, 7, 8, 9, 15]}\\
{\tt scanlist = `<3,7\~{}9,15'}

*** control of plot lines in {\tt `spectra'} and {\tt `grid' plottype} ***\\
Note that {\tt colormap} and {\tt linestyles} cannot be controlled at a time.
The {\tt linestyles} is ignored if both of them are specified.
Some plot options, like changing titles, legends, fonts,
and the like are not supported in this task.  You should use
{\tt sd.plotter} from the ASAP toolkit directly for this.

*** available {\tt plottypes} ***
\begin{itemize}
\item {\tt plottype = `spectra'} plots single dish spectra. Multiple
  scans, IFs, polarizations, and beams can be handles through stacking
  and paneling.  This task uses the JPL line catalog as supplied by
  ASAP.  If you wish to use a different catalog, or have it plot the
  line IDs from top or bottom (rather than alternating), then you will
  need to explore the sd toolkit also.
\item {\tt plottype = `grid'} plots spectra based on their pointing direction.
The spectra are gridded by direction before plotting.
Multiple IFs and polarizations are not handled in this mode. Only
the first IF and polarization is gridded and plotted if data 
includes multiple IDs after selections are applied. Hence, over
plotting is not available
\end{itemize}

Currently most of the parameters are ignored in the following modes.
\begin{itemize}
\item {\tt plottype=`totalpower'} is used to plot the total power data.
and only plot option is amplitude versus data row number.
\item {\tt plottype=`azel'} plots azimuth and elevation tracks of the source.
\item {\tt plottype=`pointing'} plots antenna pointings.
\end{itemize}

See the {\tt sdcal} description for information on the {\tt fluxunit} conversion
and the {\tt telescopeparm} parameter.
Also, see the {\tt sdcal} description for note on GBT raw SDFITS format data.

WARNING: be careful plotting otf data with lots of fields!


\bigskip
{\bf GUI Plot Control on ASAP Plotter}

The principal ways to plot single dish spectra are using 
the {\tt sdplot} task and {\tt sd.plotter} toolkit. 
These task and toolkit load {\tt ASAP Plotter} which uses 
the {\tt matplotlib} plotting library to display plots. 
You can find information on {\tt matplotlib} at
\url{http://matplotlib.sourceforge.net/}.

\begin{figure}[h!]
\begin{center}
\pngname{asapplotter_toolbar}{4.5}
\caption{\label{fig:sdplot_toolbar}
  The toolbars on {\tt ASAP plotter}.
  The {\bf bottom set of buttons} are the standard {\tt matplotlib} toolbar. 
  See the caption of Figure \ref{fig:matplotlib} for detailed descriptions.
  The {\bf upper set of buttons} are:
  1) {\bf notation}. Press this to begin editing notes on the plotter. 
  2) {\bf statistics}.Press this to begin printing statistics to the logger.
  3,4) $ {\bf +} $, $ {\bf -} $. Click to move to the next or previous page in a series 
  of iterated plots. The page counter on their left shows the current page 
  number. Finally, the {\bf Quit} is on the bottom right.}
\hrulefill
\end{center}
\end{figure}

The {\tt ASAP Plotter} has two rows of buttons at the bottom to 
control interactive operations as shown in Figure \ref{fig:sdplot_toolbar}. 
When none of the button is depressed, the {\tt ASAP Plotter} is in spectral 
value mode. Click on a spectrum to select it and drag the mouse to print 
the spectral value at the channel position of mouse. The value is printed 
to the bottom right corner of plotter window.

The buttons on the lower row are the standard 
{\tt matplotlib} navigation buttons. 
See \S~\ref{section:edit.plot.plotxy.control} about details of their 
capabilities.

In a row above it, there are a set of the other buttons (left to right):
\begin{itemize}
\item {\bf notation} --- If depressed lets you edit texts on the plotter. 
  See below for details of text edition.
  Clicking the button again will un-depress it and go back 
  to the default spectral value mode.
\item {\bf statistics} --- If depressed lets you print statics of a 
  selected regions of scantable to the logger.
  See below for details of region selection.
  Clicking the button again will un-depress it and go back 
  to the default spectral value mode.
\item $ {\bf +} $ and $ {\bf -} $ --- Step to the next or previous plot 
  in an iteration. The page counter on their left shows the current page
  number.
\item {\bf Quit} --- Click this to close {\tt ASAP Plotter}.
\end {itemize}

{\bf Editing texts on the plotter}\\
\begin{figure}[h!]
\begin{center}
\pnghigh{asapplotter_notationwin}{1.5}
\caption{\label{fig:notationwin} The Notation widget.}
\hrulefill
\end{center}
\end{figure}

When the {\bf notation} button is depressed, 
it lets you edit texts on the plotter. 
Left-click at a position on the plotter to print a new text,
and the {\tt Notation window} is loaded (Figure \ref{fig:notationwin}).
Type the arbitrary text in the text box, select an anchor, and press 
the {\bf print} button to print it at the position you clicked.
There are three choices of anchors: {\bf figure}, 
{\bf panel}, and {\bf data}. 
The {\bf figure} or {\bf panel} locates the text at a fixed position 
in the figure or subplot, respectively. Its relative position to 
the figure or subplot boundaries doesn't change when you resize the plotter.
On the other hand, the text is fixed on a position in the data coordinate 
of subplot, when {\bf data} is selected as the anchor. 
The text moves along with plotted spectra as you pan the subplot.

You can modify or delete texts you added on the plotter. 
To do it, right-click on a text to show a menu with 
{\bf Modify} and {\bf Delete}. 
When {\bf Modify} is selected, the {\tt Notation window} is loaded
to modify the selected text. 
Click on {\bf Delete} and confirm the operation in a pop-up dialog 
to delete the text.
Clicking the {\bf notation} button again will un-depress it and go back 
to the default spectral value mode.


{\bf Printing statistics of scantable}\\
When {\bf statistics} button is depressed, 
it lets you print statistics of a selected channel region 
of the scantable plotted. 
The statistics values are printed to the logger.
You can select a channel region by left- or right-clicking and 
dragging the mouse to draw a rectangle. 
Draw it with left-mouse to print statistics within the region,
while do with right-mouse to print statistics excluding the region.
Clicking the {\bf statistics} button again will un-depress it and go back 
to the default spectral value mode.




\subsubsection{{\tt sdsave}}
\label{section:sd.sdtasks.tasks.sdsave}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
getpt -- fill DIRECTION column properly, or reuse POINTING table 
         in original MS (only effective for MS input)
         default: True
         options: True (fill DIRECTION column properly)
                  False (reuse POINTING table in original MS)
rowlist -- list of row numbers to process
        default: [] (use all rows)
        example: [0,2,4,6]
        For expert users only!
        this selection is applied first, and then followed by
        the selection with scans, fields, ifs, and polarizations. 
scanlist -- list of to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field, iflist, and pollist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, and pollist
iflist -- list of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to scanlist, field, and pollist
pollist -- list of polarization id numbers to select
        default: [] (use all polarizations)
        example: [1]
        this selection is in addition to scanlist, field, and iflist
scanaverage --  average integrations within scans
        options: (bool) True,False
        default: False
        example: if True, average integrations before it is saved
timeaverage -- average times for multiple scan cycles
        options: (bool) True,False
        default: False
        >>>timeaverage expandable parameter
         tweight -- weighting for time average
                 options: 'none'
                          'var'   (1/var(spec) weighted)
                          'tsys'  (1/Tsys**2 weighted)
                          'tint'  (integration time weighted)
                          'tintsys'  (Tint/Tsys**2)
                          'median'  ( median averaging)
                 default: 'none'

polaverage -- average polarizations
        options: (bool) True,False
        default: False
        >>>polaverage expandable parameter
         pweight -- weighting for polarization average
                 options: 'none'
                          'var'  (1/var(spec) weighted)
                          'tsys' (1/Tsys**2 weighted)
restfreq -- rest frequencies of output data
        Available types are a number, string, a list of numbers or
        strings (see examples below), and list of dictionaries. 
        The default unit of restfreq is Hz, if not specified.
        A list can be used to set different rest frequencies to
        each IF. the length of list input must be nIF. Dictionary 
        input should be a pair of molecule name and frequency with 
        keys of 'name' and 'value', respectively. The 'value's in the 
        dictionary input follows the same manner as for single 
        float or string input. 
        default: '' (use current setting)
        example: 4.6e10 (float value in Hz),
                 '46GHz' (string with unit),
                 ['345.8GHz', '347.0GHz', 356.7e9] (for each IF)
                 [{'name':'CO','value':345e9}] (a value with name)
outfile -- name of output dataset
        default: '' 
outform -- output data format
        default: 'ASAP'
        Options: 'ASAP', 'MS2', 'SDFITS', 'ASCII'
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
        WARNING: if outform='ASCII', this parameter is ignored
\end{verbatim}

DESCRIPTION:

Task {\tt sdsave} writes the single dish data to a disk file in 
specified format (ASAP, MS2, SDFITS, ASCII). It is possible to
save the subset of the data by selecting row numbers, scan numbers, IF ids
and field names. The ASAP (scantable) format is recommended for
further analysis using sd tool. For further imaging using imager,
save the data to the Measurement Set (MS2).
          
Note that setting {\tt getpt=False} needs a lot of attention.
If you set {\tt getpt=False}, the task retrieves pointing direction from 
MS's FIELD table, which might not be correct for single dish 
observation, instead to check MS's POINTING table, which is the 
default behavior of the task ({\tt getpt=True}). To compensate this, 
absolute path to MS's POINTING table is stored, and it will be used 
for POINTING table when the data is converted back to MS format. 
In general, {\tt getpt=False} is faster especially for large data. However, 
MS created from Scantable cannot have correct POINTING table if 
original MS's POINTING table doesn't exist. Such situation will 
happen when original MS is removed or renamed, or imported Scantable 
is moved to other computer alone.

See the {\tt sdcal} description for note on GBT raw SDFITS format data.

WARNING:  The parameter {\tt rowlist} enables you to make data selection based
on row number in the Measurement Set or scantable for data saving. 
Note that data should be treated carefully when applying row
based selection, since row numbers can be changed easily by
sorting, prior selection, etc. Therefore, this parameter is expected
to be used by expert users only . 


\subsubsection{{\tt sdscale}}
\label{section:sd.sdtasks.tasks.sdscale}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
antenna -- antenna name or id (only effective for MS input). 
factor -- scaling factor. float or one- or two-dimensional float list.
          default: 1 (no scaling)
scaletsys -- scaling of associated Tsys
            default: True
outfile -- output file name 
           outfile='' will write the data to a file named,
           <infile>_scaled<factor>
           default: ''
overwrite -- overwrite the output file if already exists
        options: (bool) True,False
        default: False
\end{verbatim}

DESCRIPTION:

Task {\tt sdscale} performs scaling of single-dish spectra.
By setting {\tt scaletsys = True}, associated Tsys is also scaled.
Tsys information are written into the file 'sdscale.log'
as well as they are displayed in the terminal window.
The {\tt infile} can be any of ASAP, MS, SDFITS, or RPFITS format.
If {\tt outfile} name is given or {\tt outfile=''}(default), the scaled data is written
to a new file with the same format as the input data (Note: in case of the
RPFITS format input data, it will be written to SDFITS format).
    
The scaling factor, {\tt factor}, accepts both scalar type and list type
value. The list must be one or two dimensional. If {\tt factor} is one
dimensional, its length must coincide with a number of spectral
channel. If {\tt factor} is two dimensional, its shape must be (n,1) or
(n,m), where n is a number of spectrum, while m is a number of channel
for each spectrum. m can be variable for each spectrum. In addition,
the {\tt factor} can be an ASCII filename that stores a space-separated list
of scaling factor consisting of adequate number of rows and columns.
For example, if the content of input ASCII file is shown as,

\begin{verbatim}
    0.5 0.3 0.2
    1.0 0.2 0.9
\end{verbatim}

it is interpreted as a list [[0.5,0.3,0.2],[1.0,0.2,0.9]].

See the {\tt sdcal} description for note on GBT raw SDFITS format data.

\subsubsection{{\tt sdstat}}
\label{section:sd.sdtasks.tasks.sdstat}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD dataset
        default: none - must input file name
        example: 'mysd.asap'
                 See sdreduce for allowed formats.
antenna -- antenna name or id (only effective for MS input). 
fluxunit -- units for line flux
        options: (str) 'K','Jy',''
        default: '' (keep current fluxunit)
        WARNING: For GBT data, see description below.
    >>> fluxunit expandable parameter
         telescopeparm -- the telescope characteristics
                options: (str) name or (list) list of gain info
                default: '' (none set)
                example: if telescopeparm='', it tries to get the telescope
                         name from the data.
                         Full antenna parameters (diameter,ap.eff.) known
                         to ASAP are
                         'ATPKSMB', 'ATPKSHOH', 'ATMOPRA', 'DSS-43',
                         'CEDUNA','HOBART'. For GBT, it fixes default fluxunit
                         to 'K' first then convert to a new fluxunit.
                         telescopeparm=[104.9,0.43] diameter(m), ap.eff.
                         telescopeparm=[0.743] gain in Jy/K
                         telescopeparm='FIX' to change default fluxunit
                         see description below

specunit -- units for spectral axis
        options: (str) 'channel','km/s','GHz','MHz','kHz','Hz',''
        default: '' (=current)
    >>> specunit expandable parameter
         restfreq -- rest frequency
                 default: '' (use current setting)
                 example: 4.6e10 (float value in Hz),
                          '46GHz' (string with unit),
                          ['345.8GHz', 347.0e9, 356.7e9] (for each IF)
                          [{'name':'CO','value':345e9}] (a value with name)
frame -- frequency frame for spectral axis
        options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                 'GEO','GALACTO','LGROUP','CMB'
        default: currently set frame in scantable
        WARNING: frame='REST' not yet implemented
doppler -- doppler mode
        options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
        default: currently set doppler in scantable
scanlist -- list of scan numbers to process
        default: [] (use all scans)
        example: [21,22,23,24]
        this selection is in addition to field, iflist, and pollist
field -- selection string for selecting scans by name
        default: '' (no name selection)
        example: 'FLS3a*'
        this selection is in addition to scanlist, iflist, and pollist
iflist -- list of IF id numbers to select
        default: [] (use all IFs)
        example: [15]
        this selection is in addition to field, scanlist, and pollist
pollist -- list of polarization id numbers to select
        default: [] (use all pols)
        example: [1]
        this selection is in addition to field, scanlist, and iflist
masklist -- list of mask regions to INCLUDE in stats
        default: [] (whole spectrum)
        example: [4000,4500] for one region
                 [[1000,3000],[5000,7000]]
                 these must be pairs of [lo,hi] boundaries
invertmask -- invert mask (EXCLUDE masklist instead)
        options: (bool) True,False
        default: false
interactive -- determines interactive masking
        options: (bool) True,False
        default: False
        example: interactive=True allows adding and deleting mask 
                 regions by drawing rectangles on the plot with mouse. 
                 Draw a rectangle with LEFT-mouse to ADD the region to 
                 the mask and with RIGHT-mouse to DELETE the region. 
outfile -- name of output file for line statistics
        default: '' (no output statistics file)
        example: 'stat.txt'
format -- format string to print statistic values
        default: '3.3f'
overwrite -- overwrite the statistics file if already exists 
        options: (bool) True,False
        default: False

-------------------------------------------------------------------
        Returns: a Python dictionary of line statistics
           keys: 'rms','stddev','max','min','max_abscissa',
                 'min_abscissa','sum','median','mean','totint','eqw'
        example: xstat=sdstat(); print "rms = ",xstat['rms']
                 these can be used for testing in scripts or
                 for regression

                 'max_abscissa' and 'min_abscissa' refer to the abscissa
                 (channel/frequency/velocity) of max and min intensity.
                 'totint' is the integrated intensity (sum*dx)
                 where dx is the abscissa interval in 'specunit'.
                 'eqw' is equivalent width (totint/mag) where mag
                 is either max or min depending on which has
                 greater magnitude. 
                 Note that 'max_abscissa', 'min_abscissa', 'totint' 
                 and 'eqw' are quantities (python dictionaries with
                 keys, 'unit' and 'value').

\end{verbatim}

DESCRIPTION: 

Task {\tt sdstat} computes basic statistics (rms,mean,median,sum)
for single-dish spectra.  It assumes that the spectra have
been calibrated.  Furthermore, it assumes that any
time and channel averaging/smoothing has also already been done as
there are no controls for these. Note that you can run {\tt sdreduce}
with {\tt calmode='none'} and do selection, writing out a new
scantable.
The calculated statistics are written into a file specified by
{\tt outfile}.
Interactive mask specification is possible with {\tt interactive=True}.
Integrated intensity will be shown on the screen and will be included
in the saved {\tt outfile} (but not yet available in the returned dictionary).

Note that multiple scans and IFs can in principle be handled, but
we recommend that you use {\tt scanlist}, {\tt field}, {\tt
iflist}, and {\tt pollist} to give a single selection for each run.

See the {\tt sdcal} description for information on the {\tt fluxunit} 
conversion and the {\tt telescopeparm} parameter.
Also, see the {\tt sdcal} description for note on GBT raw SDFITS format data.

WARNING: If you do have multiple scantable rows, then {\tt xstat}
values will be lists.


\subsubsection{{\tt sdtpimaging}}
\label{section:sd.sdtasks.tasks.sdtpimaging}

\begin{verbatim}
Keyword arguments:
infile -- name of input SD (MS) dataset
calmode -- calibration mode (currently only baseline subtraction)
        options: 'baseline','none'
        default: 'none'
        example: choose mode 'none' if you have
                 already calibrated and want to do
                 plotting and/or imaging 
    >>> calmode='baseline' expandable parameters
       masklist -- mask in numbers of rows from each edge of each scan 
                   to be included for baseline fitting
         default: none
         example: [30,30] or [30] 
                  used first 30 rows and last 30 rows of each scan for 
                  the baseline 
       blpoly -- polynomial order for the baseline fit
         default: 1
       backup -- set True to create backup for input data
         default: True
flaglist -- list of scan numbers to flag (ranges can be accepted)  
        default: [] (use all scans)
        example: [[0,3],80]
                 flag the scan range [0,3] = [0,1,2,3] and scan 80 
antenna -- select data based on antenna name(s) or id(s) in string
        default: '' (use all antennas)
        example: '0,1', 'DV01'
        WARNING: currently baseline subtraction properly 
                 only one of the antennas.
stokes -- select data based on stokes or polarization type 
        default: '' (use all polarizations)
        example: 'XX'
createimage -- do imaging? 
        default: False 
    >>> createimage=True expandable parameters
       outfile -- output image name
         default: none
         example: 'mySDimage.im'
       imsize -- x and y image size in pixels, symmetric for single 
                 value
         default: [256,256]
         example: imsize=200 (equivalent to [200,200])
       cell -- x and y cell size. default unit arcmin
         default: '1.0arcmin'
         example: cell=['0.2arcmin, 0.2arcmin']
                  cell='0.2arcmin' (equivalent to example above)
       phasecenter -- image phase center: direction measure or fieldid 
         default: 0
         example: 'J2000 13h44m00 -17d02m00', 'AZEL -123d48m29 15d41m41'
       ephemsrcname -- ephemeris source name to proper shifting to 
                       center on the moving source for imaging
         default: ''
                  if the source name in the data matches one of the 
                  known solar objects by the system, this task 
                  automatically set the source name. 
         example: 'moon' 
       pointingcolumn -- pointing data column to use
         option: 'direction', 'target', 'pointing_offset', 
                 'source_offset', 'encoder' 
         default: 'direction'
       gridfunction -- gridding function for imaging
         options: 'BOX' (Box-car), 'SF' (Spheroidal), 
                  'PB' (Primary-beam), 'GAUSS' (Gaussian),
                  'GJINC' (Gaussian*Jinc)
         default: 'BOX'
         example: 'SF'
plotlevel -- control for plotting of results
        options: (int) 0=none, 1=some, 2=more, <0=hardcopy
        default: 0 (no plotting)
        example: plotlevel<0 as abs(plotlevel), e.g.
                 -1: hardcopy plot 
                     (will be named <infile>_scans.eps)
                  1: plot raw data, calibrated data 
                     (for calmode='baseline)
                     plot raw or if exist calibrated data 
                     (for calmode='none')
                  2: plot raw data, progressively display baseline 
                     fitting for each scan, and final calibrated data 
                     (for calmode='baseline')  

\end{verbatim}
DESCRIPTION:

Task {\tt sdtpimaging} performs data selection, calibration, and
imaging for single-dish total power raster scan data.  This is a still
experimental task made to work for the data taken at the ALMA Testing
Facility (ATF) and OSF. Currently, this task directly accesses the
Measurement Set data because of the data access efficiency.  So it
differs from other single-dish tasks that mostly operate on the ASAP
scantable data format.  By setting {\tt calmode='none'}, one can run
{\tt sdtpimaging} to plot the data (raw or calibrated, if exists) and
further imaging by setting {\tt createimage=True}.  The calibration
available at this moment is just a simple baseline subtraction for
each scan. The fitted regions set by {\tt masklist} are the common for
all the scans.  Selection of the antennas can be made by setting
antenna ID(s) or antenna name(s) in string (e.g. '0', '0,1',
'DV01',etc.).  For baseline subtraction, it currently works properly
for a single antenna selection.  So a separate {\tt sdtpimaging} task
needs to be run for each antenna.  It currently assumes that the data
has a single spw(=0) and fieldid(=0).  By setting {\tt flaglist}, one
can set flag by scan numbers to be excluded from imaging.  (Note:
'scan numbers' are determined from state id and related to SUB\_SCAN
column in STATE subtable and they are typically different from
SCAN\_NUMBER in MS.)  By default, baseline subtraction stage
overwrites \verb!(FLOAT_)DATA! column of input data. You can keep
original data by setting {\tt backup} parameter to True. In this case,
the task make a copy of input data specified by infile parameter.
Name of backup file is \verb|<infile>.sdtpimaging.bak.<timestamp>|.
The selection of polarizations can be made by specifying the
polarization name in stokes, such as 'XX' or 'YY' for linear
polarizations. For example, with {\tt createimage=True}, {\tt
  stokes='XXYY'} will produces an image cube with each plane contains
the image of one of the polarizations while {\tt stokes=''} or {\tt
  stokes='I'} will produces a 'total intensity' or Stokes I image.

Among the imaging sub-parameters, {\tt ephemsrcname} is used to set
the name of a moving source such as planets to produce a stationary
image (can be omitted), and {\tt pointingcolumn} is used to specify
which pointing data column to use for imaging.  Convolution kernel for
imaging can be specified by using gridfunction. Available options are
'Box' (Box-car), 'SF' (Spheroidal), 'PB' (Primary-beam), 'GAUSS'
(Gaussian), and 'GJINC' (Gaussian*Jinc), where ${\rm Jinc}(x) = {\rm
  J}_1 \left( \frac{\pi x}{c} \right) / \left(\frac{\pi x}{c} \right)
$ with a first order Bessel function ${\rm J}_1$. Sub-parameters for
convolution functions cannot be specified in this task. To customize
your convolution function, please do imaging using sdimaging task or
imager tool.

\subsubsection{{\tt sdimprocess}}
\label{section:sd.sdtasks.tasks.sdimprocess}

\begin{verbatim}
Keyword arguments:
infiles -- name of input SD (FITS or CASA) image
mode -- processing mode
        default: 'basket'
        options: 'basket', 'press'

    >>>mode expandable parameter
         direction -- scan direction in unit of degree
             default: []
             example: [0.0,90.0]
         masklist -- mask width for Basket-Weaving on percentage
             default: 1.0 (1.0\% of map size)
         numpoly -- order of polynomial fit in Pressed-out
             default: 2
         beamsize -- beam size 
             default: 0.0
             example: 10.0 (interpreted as '10arcsec'), '1arcmin'
         smoothsize -- smoothing beam in Pressed-out
             default: 2.0 (interpreted as 2.0 * beamsize)
             example: '1arcmin' (set smoothsize directly)

tmax -- maximum value used for process
        default: 0.0 (no threshold in maximum)
        example: 10.0 (mask data larger value than 10.0)
tmin -- minimum value used for process
        default: 0.0 (no threshold in minimum)
        example: -10.0 (mask data smaller value than -10.0)
outfile -- output CASA image name
        default: '' (use default name)
        example: 'output.im'
overwrite -- overwrite option for outfile
        default: False (not overwrite)
        options: True, False
        example: if True, existing file will be overwritten
\end{verbatim}

DESCRIPTION:

Task {\tt sdimprocess} is used to remove a scanning noise that appears 
as a striped noise pattern along the scan direction in a raster 
scan data. 

By default, the scanning noise is removed by using the 
'Basket-Weaving' method (Emerson \& Grave 1988) that requires 
multiple images that observed exactly the same area with different 
scanning direction. If only one image is available, the 'Pressed-out' 
method (Sofue \& Reich 1979) can be used to remove the scanning effect.

For 'Basket-Weaving', scanning directions must have at least two 
different values. Normally, the scanning direction should be 
specified for each input image. Otherwise, specified scanning 
directions will be used iteratively. The {\tt masklist} is a width of 
masking region in the Fourier plane. It is specified as a fraction 
(percentage) of the image size. 

For 'Pressed-out', the scanning direction must be unique. There are 
two ways to specify a size of smoothing beam used for process. One 
is to specify smoothing size directly, where {\tt smoothsize} is specified
as string that consists of a numerical value and an unit 
(e.g. '10.0arcsec'). The value of {\tt beamsize} will be ignored in this case. 
Another way to specify smoothing size is to set an observed beam size 
and indicate them smoothing size as a scale factor of the observed beam.
In this case, the {\tt beamsize} is interpreted as the observed beam 
size, and the {\tt smoothsize} is the scale factor. If the {\tt beamsize} is 
provided as float value, its unit is assumed to have 'arcsec' units. It is also 
possible to set the {\tt beamsize} as string consisting of the numerical 
value and the unit. The {\tt smoothsize} must be float value.

The {\tt infiles} only allows an image data (CASA or FITS), and does
not work with MS or Scantable. The {\tt direction} is an angle with respect 
to the horizontal direction in degree units. Any value may be 
interpreted properly, but the value ranging from 0.0 to 180.0 will be 
secure. The {\tt tmax} and the {\tt tmin} is used to specify a threshold that 
defines a range of spectral values used for processing. The data point 
that has the value larger than {\tt tmax} or smaller than {\tt tmin} will be 
excluded from the processing. The default (0.0) is no threshold. 
The {\tt outfile} specifies an output CASA image name. If the {\tt outfile} 
is empty, the default name ('sdimprocess.out.im') will be used. 


\subsubsection{{\tt msmoments}}
\label{section:sd.sdtasks.tasks.sdmoments}

\begin{verbatim}
Keyword arguments:
infile -- Name of input MS data
        default: none; example: infile="OrionS_rawACSmod"
moments -- List of moments you would like to compute
        default: 0 (integrated spectrum);example: moments=[0,1]
        see list above
antenna -- antenna name or id that the user wants to compute moments
        default: '' (all antennae)
field -- field name or id that the user wants to compute moments
        default: '' (all fields)
spw -- spectral window id that the user wants to compute moments
        default: '' (all spectral windows)

includemask -- List of masks to include
        default: [-1] (include all channels); example=[2,100]
excludemask -- List of masks to exclude
        default: [-1] (don't exclude channels); example=[100,200]
outfile -- Output MS file name (or root for multiple moments)
        default: '' (input+auto-determined suffix);example: outfile='source_moment'
overwrite -- Overwrite existing output files
        default: false
\end{verbatim}

Task {\tt msmoments} computes moments from spectral data stored
in MS. The task is defined in analogy with {\tt immoments} task,
so that you can calculate any moments that is available
for {\tt  immoments} task. Currently, the task only accepts MS
with FLOAT\_DATA column.

The spectral moment distributions at each row in input MS are
determined. Input MS must have FLOAT\_DATA column, i.e. 
autocorrelation data.  
See the cookbook and User Reference Manual for
mathematical details.

The main control of the calculation is given by parameter {\tt moments}:
        
\begin{itemize}
   \item {\tt moments=-1} - mean value of the spectrum
   \item {\tt moments=0}  - integrated value of the spectrum
   \item {\tt moments=1}  - intensity weighted coordinate;traditionally used to get 'velocity fields'
   \item {\tt moments=2}  - intensity weighted dispersion of the coordinate; traditionally used to get "velocity dispersion"
   \item {\tt moments=3}  - median of I
   \item {\tt moments=4}  - median coordinate
   \item {\tt moments=5}  - standard deviation about the mean of the spectrum
   \item {\tt moments=6}  - root mean square of the spectrum
   \item {\tt moments=7}  - absolute mean deviation of the spectrum
   \item {\tt moments=8}  - maximum value of the spectrum
   \item {\tt moments=9}  - coordinate of the maximum value of the spectrum
   \item {\tt moments=10} - minimum value of the spectrum
   \item {\tt moments=11} - coordinate of the minimum value of the spectrum
\end{itemize}

Note that includemask and excludemask cannot set simultaneously. 

Example for finding the 1-momment, intensity-weighted
coordinate, often used for finding velocity fields.

\begin{verbatim}
   msmoments( infile="mydata", moment=1, outfile="velocityfields" )
\end{verbatim}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Single Dish Analysis Use Cases With SDTasks}
\label{section:sd.sdtasks.usecase}

\subsubsection{GBT Position Switched Data Analysis}
As an example, the following illustrates the use of the SDtasks for
the Orion data set, which contains the HCCCN line in one of its IFs.
This walk-through contains comments about setting parameter values
and some options during processing.

\begin{verbatim}
#####################################
#
# ORION-S SDtasks Use Case
# Position-Switched data
# Version TT 2008-10-14 (updated)
# Version STM 2007-03-04
#
# This is a detailed walk-through
# for using the SDtasks on a
# test dataset.
#
#####################################
import time
import os

#
# This is the environment variable
# pointing to the head of the CASA
# tree that you are running
casapath=os.environ['AIPSPATH']

#
# This bit removes old versions of the output files
os.system('rm -rf sdusecase_orions* ')
#
# This is the path to the OrionS GBT ms in the data repository
datapath=casapath+'/data/regression/ATST5/OrionS/OrionS_rawACSmod'
#
# The following will remove old versions of the data and
# copy the data from the repository to your
# current directory.  Comment this out if you already have it
# and don't want to recopy
os.system('rm -rf OrionS_rawACSmod')
copystring='cp -r '+datapath+' .'
os.system(copystring)

# Now is the time to set some of the more useful
# ASAP environment parameters (the ones that the
# ASAP User Manual claims are in the .asaprc file).
# These are in the Python dictionary sd.rcParams
# You can see what's in it by typing:
#sd.rcParams
# One of them is the 'verbose' parameter which tells
# ASAP whether to spew lots of verbiage during processing
# or to keep quiet.  The default is
#sd.rcParams['verbose']=True
# You can make ASAP run quietly (with only task output) with
#sd.rcParams['verbose']=False

# Another key one is to tell ASAP to save memory by
# going off the disk instead.  The default is
#sd.rcParams['scantable.storage']='memory'
# but if you are on a machine with small memory, do
#sd.rcParams['scantable.storage']='disk'

# You can reset back to defaults with
#sd.rcdefaults

##########################
#
# ORION-S HC3N
# Position-Switched data
#
##########################
startTime=time.time()
startProc=time.clock()

##########################
# List data
##########################
# List the contents of the dataset
# First reset parameter defaults (safe)
default('sdlist')

# You can see its inputs with
#inp('sdlist')
# or just
#inp
# now that the defaults('sdlist') set the
# taskname='sdlist'
#
# Set the name of the GBT ms file
infile = 'OrionS_rawACSmod'

# Set an output file in case we want to
# refer back to it
outfile = 'sdusecase_orions_summary.txt'
sdlist()

# You could also just type
#go

# You should see something like:
#
\end{verbatim}
\scriptsize
\begin{verbatim}
# --------------------------------------------------------------------------------
#  Scan Table Summary
# --------------------------------------------------------------------------------
# Project:       AGBT06A_018_01
# Obs Date:      2006/01/19/01:45:58
# Observer:      Joseph McMullin
# Antenna Name:  GBT@GREENBANK
# Data Records:  512 rows
# Obs. Type:     OffOn:PSWITCHOFF:TPWCAL
# Beams:         1   
# IFs:           8   
# Polarisations: 2   (circular)
# Channels:      8192
# Flux Unit:     K
# Abscissa:      Channel
# Selection:     none
#
# Scan Source         Time range                           Int[s] Record SrcType FreqIDs MolIDs 
#        Beam  Position (J2000)       
# --------------------------------------------------------------------------------
#   20 OrionS         2006/01/19/01:45:58.0 - 01:47:58.2   30.03     64  [PSOFF, PSOFF:CALON] [0, 1, 2, 3] [0]
#        0      05:15:13.5 -05.24.08.6
#   21 OrionS         2006/01/19/01:48:38.0 - 01:50:38.2   30.03     64  [PSON, PSON:CALON] [0, 1, 2, 3] [0]
#        0      05:35:13.4 -05.24.07.8
#   22 OrionS         2006/01/19/01:51:21.0 - 01:53:21.2   30.03     64  [PSOFF, PSOFF:CALON] [0, 1, 2, 3] [0]
#        0      05:15:13.6 -05.24.08.5
#   23 OrionS         2006/01/19/01:54:01.0 - 01:56:01.2   30.03     64  [PSON, PSON:CALON] [0, 1, 2, 3] [0]
#        0      05:35:13.4 -05.24.08.1
#   24 OrionS         2006/01/19/02:01:47.0 - 02:03:47.2   30.03     64  [PSOFF, PSOFF:CALON] [4, 5, 6, 7] [1]
#        0      05:15:13.5 -05.24.08.5
#   25 OrionS         2006/01/19/02:04:27.0 - 02:06:27.2   30.03     64  [PSON, PSON:CALON] [4, 5, 6, 7] [1]
#        0      05:35:13.4 -05.24.08.1
#   26 OrionS         2006/01/19/02:07:10.0 - 02:09:10.2   30.03     64  [PSOFF, PSOFF:CALON] [4, 5, 6, 7] [1]
#        0      05:15:13.5 -05.24.08.4
#   27 OrionS         2006/01/19/02:09:51.0 - 02:11:51.2   30.03     64  [PSON, PSON:CALON] [4, 5, 6, 7] [1]
#        0      05:35:13.3 -05.24.08.1
# --------------------------------------------------------------------------------
# FREQUENCIES: 4
#    ID  IFNO   Frame   RefVal          RefPix Increment      Channels POLNOs
#     0    0     LSRK   4.5489351e+10 4095.5       6104.233      8192  [0, 1]
#     1    1     LSRK   4.5300782e+10 4095.5       6104.233      8192  [0, 1]
#     2    2     LSRK   4.4074926e+10 4095.5       6104.233      8192  [0, 1]
#     3    3     LSRK   4.4166212e+10 4095.5       6104.233      8192  [0, 1]
#     4   12     LSRK   4.3962123e+10 4095.5      6104.2336      8192  [0, 1]
#     5   13     LSRK   4.2645417e+10 4095.5      6104.2336      8192  [0, 1]
#     6   14     LSRK   4.1594977e+10 4095.5      6104.2336      8192  [0, 1]
#     7   15     LSRK    4.342282e+10 4095.5      6104.2336      8192  [0, 1]
# --------------------------------------------------------------------------------
# MOLECULES: 
#    ID   RestFreq          Name           
#     0   [4.54903e+10] []
#     1   [4.3963e+10] []
# --------------------------------------------------------------------------------
\end{verbatim}
\normalsize
\begin{verbatim}
# The HC3N and CH3OH lines are in IFs 0 and 2 respectively
# of scans 20,21,22,23.  We will pull these out in our
# calibration.

##########################
# Calibrate data
##########################
# We will use the sdreduce task to calibrate the data.
# Set the defaults
default('sdreduce')

# You can see the inputs with
#inp

# Set our infile (which would have been set from our run of
# sdlist if we were not cautious and reset defaults).
infile = 'OrionS_rawACSmod'
fluxunit = 'K'

# Lets leave the spectral axis in channels for now
specunit = 'channel'

# This is position-switched data so we tell sdreduce this
calmode = 'ps'

# For GBT data, it is safest to not have scantable pre-average
# integrations within scans.
average = True
scanaverage = False

# We do want sdreduce to average up scans and polarization after
# calibration however. The averaging of scans are weighted by 
# integration time and Tsys, and the averaging of polarization 
# by Tsys.
timeaverage = True
tweight = 'tintsys'
polaverage = True
pweight = 'tsys'
# Do an atmospheric optical depth (attenuation) correction
# Input the zenith optical depth at 43 GHz
tau = 0.09

# Select our scans and IFs (for HC3N)
scanlist = [20,21,22,23]
iflist = [0]

# We do not require selection by field name (they are all
# the same except for on and off)
field = ''

# We will do some spectral smoothing
# For this demo we will use boxcar smoothing rather than
# the default
#kernel='hanning'
# We will set the width of the kernel to 5 channels
kernel = 'boxcar'
kwidth = 5

# We wish to fit out a baseline from the spectrum
# The GBT has particularly nasty baselines :(
# We will let ASAP use auto_poly_baseline mode
# but tell it to drop the 1000 edge channels from
# the beginning and end of the spectrum.
# A 2nd-order polynomial will suffice for this test.
# You might try higher orders for fun.
blmode = 'auto'
blpoly = 2
edge = [1000]

# We will not give it regions as an input mask
# though you could, with something like
#masklist=[[1000,3000],[5000,7000]]
masklist = []

# By default, we will not get plots in sdreduce (but
# can make them using sdplot).
plotlevel = 0
# But if you wish to see a final spectrum, set
#plotlevel = 1
# or even
#plotlevel = 2
# to see intermediate plots and baselining output.

# Now we give the name for the output file
outfile = 'sdusecase_orions_hc3n.asap'

# We will write it out in ASAP scantable format
outform = 'asap'

# You can look at the inputs with
#inp

# Before running, lets save the inputs in case we want
# to come back and re-run the calibration.
saveinputs('sdreduce','sdreduce.orions.save')
# These can be recovered by
#execfile 'sdreduce.orions.save'

# We are ready to calibrate
sdreduce()

# Note that after the task ran, it produced a file
# sdreduce.last which contains the inputs from the last
# run of the task (all tasks do this). You can recover
# this (any time before sdreduce is run again) with
#execfile 'sdreduce.last'

##########################
# List data
##########################
# List the contents of the calibrated dataset
# Set the input to the just created file
infile = outfile
outfile = ''
sdlist()

# You should see:
\end{verbatim}
\footnotesize
\begin{verbatim}
# --------------------------------------------------------------------------------
#  Scan Table Summary
# --------------------------------------------------------------------------------
# Project:       AGBT06A_018_01
# Obs Date:      2006/01/19/01:45:58
# Observer:      Joseph McMullin
# Antenna Name:  GBT@GREENBANK
# Data Records:  1 rows
# Obs. Type:     OffOn:PSWITCHOFF:TPWCAL
# Beams:         1   
# IFs:           8   
# Polarisations: 1   (stokes)
# Channels:      8192
# Flux Unit:     K
# Abscissa:      Channel
# Selection:     none

# Scan Source         Time range                           Int[s] Record SrcType FreqIDs MolIDs 
#        Beam  Position (J2000)       
# --------------------------------------------------------------------------------
#    0 OrionS         2006/01/19/01:52:04.6 - 02:00:05.1   480.48     1  [PSON] [0] [0]
#        0      05:35:13.4 -05.24.07.8
# --------------------------------------------------------------------------------
# FREQUENCIES: 1
#    ID  IFNO   Frame   RefVal          RefPix Increment      Channels POLNOs
#     0    0     LSRK   4.5489351e+10 4095.5       6104.233      8192  [0]
# --------------------------------------------------------------------------------
# MOLECULES: 
#    ID   RestFreq          Name           
#     0   [4.54903e+10] []
#     1   [4.3963e+10] []
# --------------------------------------------------------------------------------
\end{verbatim}
\normalsize
\begin{verbatim}
# Note that our scans are now collapsed (timeaverage=True) but 
# we still have our IF 0

##########################
# Plot data
##########################
default('sdplot')

# The file we produced after calibration
# (if we hadn't reset defaults it would have
# been set - note that sdplot,sdfit,sdstat use
# infile as the input file, which is the output
# file of sdreduce).
infile = 'sdusecase_orions_hc3n.asap'

# Let's just go ahead and plot it up as-is
sdplot()

# Looks ok.  Plot with x-axis in GHz
specunit='GHz'
sdplot()

# Note that the rest frequency in the scantable
# is set correctly to the HCCCN line at 45.490 GHz.
# So you can plot the spectrum in km/s
specunit='km/s'
sdplot()

# Zoom in
sprange=[-100,50]
sdplot()

# Let's plot up the lines to be sure
# We have to go back to GHz for this
# (known deficiency in ASAP)
specunit='GHz'
sprange=[45.48,45.51]
linecat='all'
sdplot()

# Too many lines! Focus on the HC3N ones
linecat='HCCCN'
sdplot()

# Finally, we can convert from K to Jy
# using the aperture efficiencies we have
# coded into the sdtasks
# For GBT data, do not set telescopeparm
fluxunit='Jy'
telescopeparm=''
sdplot()

# Let's save this plot
outfile='sdusecase_orions_hc3n.eps'
sdplot()

##########################
# Off-line Statistics
##########################
# Now do some region statistics
# First the line-free region
# Set parameters
default('sdstat')
infile = 'sdusecase_orions_hc3n.asap'

# Keep the default spectrum and flux units
# K and channel
fluxunit = ''
specunit = ''

# Pick out a line-free region
# You can bring up a default sdplot again
# to check this
masklist = [[5000,7000]]

# This is a line-free region so we don't need
# to invert the mask
invertmask = False

# You can check with
#inp

# sdstat returns some results in
# the Python dictionary.  You can assign
# this to a variable
off_stat=sdstat()

# and look at it
off_stat
# which should give
# {'eqw': 38.563105620704945,
#  'max': 0.15543246269226074,
#  'mean': -0.0030361821409314871,
#  'median': -0.0032975673675537109,
#  'min': -0.15754437446594238,
#  'rms': 0.047580458223819733,
#  'stddev': 0.047495327889919281,
#  'sum': -6.0754003524780273}


#You see it has some keywords for the various
#stats.  We want the standard deviation about
#the mean, or 'stddev'
print "The off-line std. deviation = ",off_stat['stddev']
# which should give
# The off-line std. deviation =  0.0474953278899

# or better formatted (using Python I/O formatting)
print "The off-line std. deviation = %5.3f K" %\
      (off_stat['stddev'])
# which should give
# The off-line std. deviation = 0.047 K

##########################
# On-line Statistics
##########################
# Now do the line region
# Continue setting or resetting parameters
masklist = [[3900,4200]]

line_stat = sdstat()

# look at these
line_stat
# which gives
# {'eqw': 73.335154614280981,
#  'max': 0.92909121513366699,
#  'mean': 0.22636228799819946,
#  'median': 0.10317134857177734,
#  'min': -0.13283586502075195,
#  'rms': 0.35585442185401917,
#  'stddev': 0.27503398060798645,
#  'sum': 68.135047912597656}

# of particular interest are the max value
print "The on-line maximum = %5.3f K" % (line_stat['max'])
# which gives
# The on-line maximum = 0.929 K

# and the estimated equivalent width (in channels)
# which is the sum/max
print "The estimated equivalent width = %5.1f channels" %\
      (line_stat['eqw'])
# which gives
# The estimated equivalent width =  73.3 channels

##########################
# Line Fitting
##########################
# Now we are ready to do some line fitting
# Default the parameters
default('sdfit')

# Set our input file
infile = 'sdusecase_orions_hc3n.asap'

# Stick to defaults
# fluxunit = 'K', specunit = 'channel'
fluxunit = ''
specunit = ''

# We will try auto-fitting first
fitmode = 'auto'
# A single Gaussian
nfit = [1]
# Leave the auto-parameters to their defaults for
# now, except ignore the edge channels
edge = [1000]

# Let's see a plot while doing this
plotlevel = 1

# Save the fit output in a file
outfile = 'sdusecase_orions_hc3n.fit'

# Go ahead and do the fit
fit_stat=sdfit()

# If you had verbose mode on, you probably saw something
# like:
#
# 0: peak = 0.811 K , centre = 4091.041 channel, FWHM = 72.900 channel
#    area = 62.918 K channel
#

# The fit is output in the dictionary

fit_stat
#
# {'cent': [[4091.04052734375, 0.72398632764816284]],
#  'fwhm': [[72.899894714355469, 1.7048574686050415]],
#  'nfit': 1,
#  'peak': [[0.81080442667007446, 0.016420882195234299]]}
#
# So you can write them out or test them:
print "The line-fit parameters were:"
print "      maximum = %6.3f +/- %6.3f K" %\
      (fit_stat['peak'][0][0],fit_stat['peak'][0][1])
print "       center = %6.1f +/- %6.1f channels" %\
      (fit_stat['cent'][0][0],fit_stat['cent'][0][1])
print "         FWHM = %6.2f +/- %6.2f channels" %\
      (fit_stat['fwhm'][0][0],fit_stat['fwhm'][0][1])
#
# Which gives:
# The line-fit parameters were:
#       maximum =  0.811 +/-  0.016 K
#        center = 4091.0 +/-    0.7 channels
#          FWHM =  72.90 +/-   1.70 channels

# We can do the fit in km/s also
specunit = 'km/s'
# For some reason we need to help it along with a mask
maskline = [-50,0]

outfile = 'sdusecase_orions_hc3n_kms.fit'
fit_stat_kms = sdfit()
# Should give (if in verbose mode)
#   0: peak = 0.811 K , centre = -27.134 km/s, FWHM = 2.933 km/s
#      area = 2.531 K km/s
#


# with
fit_stat_kms
# giving
# {'cent': [[-27.133651733398438, 0.016480101272463799]],
#  'fwhm': [[2.93294358253479, 0.038807671517133713]],
#  'nfit': 1,
#  'peak': [[0.81080895662307739, 0.0092909494414925575]]}


print "The line-fit parameters were:"
print "      maximum = %6.3f +/- %6.3f K" %\
      (fit_stat_kms['peak'][0][0],fit_stat_kms['peak'][0][1])
print "       center = %6.2f +/- %6.2f km/s" %\
      (fit_stat_kms['cent'][0][0],fit_stat_kms['cent'][0][1])
print "         FWHM = %6.4f +/- %6.4f km/s" %\
      (fit_stat_kms['fwhm'][0][0],fit_stat_kms['fwhm'][0][1])

# The line-fit parameters were:
#       maximum =  0.811 +/-  0.009 K
#        center = -27.13 +/-   0.02 km/s
#          FWHM = 2.9329 +/- 0.0388 km/s

##########################
#
# End ORION-S Use Case
#
##########################
\end{verbatim}

\subsubsection{Imaging of Total Power Raster Scans}
This example illustrates the use of {\tt sdtpimaging} for the total
power raster scans of the Moon taken at ATF.
\begin{figure}[h!]
\begin{center}
\pnghigh{totalpower_calib}{5}
\caption{\label{fig:sdtpimaging} Total power data display using {\tt sdtpimaging}, 
with {\tt calmode='baseline'}. The top  panel shows uncalibrated data versus row numbers.The middle panel shows baseline fitting of each scan (only shown here the last
scan). The bottom panel shows the calibrated (baseline subtracted) data. }
\hrulefill
\end{center}
\end{figure}

\begin{verbatim}
# The data used here (uid___X1e1_X3197_X1.ms) is the total power 
# raster scans of the Moon  taken  at ATF (with both antennas). 
# It is in MS format  which was converted from the ASDM format.

# Do data plotting only
default(sdtpimaging)
inp()
plotlevel=2
# select antenna 1 (Vertex antenna) 
antenna='1'
infile='uid___X1e1_X3197_X1.ms'
sdtpimaging()

# Now, rerun sdtpimaging to do actual data reduction (applying
# baseline subtraction from each scan, and then do imaging).
#
# Do baseline subtraction 
calmode='baseline'
masklist=[30] # use 30 data points from each end of scan for fitting
# Do imaging 
createimage=True
outfile='moon.im'
imagesize=[200,200]
cell=[0.2] # in arcmin
phasecenter='AZEL 187d54m22s 41d03m0s'  
ephemsrcname='moon' # specify ephemeris source name (can be omitted)
plotlevel=1
#plotlevel=2 to see progress of each fitting
sdtpimaging()
\end{verbatim}

%% TODO 
%%\subsubsection{spectral imaging (with sdimaging?)}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


##################### generated by xml-casa (v2) from table.xml #####################
##################### 14a5aad1a3c523d174f26c900bb9548f ##############################
from __future__ import absolute_import 
from .__casac__ import table as _table
from .platform import str_encode as _str_ec
from .platform import str_decode as _str_dc
from .platform import dict_encode as _dict_ec
from .platform import dict_decode as _dict_dc
from .platform import dict_encode as _quant_ec
from .platform import dict_decode as _quant_dc
from .platform import encode as _any_ec
from .platform import decode as _any_dc
from .typecheck import validator as _pc
from .coercetype import coerce as _coerce
_wrap_table = lambda swig_object: table(swig_object=swig_object)

class table:
    ### self
    def __init__(self, *args, **kwargs):
        """Use this constructor to construct a table tool inside casapy from
        the name of a disk file containing a casa Table. A
        new table may also be created from a table descriptor
        (see tablecreatedesc).
        When creating a new table, detailed data manager information can be
        given using the texttt{dminfo} argument. This is a record as
        returned by the getdminfo
        function.
        
        Most of the arguments are rarely used: most of the time, you'll
        just need to use the tablename, and perhaps nomodify.
        
        A table can be shared by multiple processes by using the appropriate
        locking options. The possible options are:
        - auto: let the system take care of locking. At regular time
        intervals these autolocks are released to give other processes the
        opportunity to access the table. The aipsrc variable
        texttt{table.relinquish.reqautolocks.interval} defines the number
        of seconds between releasing autolocks on tables needed in another process.
        texttt{table.relinquish.allautolocks.interval} defines the number
        of seconds between releasing all autolocks.
        - autonoread: as auto, but no read locking is needed. This must be
        used with care, because it means that reading can be done while
        the table tool is not synchronized with the table file (as is
        normally done when a lock is acquired). The function texttt{resync}
        can be used to explicitly synchronize the table tool
        - user: the user takes care by explicit calls to lock and unlock
        - usernoread: as user and the no readlocking behaviour of autonoread.
        - permanent: use a permanent lock; the constructor fails when the table is
        already in use in another process
        - permanentwait: as above, but wait until the other process
        releases its lock
        - default: this is the default option.
        If the given table is already open, the locking option in use is not
        changed. Otherwise it reverts to auto.
        When auto locking is used, it is possible to give a record containing
        the fields option, interval, and/or maxwait. In this way advanced
        users have full control over the locking options. In practice this is
        hardly ever needed.
        
        When creating a new table, the endian format in which the
        data should be stored, can be specified. The possible values are:
        - big: big endian format (as used on e.g. SUN)
        - little: little endian format (as used on e.g. PC)
        - local: use the endian format of the machine being used
        - aipsrc: use the endian format specified in aipsrc variable
        table.endianformat (which defaults to big).
        The default is aipsrc.
        Note that usually it is best to store data in local endian format,
        because that requires the least amount of byte swapping. However,
        if the table must be accessible with AIPS++ version 1.7 or before,
        big endian should be used.
        
        When creating a new table, the table will normally reside on disk. It
        is, however, possible to specify that the table should be held in
        memory. In such a case the table is process specific, thus cannot be
        seen by other processes. Note that a memory table uses the MemoryStMan
        storage manager for all its stored columns, but it is still possible
        to use virtual columns as well.
        """
        self._swigobj = kwargs.get('swig_object',None)
        if self._swigobj is None:
            self._swigobj = _table()

    def fromfits(self, tablename, fitsfile, whichhdu=int(1), storage='standard', convention='none', nomodify=True, ack=True):
        """Create a table from binary FITS format. This generates a CASA table
        from the binary FITS table in the given HDU (header unit) of the
        FITS file. Note that other FITS formats ({em e.g.}
        Image FITS and UVFITS) are read by other means.
        It is possible to specify the storage manager to use for the table:
        texttt{standard} is the default storage manager.
        texttt{incremental} is efficient for slowly varying data.
        texttt{memort} is for in memory use for e.g to grab given columns via getcol.
        """
        schema = {'tablename': {'type': 'cStr'}, 'fitsfile': {'type': 'cStr'}, 'whichhdu': {'type': 'cInt'}, 'storage': {'type': 'cStr'}, 'convention': {'type': 'cStr'}, 'nomodify': {'type': 'cBool'}, 'ack': {'type': 'cBool'}}
        doc = {'tablename': tablename, 'fitsfile': fitsfile, 'whichhdu': whichhdu, 'storage': storage, 'convention': convention, 'nomodify': nomodify, 'ack': ack}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromfits_result = _wrap_table(swig_object=self._swigobj.fromfits(_str_ec(_pc.document['tablename']), _str_ec(_pc.document['fitsfile']), _pc.document['whichhdu'], _str_ec(_pc.document['storage']), _str_ec(_pc.document['convention']), _pc.document['nomodify'], _pc.document['ack']))
        return _fromfits_result

    def fromascii(self, tablename, asciifile, headerfile='', autoheader=False, autoshape=[ int(-1) ], sep='', commentmarker='', firstline=int(0), lastline=int(-1), nomodify=True, columnnames=[  ], datatypes=[  ]):
        """Create a table from an ASCII file. Columnar data as well as
        table and column keywords may be specified.
        Once the table is created from the ASCII data, it is opened in the
        specified mode by the table tool.
        
        The table columns are filled from a file containing the data values
        separated by a separator (one line per table row). The default
        separator is a blank. Blanks after the separator are ignored.
        If a non-blank separator is used, values can be empty. Such values
        default to 0, empty string, or F depending on the data type. E.g.
        1,,2, has 4 values of which the 2nd and 4th are empty and default to 0.
        Similarly if fewer values are given than needed, the missing values
        get the default value.
        
        Either the data format can be explicitly specified or it can be found
        automatically. The former gives more control in ambiguous situations.
        Both scalar and array columns can be generated from the ASCII input.
        The format string determines the type and optional shape.
        
        In automatic mode (texttt{autoheader=True}) the first line
        of the ASCII data is analyzed
        to deduce the data types. Only the types I, D, and A can be
        recognized. A number without decimal point or exponent is I (integer),
        otherwise it is D (double). Any other string is A (string).
        Note that a number may contain a leading sign (+ or -).
        The texttt{autoshape} argument can be used to specify if the input
        should be stored as multiple scalars (the default) or as a single
        array. In the latter case one axis in the shape can be defined as
        variable length by giving it the value 0. It means that the actual
        array shape in a row is determined by the number of values in the
        corresponding input line.
        Columns get the names texttt{Column1}, texttt{Column2}, etc..
        For example:
        begin{enumerate}
        item
        texttt{autoshape=[]} (which is the default) means that all values
        are to be stored as scalar columns.
        item
        texttt{autoshape=0} means that all values in a row are to be stored as
        a variable length vector.
        item
        texttt{autoshape=10} defines a fixed length vector. If an input
        line contains less than 10 values, the vector is filled with default
        values. If more than 10 values, the latter values are ignored.
        item
        texttt{autoshape=[5,0]} defines a 2-dim array of which the 2nd axis is
        variable. Note that if an input line does not contain a multiple of 5
        values, the array is filled with default values.
        end{enumerate}
        
        If the format of the table is explicitly specified, it has to be done
        either in the first two lines of the data file (named by the
        argument filename), or in a separate header file (named by the
        argument headerfile). In both forms, table keywords may also be
        specified before the column definitions.
        The column names and types can be described by two lines:
        
        begin{enumerate}
        item The first line contains the names of the columns.
        These names may be enclosed in quotes (either single or double).
        item The second line contains the data type and optionally the shape
        of each column. Valid types are:
        begin{itemize}
        item S for Short data
        item I for Integer data
        item R for Real data
        item D for Double Precision data
        item X for Complex data (Real followed by Imaginary)
        item Z for Complex data (Amplitude then Phase)
        item DX for Double Precision Complex data (Real followed by Imaginary)
        item DZ for Double Precision Complex data (Amplitude then Phase)
        item A for ASCII data (a value must be enclosed in single or double quotes
        if it contains whitespace)
        item B for Boolean data (False are empty string, 0, or any string
        starting with F, f, N, or n).
        end{itemize}
        end{enumerate}
        If a column is an array, the shape has to be given after the data type
        without any whitespace. E.g. texttt{I10} defines an integer vector
        of length 10. texttt{A2,5} defines a 2-dim string array with shape
        [2,5]. Note that texttt{I} is not the same as texttt{I1} as the
        first one defines a scalar and the other one a vector with length 1.
        The last column can have one variable length axis denoted by the value
        0. It "consumes" the remainder of the input line.
        
        If the argument headerfile is set then the header information is
        read from that file instead of the first lines of the data file.
        
        To give a simple example of the form where the header information
        is located at the top of the data file:
        
        begin{verbatim}
        COLI   COLF   COLD       COLX        COLZ       COLS
        I      R      D          X           Z          A
        1      1.1    1.11       1.12 1.13   1.14 1.15  Str1
        10     11     12         13   14     15   16    ""
        end{verbatim}
        Note that a complex number consists of 2 numbers.
        Also note that an empty string can be given.
        
        Let us now give an example of a separate header file that one might use to get
        interferometer data into casa:
        
        begin{verbatim}
        U     V      W         TIME        ANT1       ANT2      DATA
        R     R      R          D           I          I        X1,0
        end{verbatim}
        
        The data file would then look like:
        
        begin{verbatim}
        124.011 54560.0  3477.1  43456789.0990    1      2        4.327 -0.1132
        34561.0 45629.3  3900.5  43456789.0990    1      3        5.398 0.4521
        end{verbatim}
        Note that the DATA column is defined as a 2-dim array of 1
        correlation and a variable number of channels, so the actual number of
        channels is determined by the input. In this example both rows will
        have 1 channel (note that a complex value contains 2 values).
        
        Tables may have keywords in addition to the columns. The keywords
        are useful for holding information that is global to the entire
        table (such as author, revision, history, {em etc,}).
        The keywords in the header definitions must preceed the column descriptions.
        They must be enclosed between a line that starts with ".key..." and
        a line that starts with ".endkey..." (where ... can be anything).
        Between these two lines each
        line should contain the following as listed below.
        A table keywordset and column keywordsets can be specified.
        The latter can be specified by specifying the column name after the
        .keywords string.
        
        begin{itemize}
        item The keyword name, e.g., ANYKEY
        item The datatype and optional  shape of the keyword
        (cf. list of valid types above)
        item The value or values for the keyword (the keyword may contain
        a scalar or an array of values). e.g., 3.14159 21.78945
        end{itemize}
        
        Thus to continue the example above, one might wish to add keywords
        as follows:
        
        begin{verbatim}
        .keywords
        DATE        A  "97/1/16"
        REVISION    D 2.01
        AUTHOR      A "Tim Cornwell"
        INSTRUMENT  A "VLA"
        .endkeywords
        .keywords TIME
        UNIT A "s"
        .endkeywords
        U     V      W         TIME        ANT1       ANT2      DATA
        R     R      R          D           I          I        X1,0
        end{verbatim}
        Similarly to the column format string, the keyword formats can also
        contain shape information. The only difference is that if no shape is
        given, a keyword can have multiple values (making it a vector).
        
        It is possible to ignore comment lines in the header and data file
        by giving the texttt{commentmarker}. It indicates that lines
        starting with the given marker are ignored. Note that the marker can
        be a regular expression (e.g. texttt{' *//'} tells that lines starting
        with // and optionally preceeded by blanks have to be ignored).
        
        With the arguments texttt{firstline} and texttt{lastline} one can
        specify which lines have to be taken from the input file. A negative value
        means 1 for texttt{firstline} or end-of-file for texttt{lastline}.
        Note that if the headers and data are combined in one file,
        these line arguments apply to the whole file. If headers and data are in
        separate files, these line arguments apply to the data file only.
        
        Also note that ignored comment lines are counted, thus are used to
        determine which lines are in the line range.
        
        The number of rows is determined by the number of lines read from the data
        file.
        """
        schema = {'tablename': {'type': 'cStr'}, 'asciifile': {'type': 'cStr'}, 'headerfile': {'type': 'cStr'}, 'autoheader': {'type': 'cBool'}, 'autoshape': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'sep': {'type': 'cStr'}, 'commentmarker': {'type': 'cStr'}, 'firstline': {'type': 'cInt'}, 'lastline': {'type': 'cInt'}, 'nomodify': {'type': 'cBool'}, 'columnnames': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}, 'datatypes': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}}
        doc = {'tablename': tablename, 'asciifile': asciifile, 'headerfile': headerfile, 'autoheader': autoheader, 'autoshape': autoshape, 'sep': sep, 'commentmarker': commentmarker, 'firstline': firstline, 'lastline': lastline, 'nomodify': nomodify, 'columnnames': columnnames, 'datatypes': datatypes}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromascii_result = self._swigobj.fromascii(_str_ec(_pc.document['tablename']), _str_ec(_pc.document['asciifile']), _str_ec(_pc.document['headerfile']), _pc.document['autoheader'], _pc.document['autoshape'], _str_ec(_pc.document['sep']), _str_ec(_pc.document['commentmarker']), _pc.document['firstline'], _pc.document['lastline'], _pc.document['nomodify'], [_str_ec(_x) for _x in _pc.document['columnnames']], [_str_ec(_x) for _x in _pc.document['datatypes']])
        return _fromascii_result

    def open(self, tablename='', lockoptions={ }, nomodify=True):
        """Opens a disk file containing an existing casa Table.
        
        Most of the time you just need to specify the tablename and perhaps
        nomodify.
        
        A table can be shared by multiple processes by using the appropriate
        locking options. The possible options are:
        - auto: let the system take care of locking. At regular time
        intervals these autolocks are released to give other processes the
        opportunity to access the table.
        - autonoread: as auto, but no read locking is needed. This must be
        used with care, because it means that reading can be done while
        the table tool is not synchronized with the table file (as is
        normally done when a lock is acquired). The function texttt{resync}
        can be used to explicitly synchronize the table tool
        - user: the user takes care by explicit calls to lock and unlock
        - usernoread: as user and the no readlocking behaviour of autonoread.
        - permanent: use a permanent lock; the constructor fails when the table is
        already in use in another process
        - permanentwait: as above, but wait until the other process
        releases its lock
        - default: this is the default option.
        If the given table is already open, the locking option in use is not
        changed. Otherwise it reverts to auto.
        When auto locking is used, it is possible to give a record containing
        the fields option, interval, and/or maxwait. In this way advanced
        users have full control over the locking options. In practice this is
        hardly ever needed.
        """
        schema = {'tablename': {'type': 'cReqPath', 'coerce': _coerce.expand_path}, 'lockoptions': {'type': 'cDict'}, 'nomodify': {'type': 'cBool'}}
        doc = {'tablename': tablename, 'lockoptions': lockoptions, 'nomodify': nomodify}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _open_result = self._swigobj.open(_str_ec(_pc.document['tablename']), _dict_ec(_pc.document['lockoptions']), _pc.document['nomodify'])
        return _open_result

    def create(self, tablename='', tabledesc={ }, lockoptions={ }, endianformat='', memtype='', nrow=int(0), dminfo={ }):
        """Create a new casa Table.
        
        Most of the time you just need to specify the table's name and a description of
        its format.
        
        A table can be shared by multiple processes by using the appropriate
        locking options. The possible options are:
        - auto: let the system take care of locking. At regular time
        intervals these autolocks are released to give other processes the
        opportunity to access the table.
        - autonoread: as auto, but no read locking is needed. This must be
        used with care, because it means that reading can be done while
        the table tool is not synchronized with the table file (as is
        normally done when a lock is acquired). The function texttt{resync}
        can be used to explicitly synchronize the table tool
        - user: the user takes care by explicit calls to lock and unlock
        - usernoread: as user and the no readlocking behaviour of autonoread.
        - permanent: use a permanent lock; the constructor fails when the table is
        already in use in another process
        - permanentwait: as above, but wait until the other process
        releases its lock
        - default: this is the default option.
        If the given table is already open, the locking option in use is not
        changed. Otherwise it reverts to auto.
        When auto locking is used, it is possible to give a record containing
        the fields option, interval, and/or maxwait. In this way advanced
        users have full control over the locking options. In practice this is
        hardly ever needed.
        """
        schema = {'tablename': {'type': 'cStr'}, 'tabledesc': {'type': 'cDict'}, 'lockoptions': {'type': 'cDict'}, 'endianformat': {'type': 'cStr'}, 'memtype': {'type': 'cStr'}, 'nrow': {'type': 'cInt'}, 'dminfo': {'type': 'cDict'}}
        doc = {'tablename': tablename, 'tabledesc': tabledesc, 'lockoptions': lockoptions, 'endianformat': endianformat, 'memtype': memtype, 'nrow': nrow, 'dminfo': dminfo}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _create_result = self._swigobj.create(_str_ec(_pc.document['tablename']), _dict_ec(_pc.document['tabledesc']), _dict_ec(_pc.document['lockoptions']), _str_ec(_pc.document['endianformat']), _str_ec(_pc.document['memtype']), _pc.document['nrow'], _dict_ec(_pc.document['dminfo']))
        return _create_result

    def flush(self):
        """Until a flush is performed, the results of all operations
        are not reflected in any change to the
        disk file. Hence you {em must} do a flush to write the changes
        to disk.
        """
        _flush_result = self._swigobj.flush()
        return _flush_result

    def fromASDM(self, tablename, xmlfile):
        """.keywords
        DATE        A  "07/7/23"
        REVISION    D 0
        AUTHOR      A "Paulo C. Cortes"
        INSTRUMENT  A "ALMA"
        .endkeywords
        
        The main function for this task is to create a CASA::Table from a XML  ASDM Table. The classes asdmCasaXMLUtil and asdmCasaSaxHandler are the main objects which
        implement the task. The asdmCasaSaxHandler encapsulate all the operations
        returning a reference to a CASA::Table. The class uses xerces-c to parse the
        XML table and creates the CASA::Table. The implementation assumes the integrity
        of the XML data, it not attempting to check whether the XML  data meets a
        column format or not. In detail, an ArrayString column should agree with
        the following format: nd nx ... data, where nd is the number of dimensions,
        nx is the size of the first dimension (implemented upto a cube, i.e. nx,ny,nz),
        and data is the array itself which should have the appropiate number of
        elements. For example, a VectorString column could be: 1 2 "I" "Q" or
        dimension 1, size 2, and two string elements. Due to the lack of data type
        spefication in the XML tables, the column names are hardcoded into the
        asdmCasaSaxHandler based on the ASDM specification (see
        http://aramis.obspm.fr/~alma/ASDM/ASDMEntities/index.html).
        While missing data from a table column will be accepted by the task,
        any new column beyond the specification has to be added into the class, also,
        any change in data types form the specificatin will produce a crash, CASA
        is picky with data types integrity. So far, the list of tables included in
        the class is:
        
        AlmaCorrelatorMode.xml,
        Antenna.xml
        ConfigDescription.xml,
        DataDescription.xml,
        ExecBlock.xml,
        Feed.xml,
        Field.xml,
        Main.xml,
        Polarization.xml,
        Processor.xml,
        Receiver.xml,
        SBSummary.xml,
        Scan.xml,
        Source.xml,
        SpectralWindow.xml,
        State.xml,
        Station.xml,
        Subscan.xml,
        SwitchCycle.xml,
        CalCurve.xml,
        CalData.xml,
        CalPhase.xml
        
        more tables will follow. The usage of fromASDM is simple, it gets two
        string, tablename and xmlfile, where tablename is the CASA::Table to be
        written and xmlfile represents the ASDM XML table. To call it do:
        tb.fromasdm(tablename,xmlfile)
        """
        schema = {'tablename': {'type': 'cStr'}, 'xmlfile': {'type': 'cStr'}}
        doc = {'tablename': tablename, 'xmlfile': xmlfile}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fromASDM_result = self._swigobj.fromASDM(_str_ec(_pc.document['tablename']), _str_ec(_pc.document['xmlfile']))
        return _fromASDM_result

    def resync(self):
        """Acquiring a read or write lock automatically synchronizes the internals
        of the table tool with the actual contents of the table files.
        In this way different processes accessing the same table always
        use the same table data.
        However, a table can be used without read locking. In that case
        the table tool internals are not synchronized automatically.
        The resync function offers a way to do explicit synchronization.
        It is only useful if the table is opened with locking mode
        texttt{autonoread} or texttt{usernoread}.
        """
        _resync_result = self._swigobj.resync()
        return _resync_result

    def close(self):
        """First a flush is done, then the table is closed inside casapy and
        is no longer available for use.
        """
        _close_result = self._swigobj.close()
        return _close_result

    def copy(self, newtablename, deep=False, valuecopy=False, dminfo={ }, endian='aipsrc', memorytable=False, returnobject=False, norows=False):
        """Copy the table. All subtables are also copied.
        References to another table are preserved.
        
        The argument texttt{deep} determines how a reference table (i.e. the
        result of a query) is copied. By default
        a file copy is made, thus the resulting table still contains
        references and no actual data. If, however, texttt{deep=True} is given,
        a deep copy is made which means that the actual data are copied. Also
        all subtables are copied.
        Normally a plain table is copied by copying the files. However,
        if texttt{deep=True} and texttt{valuecopy=True} are given, a plain table is
        copied by copying all its values and subtables. This is useful to
        reorganize the tables, i.e. to regain file space that is wasted by
        frequent updates to a table.
        The argument texttt{dminfo} can be used to specify explicit data
        manager info for the columns in the new plain table. It can be used to
        change, for example, a storage manager from IncrStMan to StandardStMan.
        The texttt{dminfo} is a record as returned by the
        getdminfo
        If texttt{dminfo} is a non-empty record, it forces texttt{valuecopy=True}.
        
        The standard operation is make the copy to a plain table. It is,
        however, possible to copy to a memory table by giving texttt{memorytable=True}.
        
        The endian format for the newly created table can be specified. This
        is only meaningful if a deep copy is made to a plain table.
        The possible values are:
        - big: big endian format (as used on e.g. SUN)
        - little: little endian format (as used on e.g. PC)
        - local: use the endian format of the machine being used
        - aipsrc: use the endian format specified in aipsrc variable
        table.endianformat (which defaults to big).
        The default is aipsrc.
        
        Normally the texttt{copy} function only copies the table and does not
        create a new table tool object. The user can do that by opening the newly
        created table in the standard way. However, it is possible to get an
        object back by using texttt{returnobject=True}. An object is always
        returned if the copy is made to a memory table.
        """
        schema = {'newtablename': {'type': 'cStr'}, 'deep': {'type': 'cBool'}, 'valuecopy': {'type': 'cBool'}, 'dminfo': {'type': 'cDict'}, 'endian': {'type': 'cStr'}, 'memorytable': {'type': 'cBool'}, 'returnobject': {'type': 'cBool'}, 'norows': {'type': 'cBool'}}
        doc = {'newtablename': newtablename, 'deep': deep, 'valuecopy': valuecopy, 'dminfo': dminfo, 'endian': endian, 'memorytable': memorytable, 'returnobject': returnobject, 'norows': norows}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _copy_result = _wrap_table(swig_object=self._swigobj.copy(_str_ec(_pc.document['newtablename']), _pc.document['deep'], _pc.document['valuecopy'], _dict_ec(_pc.document['dminfo']), _str_ec(_pc.document['endian']), _pc.document['memorytable'], _pc.document['returnobject'], _pc.document['norows']))
        return _copy_result

    def copyrows(self, outtable, startrowin=int(0), startrowout=int(-1), nrow=int(-1)):
        """Copy rows from this table to another. By default all rows of this
        table are appended to the output table. It is possible though to
        control which rows are copied.
        Rows are added to the output table as needed.
        Because no rows can be added to a reference table, it is only possible
        to overwrite existing rows in such tables.
        
        Only the data of columns existing in both tables will be copied.
        Thus by making a reference table consisting of a few columns, it
        is possible to copy those columns only.
        """
        schema = {'outtable': {'type': 'cStr'}, 'startrowin': {'type': 'cInt'}, 'startrowout': {'type': 'cInt'}, 'nrow': {'type': 'cInt'}}
        doc = {'outtable': outtable, 'startrowin': startrowin, 'startrowout': startrowout, 'nrow': nrow}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _copyrows_result = self._swigobj.copyrows(_str_ec(_pc.document['outtable']), _pc.document['startrowin'], _pc.document['startrowout'], _pc.document['nrow'])
        return _copyrows_result

    def done(self):
        """Effectively a synonym for function close.
        """
        _done_result = self._swigobj.done()
        return _done_result

    def iswritable(self):
        """Test if the table is opened for write.
        """
        _iswritable_result = self._swigobj.iswritable()
        return _iswritable_result

    def endianformat(self):
        """Get the endian format used for this table.
        It returns a string with value 'big' or 'little'.
        """
        _endianformat_result = _str_dc(self._swigobj.endianformat())
        return _endianformat_result

    def lock(self, write=True, nattempts=int(0)):
        """Try to acquire a read or write lock on the table. Nothing will be
        done if the table is already correctly locked by this process.
        It is only needed when user locking is used.
        When the lock is acquired, the internal caches will be synchronized
        with the (possibly changed) contents of the table.
        It is possible to specify the number of attempts to do (1 per
        second) in case the table is locked by another process. The default 0
        is trying indefinitely.
        """
        schema = {'write': {'type': 'cBool'}, 'nattempts': {'type': 'cInt'}}
        doc = {'write': write, 'nattempts': nattempts}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _lock_result = self._swigobj.lock(_pc.document['write'], _pc.document['nattempts'])
        return _lock_result

    def unlock(self):
        """The table is flushed and the lock on the table is released.
        This function is only needed when user locking is used.
        However, it is also possible to use it with auto locking. In that case
        the lock will automatically be re-acquired before the next table operation.
        """
        _unlock_result = self._swigobj.unlock()
        return _unlock_result

    def datachanged(self):
        """This function tests if data in the table have changed (by another
        process) since the last call to this function.
        """
        _datachanged_result = self._swigobj.datachanged()
        return _datachanged_result

    def haslock(self, write=True):
        """Has this process a read or write lock on the table?
        """
        schema = {'write': {'type': 'cBool'}}
        doc = {'write': write}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _haslock_result = self._swigobj.haslock(_pc.document['write'])
        return _haslock_result

    def lockoptions(self):
        """Get the lock options used for this table.
        It returns a record with the fields: option, interval and maxwait.
        The record can be used as the lockoptions argument when opening a table.
        """
        _lockoptions_result = _dict_dc(self._swigobj.lockoptions())
        return _lockoptions_result

    def ismultiused(self, checksubtables=False):
        """Is the table still in use in another process?
        If so, the table cannot be deleted.
        """
        schema = {'checksubtables': {'type': 'cBool'}}
        doc = {'checksubtables': checksubtables}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _ismultiused_result = self._swigobj.ismultiused(_pc.document['checksubtables'])
        return _ismultiused_result

    def browse(self):
        """To start the browser, the environment variable
        DISPLAY must be set.
        """
        _browse_result = self._swigobj.browse()
        return _browse_result

    def name(self):
        """Gives the name of the casa table on disk that the
        table tool has open.
        """
        _name_result = _str_dc(self._swigobj.name())
        return _name_result

    def createmultitable(self, outputTableName, tables, subdirname):
        """
        """
        schema = {'outputTableName': {'type': 'cStr'}, 'tables': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}, 'subdirname': {'type': 'cStr'}}
        doc = {'outputTableName': outputTableName, 'tables': tables, 'subdirname': subdirname}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _createmultitable_result = self._swigobj.createmultitable(_str_ec(_pc.document['outputTableName']), [_str_ec(_x) for _x in _pc.document['tables']], _str_ec(_pc.document['subdirname']))
        return _createmultitable_result

    def toasciifmt(self, asciifile, headerfile='', columns=[  ], sep=''):
        """Write a table into an ASCII format approximately compatible with fromascii except that in order to permit variable shaped arrays (as they often occur in MSs), array values are output enclosed in square brackets.
        The separator between values can be specified and defaults to a blank. Note that columns containing
        invalid data or record type data are ignored and a warning is issued.
        
        If the argument headerfile is set then the header information is
        written to that file instead of the first two lines of the data file.
        """
        schema = {'asciifile': {'type': 'cStr'}, 'headerfile': {'type': 'cStr'}, 'columns': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}, 'sep': {'type': 'cStr'}}
        doc = {'asciifile': asciifile, 'headerfile': headerfile, 'columns': columns, 'sep': sep}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _toasciifmt_result = self._swigobj.toasciifmt(_str_ec(_pc.document['asciifile']), _str_ec(_pc.document['headerfile']), [_str_ec(_x) for _x in _pc.document['columns']], _str_ec(_pc.document['sep']))
        return _toasciifmt_result

    def taql(self, taqlcommand='TaQL expression'):
        """This method Expose TaQL to the user.
        Details on TaQL maybe found at http://www.astron.nl/aips++/docs/notes/199
        """
        schema = {'taqlcommand': {'type': 'cStr'}}
        doc = {'taqlcommand': taqlcommand}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _taql_result = _wrap_table(swig_object=self._swigobj.taql(_str_ec(_pc.document['taqlcommand'])))
        return _taql_result

    def query(self, query='String', name='', sortlist='', columns='', style=''):
        """Make a table from a query applied to the current table.  It is possible to
        specify column(s) and/or expressions to sort on and to specify the
        columns to be contained in the output table.  See the example below.
        A new "on-the-fly" table tool is returned. The new (reference) table
        can be given a name and will then be written to disk. Note that the
        resulting table is just a reference to the original table.  One can
        make a deep copy of the query result using the copy function (see example).
        """
        schema = {'query': {'type': 'cStr'}, 'name': {'type': 'cStr'}, 'sortlist': {'type': 'cStr'}, 'columns': {'type': 'cStr'}, 'style': {'type': 'cStr'}}
        doc = {'query': query, 'name': name, 'sortlist': sortlist, 'columns': columns, 'style': style}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _query_result = _wrap_table(swig_object=self._swigobj.query(_str_ec(_pc.document['query']), _str_ec(_pc.document['name']), _str_ec(_pc.document['sortlist']), _str_ec(_pc.document['columns']), _str_ec(_pc.document['style'])))
        return _query_result

    def calc(self, expr, prefix='using style base0, endincl, fortranorder', showtaql=False):
        """Get the result from the calculation of an expression on a table
        
        The expression can be any expression that can be given in the WHERE
        clause of a SELECT expression (thus including subqueries).
        The given expression determines if the result is a scalar, a vector,
        or a record containing arrays. See the examples below.
        """
        schema = {'expr': {'type': 'cStr'}, 'prefix': {'type': 'cStr'}, 'showtaql': {'type': 'cBool'}}
        doc = {'expr': expr, 'prefix': prefix, 'showtaql': showtaql}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _calc_result = _any_dc(self._swigobj.calc(_str_ec(_pc.document['expr']), _str_ec(_pc.document['prefix']), _pc.document['showtaql']))
        return _calc_result

    def selectrows(self, rownrs, name=''):
        """Create a (reference) table containing a given subset of rows.
        It is, for instance, useful when a selection is done
        on another table containing the row numbers in the main table.
        It can be useful to apply the casapy function unique to those
        row numbers, otherwise the same row might be included multiple
        times (see example).
        
        
        
        It is possible to give a name to the resulting table. If given,
        the resulting table is made persistent with that table name.
        Otherwise the table is transient and disappears when closed or when
        casapy exits.
        
        The rownumbers function returns a
        vector containing the row number in the main table for each row in the
        selection table.
        Thus given a row number vector texttt{rownrs}, the following is
        always true.
        begin{verbatim}
        rownrs == tb.selectrows(rownrs).rownumbers()
        end{verbatim}
        However, it is not true when selectrows is used on a selection table.
        because texttt{rownumbers} does not return the row number in that
        selection table but in the main table.
        It means that one has to take great care when using
        texttt{selectrows} on a selection table.
        """
        schema = {'rownrs': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'name': {'type': 'cStr'}}
        doc = {'rownrs': rownrs, 'name': name}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _selectrows_result = _wrap_table(swig_object=self._swigobj.selectrows(_pc.document['rownrs'], _str_ec(_pc.document['name'])))
        return _selectrows_result

    def info(self):
        """The info record contains information on the table.
        """
        _info_result = _dict_dc(self._swigobj.info())
        return _info_result

    def putinfo(self, value):
        """The info record contains information on the table. It is
        written by applications, and used  to determine what type of
        information is stored in a table.
        """
        schema = {'value': {'type': 'cDict'}}
        doc = {'value': value}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putinfo_result = self._swigobj.putinfo(_dict_ec(_pc.document['value']))
        return _putinfo_result

    def addreadmeline(self, value):
        """A readme line is part of the info record associated with a table.
        It is to inform the user, and is not used by any application directly.
        """
        schema = {'value': {'type': 'cStr'}}
        doc = {'value': value}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _addreadmeline_result = self._swigobj.addreadmeline(_str_ec(_pc.document['value']))
        return _addreadmeline_result

    def summary(self, recurse=False):
        """A (terse) summary of the table contents is sent to the defaultlogger.
        """
        schema = {'recurse': {'type': 'cBool'}}
        doc = {'recurse': recurse}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _summary_result = self._swigobj.summary(_pc.document['recurse'])
        return _summary_result

    def colnames(self):
        """The names of the columns in the table are returned as a vector
        of Strings.
        """
        _colnames_result = [_str_dc(_x) for _x in self._swigobj.colnames()]
        return _colnames_result

    def rownumbers(self, tab={ }, nbytes=int(0)):
        """!!!NOTE INPUT PARAMETERS IGNORED!!!
        
        This function can be useful after a selection or a sort.
        It returns the row numbers of the rows in this table with respect
        to the given table. If no table is given, the original table is used.
        For example:
        begin {verbatim}
        !!!NOTE INPUT PARAMETERS IGNORED!!!
        
        tb.open('3C273XC1.MS')
        t1=tb.selectrows([1,3,5,7,9])
        t1.rownumbers()
        # [1L, 3L, 5L, 7L, 9L]
        t2=t1.selectrows([2,4])
        t2.rownumbers(t1)
        # [2L, 4L]
        t2.rownumbers(tb.name())
        # [5L, 9L]
        t2.rownumbers()
        # [5L, 9L]
        end{verbatim}
        The last statements show that the function returns the row numbers
        referring to the given table. Table t2 contains rows 2 and 4 in table t1,
        which are rows 5 and 9 in table '3C273XC1.MS'.
        
        Note that when a table is opened using its name, that table can
        be a reference table. Thus in the example above
        the last 2 statements may give different results depending on the fact
        if 3C273XC1.MS is a reference table or not.
        The function should always be called with a table argument.
        The ability of omitting the argument is only present for backward
        compatibility.
        
        The function can be useful to get the correct values from the result of a
        getcol or getcolslice on the original table.
        
        !!!NOTE INPUT PARAMETERS IGNORED!!!
        """
        schema = {'tab': {'type': 'cDict'}, 'nbytes': {'type': 'cInt'}}
        doc = {'tab': tab, 'nbytes': nbytes}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _rownumbers_result = self._swigobj.rownumbers(_dict_ec(_pc.document['tab']), _pc.document['nbytes'])
        return _rownumbers_result

    def setmaxcachesize(self, columnname, nbytes):
        """It can sometimes be useful to limit the size of the cache used by
        a column stored with the tiled storage manager.
        This function requires some more knowledge about the table system
        and is not meant for the casual user.
        """
        schema = {'columnname': {'type': 'cStr'}, 'nbytes': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'nbytes': nbytes}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setmaxcachesize_result = self._swigobj.setmaxcachesize(_str_ec(_pc.document['columnname']), _pc.document['nbytes'])
        return _setmaxcachesize_result

    def isscalarcol(self, columnname):
        """A column may contain either scalars or arrays in each cell.
        This tool function tests if the specified column has scalar contents.
        """
        schema = {'columnname': {'type': 'cStr'}}
        doc = {'columnname': columnname}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _isscalarcol_result = self._swigobj.isscalarcol(_str_ec(_pc.document['columnname']))
        return _isscalarcol_result

    def isvarcol(self, columnname):
        """This functions tells if the column contains variable shaped arrays.
        If so, the function texttt{getvarcol} should be used to get the
        entire column. Otherwise texttt{getcol} can be used.
        """
        schema = {'columnname': {'type': 'cStr'}}
        doc = {'columnname': columnname}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _isvarcol_result = self._swigobj.isvarcol(_str_ec(_pc.document['columnname']))
        return _isvarcol_result

    def coldatatype(self, columnname):
        """A column may contain various data types. This tool function returns the
        type of the column as a string.
        """
        schema = {'columnname': {'type': 'cStr'}}
        doc = {'columnname': columnname}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _coldatatype_result = _str_dc(self._swigobj.coldatatype(_str_ec(_pc.document['columnname'])))
        return _coldatatype_result

    def colarraytype(self, columnname):
        """The possible column array types are defined as:
        begin{description}
        item[FixedShape]  FixedShape means that the shape of the array must be the
        same in each cell of the column. If not given, the array
        shape may vary. Option Direct forces FixedShape.
        item[Direct] Direct means that the data is directly stored in the
        table. Direct forces option FixedShape. If not given, the array is
        indirect, which implies that the data will be stored in a
        separate file.
        end{description}
        """
        schema = {'columnname': {'type': 'cStr'}}
        doc = {'columnname': columnname}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _colarraytype_result = _str_dc(self._swigobj.colarraytype(_str_ec(_pc.document['columnname'])))
        return _colarraytype_result

    def ncols(self):
        """
        """
        _ncols_result = self._swigobj.ncols()
        return _ncols_result

    def nrows(self):
        """Note that rows are numbered starting at 0.
        """
        _nrows_result = self._swigobj.nrows()
        return _nrows_result

    def addrows(self, nrow=int(1)):
        """Rows can be added to the end of a table that was opened nomodify=False.
        The new rows are empty.
        """
        schema = {'nrow': {'type': 'cInt'}}
        doc = {'nrow': nrow}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _addrows_result = self._swigobj.addrows(_pc.document['nrow'])
        return _addrows_result

    def removerows(self, rownrs):
        """Remove the row numbers specified in the vector from the table.
        It fails when the table does not support row removal.
        """
        schema = {'rownrs': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'rownrs': rownrs}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _removerows_result = self._swigobj.removerows(_pc.document['rownrs'])
        return _removerows_result

    def addcols(self, desc, dminfo={ }):
        """Columns can be added to a table that was opened nomodify=False.
        The new columns will be filled with a default value (0 or blank).
        
        
        !!!THESE COLUMN DESCRIPTION FUNCTIONS HAVE NOT BEEN IMPLEMENTED!!!
        For each column to be added a column description has to be setup
        using function
        tablecreatescalarcoldesc or
        tablecreatearraycoldesc.
        When multiple columns are used, they have to be combined in a single
        record using
        tablecreatedesc.
        It is possible to specify data manager info in order to define a
        data manager (storage manager or virtual column engine) for the
        columns to be added.
        """
        schema = {'desc': {'type': 'cDict'}, 'dminfo': {'type': 'cDict'}}
        doc = {'desc': desc, 'dminfo': dminfo}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _addcols_result = self._swigobj.addcols(_dict_ec(_pc.document['desc']), _dict_ec(_pc.document['dminfo']))
        return _addcols_result

    def renamecol(self, oldname, newname):
        """A column can be renamed in a table that was opened nomodify=False.
        However, renaming is not possible in a (reference) table resulting
        from a select or sort operation.
        """
        schema = {'oldname': {'type': 'cStr'}, 'newname': {'type': 'cStr'}}
        doc = {'oldname': oldname, 'newname': newname}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _renamecol_result = self._swigobj.renamecol(_str_ec(_pc.document['oldname']), _str_ec(_pc.document['newname']))
        return _renamecol_result

    def removecols(self, columnames):
        """Columns can be removed from a table that was opened nomodify=False.
        It may not always be possible to remove a column, because some data
        managers do not support column removal. However, if all columns of
        a data manager are removed, it will always succeed. It results in the
        removal of the entire data manager (and its possible files).
        Note that function getdminfo
        can be used to find which columns are served by which data manager.
        """
        schema = {'columnames': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}}
        doc = {'columnames': columnames}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _removecols_result = self._swigobj.removecols([_str_ec(_x) for _x in _pc.document['columnames']])
        return _removecols_result

    def iscelldefined(self, columnname, rownr=int(0)):
        """A column containing variable shaped arrays can have an empty cell
        (if no array has been put into it). This function tests if a cell
        is defined (thus is not empty).
        Note that a scalar column and a fixed shape array column cannot have
        empty cells.
        """
        schema = {'columnname': {'type': 'cStr'}, 'rownr': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'rownr': rownr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _iscelldefined_result = self._swigobj.iscelldefined(_str_ec(_pc.document['columnname']), _pc.document['rownr'])
        return _iscelldefined_result

    def getcell(self, columnname, rownr=int(0)):
        """A cell is the value at one row in one column. It may be a scalar
        or an array.
        """
        schema = {'columnname': {'type': 'cStr'}, 'rownr': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'rownr': rownr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getcell_result = _any_dc(self._swigobj.getcell(_str_ec(_pc.document['columnname']), _pc.document['rownr']))
        return _getcell_result

    def getcellslice(self, columnname, rownr, blc, trc, incr=[ int(1) ]):
        """A cell is the value at one row in one column. It must be an array.
        The slice must be specified as blc, trc with an optional stride.
        In blc and trc -1 can be used to indicate all values for a dimension
        (-1 in blc is equivalent to 0, so -1 is especially useful for trc).
        """
        schema = {'columnname': {'type': 'cStr'}, 'rownr': {'type': 'cInt'}, 'blc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'trc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'incr': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'columnname': columnname, 'rownr': rownr, 'blc': blc, 'trc': trc, 'incr': incr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getcellslice_result = _any_dc(self._swigobj.getcellslice(_str_ec(_pc.document['columnname']), _pc.document['rownr'], _pc.document['blc'], _pc.document['trc'], _pc.document['incr']))
        return _getcellslice_result

    def getcol(self, columnname, startrow=int(0), nrow=int(-1), rowincr=int(1)):
        """The entire column (or part of it) is returned. Warning: it might be big!
        The functions can only be used if all arrays in the column have the
        same shape. That is guaranteed for columns containing scalars or fixed
        shaped arrays. For columns containing variable shaped arrays it only
        succeeds if all those arrays happen to have the same shape.
        Note that function texttt{getvarcol} can be used to get a column of
        arbitrary shaped arrays, which also handles empty cells correctly.
        Function texttt{isvarcol} tells if a column contains variable shaped arrays.
        shaped
        """
        schema = {'columnname': {'type': 'cStr'}, 'startrow': {'type': 'cInt'}, 'nrow': {'type': 'cInt'}, 'rowincr': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'startrow': startrow, 'nrow': nrow, 'rowincr': rowincr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getcol_result = _any_dc(self._swigobj.getcol(_str_ec(_pc.document['columnname']), _pc.document['startrow'], _pc.document['nrow'], _pc.document['rowincr']))
        return _getcol_result

    def getvarcol(self, columnname, startrow=int(0), nrow=int(-1), rowincr=int(1)):
        """Function texttt{getcol} can only used if values in the column cells to get
        have the same shape. Function texttt{getvarcol} addresses this limitation by
        returning the values as a record instead of an array. Each field in
        the record contains the value for a column cell. If the value is
        undefined (i.e. the cell does not contain a value), the unset value is
        put in the record. Each field name is the letter r followed by the
        row number. The length of the record is the number of rows to get.
        Note that the function texttt{isvarcol} tells if a column contains
        variable shaped arrays.
        """
        schema = {'columnname': {'type': 'cStr'}, 'startrow': {'type': 'cInt'}, 'nrow': {'type': 'cInt'}, 'rowincr': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'startrow': startrow, 'nrow': nrow, 'rowincr': rowincr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getvarcol_result = _dict_dc(self._swigobj.getvarcol(_str_ec(_pc.document['columnname']), _pc.document['startrow'], _pc.document['nrow'], _pc.document['rowincr']))
        return _getvarcol_result

    def getcolslice(self, columnname, blc, trc, incr, startrow=int(0), nrow=int(-1), rowincr=int(1)):
        """A slice from the entire column (or part of it) is returned.
        Warning: it might be big!
        In blc and trc -1 can be used to indicate all values for a dimension
        (-1 in blc is equivalent to 1, so -1 is especially useful for trc).
        Note that blc and trc should not contain the row number, only the
        blc and trc of the arrays in the column.
        """
        schema = {'columnname': {'type': 'cStr'}, 'blc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'trc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'incr': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'startrow': {'type': 'cInt'}, 'nrow': {'type': 'cInt'}, 'rowincr': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'blc': blc, 'trc': trc, 'incr': incr, 'startrow': startrow, 'nrow': nrow, 'rowincr': rowincr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getcolslice_result = _any_dc(self._swigobj.getcolslice(_str_ec(_pc.document['columnname']), _pc.document['blc'], _pc.document['trc'], _pc.document['incr'], _pc.document['startrow'], _pc.document['nrow'], _pc.document['rowincr']))
        return _getcolslice_result

    def putcell(self, columnname, rownr, thevalue=[ ]):
        """A cell is the the value at one row in one column. It
        may be a scalar or an array.
        """
        schema = {'columnname': {'type': 'cStr'}, 'rownr': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'thevalue': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'columnname': columnname, 'rownr': rownr, 'thevalue': thevalue}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putcell_result = self._swigobj.putcell(_str_ec(_pc.document['columnname']), _pc.document['rownr'], _any_ec(_pc.document['thevalue']))
        return _putcell_result

    def putcellslice(self, columnname, rownr, value=[ ], blc=[ ], trc=[ ], incr=[ int(1) ]):
        """A cell is the value at one row in one column. It must be an array.
        The slice must be specified as blc, trc with an optional stride.
        In blc and trc -1 can be used to indicate all values for a dimension
        (-1 in blc is equivalent to 0, so -1 is especially useful for trc).
        """
        schema = {'columnname': {'type': 'cStr'}, 'rownr': {'type': 'cInt'}, 'value': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'blc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'trc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'incr': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'columnname': columnname, 'rownr': rownr, 'value': value, 'blc': blc, 'trc': trc, 'incr': incr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putcellslice_result = self._swigobj.putcellslice(_str_ec(_pc.document['columnname']), _pc.document['rownr'], _any_ec(_pc.document['value']), _pc.document['blc'], _pc.document['trc'], _pc.document['incr'])
        return _putcellslice_result

    def putcol(self, columnname, value=[ ], startrow=int(0), nrow=int(-1), rowincr=int(1)):
        """
        """
        schema = {'columnname': {'type': 'cStr'}, 'value': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'startrow': {'type': 'cInt'}, 'nrow': {'type': 'cInt'}, 'rowincr': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'value': value, 'startrow': startrow, 'nrow': nrow, 'rowincr': rowincr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putcol_result = self._swigobj.putcol(_str_ec(_pc.document['columnname']), _any_ec(_pc.document['value']), _pc.document['startrow'], _pc.document['nrow'], _pc.document['rowincr'])
        return _putcol_result

    def putvarcol(self, columnname, value, startrow=int(0), nrow=int(-1), rowincr=int(1)):
        """texttt{putcol} can only used if values in the column cells to put
        have the same shape. texttt{putvarcol} addresses this limitation by
        passing the values as a record instead of an array. Each field in
        the record contains the value for a column cell. So the length of the
        record has to match the number of rows to put. If a value is the unset
        value, no put is done for that row.
        """
        schema = {'columnname': {'type': 'cStr'}, 'value': {'type': 'cDict'}, 'startrow': {'type': 'cInt'}, 'nrow': {'type': 'cInt'}, 'rowincr': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'value': value, 'startrow': startrow, 'nrow': nrow, 'rowincr': rowincr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putvarcol_result = self._swigobj.putvarcol(_str_ec(_pc.document['columnname']), _dict_ec(_pc.document['value']), _pc.document['startrow'], _pc.document['nrow'], _pc.document['rowincr'])
        return _putvarcol_result

    def putcolslice(self, columnname, value=[ ], blc=[ ], trc=[ ], incr=[ int(1) ], startrow=int(0), nrow=int(-1), rowincr=int(1)):
        """In blc and trc, -1 can be used to indicate all values for a dimension
        (-1 in blc is equivalent to 0, so -1 is especially useful for trc).
        Note that blc and trc should not contain the row number, only the
        blc and trc of the arrays in the column.
        """
        schema = {'columnname': {'type': 'cStr'}, 'value': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'blc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'trc': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'incr': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'startrow': {'type': 'cInt'}, 'nrow': {'type': 'cInt'}, 'rowincr': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'value': value, 'blc': blc, 'trc': trc, 'incr': incr, 'startrow': startrow, 'nrow': nrow, 'rowincr': rowincr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putcolslice_result = self._swigobj.putcolslice(_str_ec(_pc.document['columnname']), _any_ec(_pc.document['value']), _pc.document['blc'], _pc.document['trc'], _pc.document['incr'], _pc.document['startrow'], _pc.document['nrow'], _pc.document['rowincr'])
        return _putcolslice_result

    def getcolshapestring(self, columnname, startrow=int(0), nrow=int(-1), rowincr=int(1)):
        """The shapes of the arrays in the entire column (or part of it) are
        returned as strings like [20,3]. When the column contains fixed shaped
        arrays, a single string is returned. Otherwise a vector of strings is
        returned.
        """
        schema = {'columnname': {'type': 'cStr'}, 'startrow': {'type': 'cInt'}, 'nrow': {'type': 'cInt'}, 'rowincr': {'type': 'cInt'}}
        doc = {'columnname': columnname, 'startrow': startrow, 'nrow': nrow, 'rowincr': rowincr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getcolshapestring_result = [_str_dc(_x) for _x in self._swigobj.getcolshapestring(_str_ec(_pc.document['columnname']), _pc.document['startrow'], _pc.document['nrow'], _pc.document['rowincr'])]
        return _getcolshapestring_result

    def getkeyword(self, keyword=[ ]):
        """The value of the given table keyword is returned. The value can be of any
        type, including a record and a table.
        If a keyword is a table, its value is returned as a string containing
        the table name prefixed by 'Table: '.
        It is possible that the value of a keyword is a record itself
        (arbitrarily deeply nested). A field in such a subrecord can be
        read by separating the name with dots.
        """
        schema = {'keyword': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'keyword': keyword}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getkeyword_result = _any_dc(self._swigobj.getkeyword(_any_ec(_pc.document['keyword'])))
        return _getkeyword_result

    def getkeywords(self):
        """The values of all table keywords are returned. The values can be of any
        type, including a record and a table.
        If a keyword is a table, its value is returned as a string containing
        the table name prefixed by 'Table: '.
        """
        _getkeywords_result = _dict_dc(self._swigobj.getkeywords())
        return _getkeywords_result

    def getcolkeyword(self, columnname, keyword=[ ]):
        """The value of the given column keyword is returned. The value can be of any
        type, including a record and a table.
        If a keyword is a table, its value is returned as a string containing
        the table name prefixed by 'Table: '.
        It is possible that the value of a keyword is a record itself
        (arbitrarily deeply nested). A field in such a subrecord can be
        read by separating the name with dots.
        """
        schema = {'columnname': {'type': 'cStr'}, 'keyword': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'columnname': columnname, 'keyword': keyword}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getcolkeyword_result = _any_dc(self._swigobj.getcolkeyword(_str_ec(_pc.document['columnname']), _any_ec(_pc.document['keyword'])))
        return _getcolkeyword_result

    def getcolkeywords(self, columnname):
        """The values of all keywords for the given column are returned.
        The values can be of any type, including a record and a table.
        If a keyword is a table, its value is returned as a string containing
        the table name prefixed by 'Table: '.
        """
        schema = {'columnname': {'type': 'cStr'}}
        doc = {'columnname': columnname}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getcolkeywords_result = _any_dc(self._swigobj.getcolkeywords(_str_ec(_pc.document['columnname'])))
        return _getcolkeywords_result

    def putkeyword(self, keyword=[ ], value=[ ], makesubrecord=False):
        """Put a table keyword. The value of the keyword can be a scalar or
        an array of any type or it can be a record.
        It is possible to define a keyword holding a subtable. In that
        case a special string containing the name of the subtable will be
        passed to the table client.
        It is possible that the value of a keyword is a record itself
        (arbitrarily deeply nested). A field in such a subrecord can be
        written by separating the name with dots. If a subrecord does not
        exist, an error is returned unless texttt{makesubrecord=True} is given.
        In such a case intermediate records are created when needed.
        """
        schema = {'keyword': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'value': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'makesubrecord': {'type': 'cBool'}}
        doc = {'keyword': keyword, 'value': value, 'makesubrecord': makesubrecord}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putkeyword_result = self._swigobj.putkeyword(_any_ec(_pc.document['keyword']), _any_ec(_pc.document['value']), _pc.document['makesubrecord'])
        return _putkeyword_result

    def putkeywords(self, value):
        """Put multiple table keywords. All fields in the given record are put
        as table keywords. The value of each field can be a scalar or
        an array of any type or it can be a record.
        It is also possible to define a keyword holding a subtable.
        This can be done by giving the keyword a string value consisting of
        the subtable name prefixed by 'Table: '.
        """
        schema = {'value': {'type': 'cDict'}}
        doc = {'value': value}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putkeywords_result = self._swigobj.putkeywords(_dict_ec(_pc.document['value']))
        return _putkeywords_result

    def putcolkeyword(self, columnname, keyword=[ ], value=[ ]):
        """Put a keyword in the given column.
        The value of the keyword can be a scalar or
        an array of any type or it can be a record.
        It is possible to define a keyword holding a subtable. In that
        case a special string containing the name of the subtable will be
        passed to the table client.
        It is possible that the value of a keyword is a record itself
        (arbitrarily deeply nested). A field in such a subrecord can be
        written by separating the name with dots. If a subrecord does not
        exist, an error is returned unless texttt{makesubrecord=True} is given.
        In such a case intermediate records are created when needed.
        """
        schema = {'columnname': {'type': 'cStr'}, 'keyword': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'value': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'columnname': columnname, 'keyword': keyword, 'value': value}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putcolkeyword_result = self._swigobj.putcolkeyword(_str_ec(_pc.document['columnname']), _any_ec(_pc.document['keyword']), _any_ec(_pc.document['value']))
        return _putcolkeyword_result

    def putcolkeywords(self, columnname, value):
        """Put multiple keywords in the given column.
        All fields in the given record are put
        as column keywords. The value of each field can be a scalar or
        an array of any type or it can be a record.
        It is also possible to define a keyword holding a subtable.
        This can be done by giving the keyword a string value consisting of
        the subtable name prefixed by 'Table: '.
        """
        schema = {'columnname': {'type': 'cStr'}, 'value': {'type': 'cDict'}}
        doc = {'columnname': columnname, 'value': value}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _putcolkeywords_result = self._swigobj.putcolkeywords(_str_ec(_pc.document['columnname']), _dict_ec(_pc.document['value']))
        return _putcolkeywords_result

    def removekeyword(self, keyword=[ ]):
        """
        """
        schema = {'keyword': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'keyword': keyword}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _removekeyword_result = self._swigobj.removekeyword(_any_ec(_pc.document['keyword']))
        return _removekeyword_result

    def removecolkeyword(self, columnname, keyword=[ ]):
        """
        """
        schema = {'columnname': {'type': 'cStr'}, 'keyword': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'columnname': columnname, 'keyword': keyword}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _removecolkeyword_result = self._swigobj.removecolkeyword(_str_ec(_pc.document['columnname']), _any_ec(_pc.document['keyword']))
        return _removecolkeyword_result

    def getdminfo(self):
        """This function returns the types and names of the data managers used.
        For each data manager it also returns the names of the columns served by it.
        The information is returned as a record containing a subrecord for
        each data manager. Each subrecord contains the fields TYPE, NAME and
        COLUMNS.
        """
        _getdminfo_result = _dict_dc(self._swigobj.getdminfo())
        return _getdminfo_result

    def keywordnames(self):
        """This function returns a vector of strings containing the names
        of all table keywords.
        """
        _keywordnames_result = [_str_dc(_x) for _x in self._swigobj.keywordnames()]
        return _keywordnames_result

    def fieldnames(self, keyword=''):
        """This function returns a vector of strings containing the names
        of all fields in the given table keyword.
        It is only valid if the keyword value is a record.
        If no keyword name is given, the names of all table keywords are returned.
        """
        schema = {'keyword': {'type': 'cStr'}}
        doc = {'keyword': keyword}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fieldnames_result = [_str_dc(_x) for _x in self._swigobj.fieldnames(_str_ec(_pc.document['keyword']))]
        return _fieldnames_result

    def colkeywordnames(self, columnname):
        """This function returns a vector of strings containing the names
        of all keywords in the column with the given name..
        """
        schema = {'columnname': {'type': 'cStr'}}
        doc = {'columnname': columnname}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _colkeywordnames_result = [_str_dc(_x) for _x in self._swigobj.colkeywordnames(_str_ec(_pc.document['columnname']))]
        return _colkeywordnames_result

    def colfieldnames(self, columnname, keyword=''):
        """This function returns a vector of strings containing the names
        of all fields in the given keyword in the given column.
        It is only valid if the keyword value is a record.
        If no keyword name is given, the names of all keywords in the column
        are returned.
        """
        schema = {'columnname': {'type': 'cStr'}, 'keyword': {'type': 'cStr'}}
        doc = {'columnname': columnname, 'keyword': keyword}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _colfieldnames_result = [_str_dc(_x) for _x in self._swigobj.colfieldnames(_str_ec(_pc.document['columnname']), _str_ec(_pc.document['keyword']))]
        return _colfieldnames_result

    def getdesc(self, actual=True):
        """The table description is a casapy record that contains a complete
        description of the layout
        of the table (except for the number of rows).
        
        By default the actual table description is returned (thus telling the
        actual shapes and data managers used). It is also possible to get
        the table description used when creating the table.
        """
        schema = {'actual': {'type': 'cBool'}}
        doc = {'actual': actual}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getdesc_result = _dict_dc(self._swigobj.getdesc(_pc.document['actual']))
        return _getdesc_result

    def getcoldesc(self, columnname):
        """The column description is a casapy record that contains a complete
        description of the layout
        of a specified column (except for the number of rows). It can be used
        to construct a table description.
        """
        schema = {'columnname': {'type': 'cStr'}}
        doc = {'columnname': columnname}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _getcoldesc_result = _dict_dc(self._swigobj.getcoldesc(_str_ec(_pc.document['columnname'])))
        return _getcoldesc_result

    def ok(self):
        """Perform a number of sanity checks and return T if ok.
        Failure (returning F) is a sign of a bug.
        """
        _ok_result = self._swigobj.ok()
        return _ok_result

    def clearlocks(self):
        """Occasionally a table will be inretrievably locked to another process no matter how much closing is done.
        So clearLocks will unlock all the files in the table cache that use AutoLocking.
        """
        _clearlocks_result = self._swigobj.clearlocks()
        return _clearlocks_result

    def listlocks(self):
        """Occasionally a table will be inretrievably locked to another process no matter how much closing is done.
        So listLocks will list the offending tables (and unoffending ones, too), so we can figure out where the problem might be.
        """
        _listlocks_result = self._swigobj.listlocks()
        return _listlocks_result

    def statistics(self, column, complex_value='', useflags=True):
        """This function computes descriptive statistics on the table column.
        It returns the statistical values as a dictionary.  The given
        column name must be a numerical column.
        If it is a complex valued column, the parameter complex_value defines
        which derived real value is used for the statistics computation.
        
        """
        schema = {'column': {'type': 'cStr'}, 'complex_value': {'type': 'cStr'}, 'useflags': {'type': 'cBool'}}
        doc = {'column': column, 'complex_value': complex_value, 'useflags': useflags}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _statistics_result = _dict_dc(self._swigobj.statistics(_str_ec(_pc.document['column']), _str_ec(_pc.document['complex_value']), _pc.document['useflags']))
        return _statistics_result

    def showcache(self, verbose=True):
        """Show the contents of the table cache.
        """
        schema = {'verbose': {'type': 'cBool'}}
        doc = {'verbose': verbose}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _showcache_result = [_str_dc(_x) for _x in self._swigobj.showcache(_pc.document['verbose'])]
        return _showcache_result

    def testincrstman(self, column):
        """Checks consistency of an Incremental Store Manager bucket layout
        
        In case of corruption it returns False and a SEVERE msg is posted containing information about the location of the corrupted bucket
        
        
        """
        schema = {'column': {'type': 'cStr'}}
        doc = {'column': column}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _testincrstman_result = self._swigobj.testincrstman(_str_ec(_pc.document['column']))
        return _testincrstman_result


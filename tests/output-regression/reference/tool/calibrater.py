##################### generated by xml-casa (v2) from calibrater.xml ################
##################### 48046d4c970151287b18f85e46a7ec61 ##############################
from __future__ import absolute_import 
from .__casac__ import calibrater as _calibrater
from .platform import str_encode as _str_ec
from .platform import str_decode as _str_dc
from .platform import dict_encode as _dict_ec
from .platform import dict_decode as _dict_dc
from .platform import dict_encode as _quant_ec
from .platform import dict_decode as _quant_dc
from .platform import encode as _any_ec
from .platform import decode as _any_dc
from .typecheck import validator as _pc
from .coercetype import coerce as _coerce


class calibrater:
    ### self
    def __init__(self, *args, **kwargs):
        """Create a {tt calibrater} tool.  The casapy environment provides
        a standard calibrater tool for general use (cb), but additional calibrater
        tools may be created if needed.  Calibrater tools created in this way
        are independent of the standard calibrater tool.
        """
        self._swigobj = kwargs.get('swig_object',None)
        if self._swigobj is None:
            self._swigobj = _calibrater()

    def open(self, filename, compress=False, addcorr=True, addmodel=True):
        """Attaches a MeasurementSet to the {tt calibrater} tool for further processing with
        other methods.
        """
        schema = {'filename': {'type': 'cStr'}, 'compress': {'type': 'cBool'}, 'addcorr': {'type': 'cBool'}, 'addmodel': {'type': 'cBool'}}
        doc = {'filename': filename, 'compress': compress, 'addcorr': addcorr, 'addmodel': addmodel}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _open_result = self._swigobj.open(_str_ec(_pc.document['filename']), _pc.document['compress'], _pc.document['addcorr'], _pc.document['addmodel'])
        return _open_result

    def selectvis(self, time=[ ], spw=[ ], scan=[ ], field=[ ], intent=[ ], observation=[ ], baseline=[ ], uvrange=[ ], chanmode='none', nchan=int(1), start=int(0), step=int(1), mstart={'value': float(0.0), 'unit': 'km/s'}, mstep={'value': float(0.0), 'unit': 'km/s'}, msselect=''):
        """This function provids for selection of the visibility data from the MS
        which will be treated by subsequent execution of the {stfaf solve} and
        {stfaf correct} functions.  Note that data selection is not cumulative, i.e.,
        any selection made in a previous call to {stfaf selectvis} will be overridden
        by the the current call.
        
        Most of the {stfaf selectvis} parameters use the standardized MS Selection
        syntax.
        
        The parameters are described below.  The selected data will satisfy the
        logical AND of all non-trivially specified parameters.  Note that the
        old-fashioned strided channel selection parameters are deprecated (and
        will soon be removed); use spw instead.  Running {stfaf selectvis} with
        no specified parameters restores selection of the entire MS.
        
        
        begin{description}
        item[time] is used to specify time ranges in a stardard format
        
        item[spw] is used to specify spectral window and channel selection.  Currently,
        only a single channel range can be specified per spw.
        
        item[scan] is used to specify scan numbers and ranges
        
        item[observation] is used to specify observation ID(s).
        
        item[field] is used to specify field names or indices
        
        item[baseline] is used to specify antenna and baseline combinations
        
        item[uvrange] is used to specify baseline length ranges
        
        item[chanmode] is deprecated (use spw)
        item[nchan] is deprecated (use spw)
        item[start] is deprecated (use spw)
        item[step] is deprecated (use spw)
        item[mstart] is deprecated (use spw)
        item[mstep] is deprecated (use spw)
        
        item[msselect] is used to specify a subselection of data according to
        Measurement Set columns in conditional combinations not possible
        with the standard parameters above.  This parameter should be specified
        as a valid htmladdnormallink{TaQL}{../../notes/199/199.html} expression.
        If both msselect and the standard selection parameter are used together,
        they are combined with a logical AND, i.e., the data must jointly satisfy
        all {stfaf selectvis} parameters.
        
        end{description}
        """
        schema = {'time': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'spw': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'scan': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'field': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'intent': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'observation': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'baseline': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'uvrange': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'chanmode': {'type': 'cStr'}, 'nchan': {'type': 'cInt'}, 'start': {'type': 'cInt'}, 'step': {'type': 'cInt'}, 'mstart': {'type': 'cDoubleQuant'}, 'mstep': {'type': 'cDoubleQuant'}, 'msselect': {'type': 'cStr'}}
        doc = {'time': time, 'spw': spw, 'scan': scan, 'field': field, 'intent': intent, 'observation': observation, 'baseline': baseline, 'uvrange': uvrange, 'chanmode': chanmode, 'nchan': nchan, 'start': start, 'step': step, 'mstart': mstart, 'mstep': mstep, 'msselect': msselect}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _selectvis_result = self._swigobj.selectvis(_any_ec(_pc.document['time']), _any_ec(_pc.document['spw']), _any_ec(_pc.document['scan']), _any_ec(_pc.document['field']), _any_ec(_pc.document['intent']), _any_ec(_pc.document['observation']), _any_ec(_pc.document['baseline']), _any_ec(_pc.document['uvrange']), _str_ec(_pc.document['chanmode']), _pc.document['nchan'], _pc.document['start'], _pc.document['step'], _quant_ec(_pc.document['mstart']), _quant_ec(_pc.document['mstep']), _str_ec(_pc.document['msselect']))
        return _selectvis_result

    def setmodel(self, modelimage):
        """Name of the model image to be used as a sky model for model visibility
        computations.  For now, this is used only by EP-Jones solver.
        """
        schema = {'modelimage': {'type': 'cStr'}}
        doc = {'modelimage': modelimage}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setmodel_result = self._swigobj.setmodel(_str_ec(_pc.document['modelimage']))
        return _setmodel_result

    def setptmodel(self, stokes=[ float(0.0),float(0.0),float(0.0),float(0.0) ]):
        """Set a global point source model Stokes parameters to use in solving operations.
        """
        schema = {'stokes': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}}
        doc = {'stokes': stokes}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setptmodel_result = self._swigobj.setptmodel(_pc.document['stokes'])
        return _setptmodel_result

    def setapply(self, type='', t=float(0.0), table='', field=[ ], interp='linear', select='', calwt=False, spwmap=[ int(-1) ], opacity=[ float(0.0) ]):
        """This function is used to specify the calibration components which should be
        applied during subsequent execution of the {stfaf solve} and
        {stfaf correct} functions.  This function should be executed as many
        times as necessary to specify all desired calibration components.
        
        Each calibration component represents a separate calibration matrix
        correction included in the measurement equation. The different types
        correspond to different instrumental and atmospheric effects.
        Calibration components are available as calibration tables generated
        by previous {stfaf solve} executions (types 'B','BPOLY','G','GSPLINE',
        'D','DF','T','M','MF','X'), or are calculated analytically on
        the fly (types 'P', 'TOPAC', 'GAINCURVE').  Upon execution
        of {stfaf solve} or {stfaf correct}, the group of specified
        calibration components will be applied in the order prescribed
        by the Measurement Equation formalism.
        
        The parameters are as follows:
        
        begin{description}
        
        item[type] The calibration type being specified.  This is only required
        for analytic types ('P','TOPAC','GAINCURVE').  When specifying an existing
        pre-solved calibration table, it is not necessary to explicitly specify the
        {stfaf type}; this will be discerned from the table.  (Specifying the
        {stfaf type} as well as the {stfaf table} will force a check that the
        table contains solutions of the specified type.
        
        For {stfaf type='GAINCURVE'}, an elevation-dependent correction
        will be applied using parameters read from the data repository.
        Currently, this is only supported for the VLA.
        
        item[t] This parameter will be used in a future release to control
        the range of applicability of the specified calibration.  Currently,
        it is ignored.
        
        item[table] For pre-solved calibration, the file name of the table
        to apply.
        
        item[field] The fields to select from the specified table, using
        MS Selection syntax (as in selectvis).
        
        item[interp] The desired type of time-dependent interpolation.  Use
        {stfaf interp='nearest'} to calibrate each datum with the calibration
        value nearest in time.  Use {stfaf interp='linear'} to calibrate each
        datum with calibration phases and amplitudes linearly interpolated
        from neighboring (in time) values.  In the case of phase, this mode
        will assume that phase jumps greater than 180 degrees between neighboring
        points indicate a cycle slip, and the interpolated value will follow
        this change in cycle accordingly (i.e., the implied rate will always
        be less than 180 degrees per sample).  Use {stfaf interp='aipslin'}
        to emulate the basic interpolation mode used in classic AIPS, i.e.,
        linearly interpolated amplitudes, with phases derived from linear
        interpolation of the complex calibration values.  While this method
        avoids having to track cycle slips (which is unstable for solutions
        with very low SNR), it will yield a phase interpolation which becomes
        increasingly non-linear as the spanned phase difference increases.  The
        non-linearity mimics the behavior of {stfaf interp='nearest'} as
        the spanned phase difference approaches 180 degrees (the phase of the
        interpolated complex calibration value initially changes very slowly,
        then rapidly jumps to the second value at the midpoint of the interval).
        If the uncalibrated phase is changing this rapidly, a 'nearest' interpolation
        is not desirable.  Usually, {stfaf interp='linear'} is the best choice.
        The {stfaf interp} parameter is applicable to any calibration type,
        as long as there are sufficient solutions available to perform the
        interpolation.  Note that calibration solutions which have been
        determined for only one timestamp will default to 'nearest'.  More
        interpolation options (e.g., 'cubic') will be added in the future.
        
        item[select] Used to specify general selection of a subset of
        calibration measurements from the table to be applied to the
        visibility data.  Arbitrary cross-calibration is possible by combining
        this function with the {stfaf setdata} function.  The string
        specified must be a valid htmladdnormallink{TaQL}{../../notes/199/199.html}
        expression.
        
        item[spwmap] This parameter is used to indicate how solutions
        derived from different spectral windows should be applied to other
        spectral windows.  Nominally, data in each spectral window will be
        corrected by solutions derived from the same spectral window.  This is
        the default behavior of {stfaf spwmap}, i.e., if {stfaf spwmap} is
        not specified, calibrater will insist that data be corrected by
        solutions from the same spw.  Otherwise, {stfaf spwmap} takes a
        vector of integers indicating which spectral window {em solutions} to
        apply to which spectral window {em data}, such that {tt spwmap[j]=i}
        causes solutions derived from the i-th spectral window to be used to
        correct the j-th spectral window.  For example, if (say) bandpass
        solutions are available for spws 0 & 2, and it is desired that these
        be applied to spws 1 & 3 (as well as 0 & 2), respectively, use
        {stfaf spwmap=[0,0,2,2]}.  Even if some spws do not require an
        explicit {stfaf spwmap} setting, yet one or more does, it is safest
        to specify it explicitly for all, e.g., {stfaf spwmap=[0,1,3,3]}
        indicates that spw 2 will be corrected with solutions from spw 3, and
        the others will behave nominally.  Note that if no solutions exist
        for any of the spws specified in {stfaf spwmap}, an error message
        will result.
        
        item[calwt] If set True, the data weights will be calibrated
        along with the data.  This is usually desirable.
        
        item[opacity] For {stfaf type='TOPAC'}, an elevation-dependent
        opacity correction will be applied according to the zenith opacity value
        supplied in the {stfaf opacity} parameter.  Currently, only one zenith
        opacity value can be supplied, and it is used for all antennas.
        
        end{description}
        
        Use the {stfaf state} function to review the list of calibration
        components that have been set for application.
        
        Pending improvements:
        
        begin{itemize}
        item Enable variety of interpolation modes and timescales
        item Allow for antenna- and time-dependent opacities
        end{itemize}
        """
        schema = {'type': {'type': 'cStr'}, 't': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'table': {'type': 'cStr'}, 'field': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'interp': {'type': 'cStr'}, 'select': {'type': 'cStr'}, 'calwt': {'type': 'cBool'}, 'spwmap': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'opacity': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}}
        doc = {'type': type, 't': t, 'table': table, 'field': field, 'interp': interp, 'select': select, 'calwt': calwt, 'spwmap': spwmap, 'opacity': opacity}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setapply_result = self._swigobj.setapply(_str_ec(_pc.document['type']), _pc.document['t'], _str_ec(_pc.document['table']), _any_ec(_pc.document['field']), _str_ec(_pc.document['interp']), _str_ec(_pc.document['select']), _pc.document['calwt'], _pc.document['spwmap'], _pc.document['opacity'])
        return _setapply_result

    def setcallib(self, callib={ }):
        """TBD
        """
        schema = {'callib': {'type': 'cDict'}}
        doc = {'callib': callib}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setcallib_result = self._swigobj.setcallib(_dict_ec(_pc.document['callib']))
        return _setcallib_result

    def validatecallib(self, callib={ }):
        """TBD
        """
        schema = {'callib': {'type': 'cDict'}}
        doc = {'callib': callib}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _validatecallib_result = self._swigobj.validatecallib(_dict_ec(_pc.document['callib']))
        return _validatecallib_result

    def setsolve(self, type='MF', t=[ ], table='', append=False, preavg=float(-1.0), phaseonly=False, apmode='AP', refant=[ ], refantmode='flex', minblperant=int(4), solnorm=False, minsnr=float(0.0), combine='', fillgaps=int(0), cfcache='', painc=float(360.0), fitorder=int(0), fraction=float(0.1), numedge=int(-1), radius='', smooth=True, zerorates=False):
        """This function specifies the calibration component that will be solved for
        by the {stff solve} function.  Currently, only one type can
        be solved for at one time.
        
        Each calibration component represents a separate calibration matrix
        correction included in the measurement equation. The different types
        correspond to different instrumental and atmospheric effects.
        Currently, the solvable calibration components are types 'G','T','B', 'D'
        and 'DF', which are antenna-based, and, 'M' and 'MF', which are
        baseline-based.  Arrange to pre-apply any existing calibration components (of
        types other than the solved-for one) using the {stfaf setapply}
        function.
        
        The parameters are:
        
        begin{description}
        item[type] Specify the calibration type you want to solve for, from
        'G','T','B','D','DF','M','MF'.
        
        item[t] Specify the solution interval.  This can be specified as an
        integer (units of seconds assumed) or as a string containing a value
        and units (e.g., '30s', '45min', '2h') or 'inf' (infinite) or 'int'
        (per data integration).  A solution interval of 0 (with or without
        units) is the same as 'int' (per integration), and negative solution
        intervals are treated as 'inf' (infinite).
        
        item[table] Specify the output calibration table name in which to
        store the calibration solve result.  Existing tables will be
        deleted and replaced.
        
        item[append] Append the solutions to an existing table.
        
        item[preavg] Specify the amount of pre-average (in time) within
        the solution interval.  By default, data are averaged up to
        the solution interval (or up to 5 minutes for 'D' solving).
        
        item[phaseonly] This parameter is deprecated, use apmode.
        
        item[apmode] Control generation of amplitude-only ('a'),
        phase-only ('p'), or amplitude-and-phase ('ap', the default) solutions.
        
        item[refant] Specify an antenna (using data selection syntax)
        for referencing the solutions.
        
        item[solnorm] Normalize the solutions by their mean post-solve. For
        'B', and 'MF', this is a complex normalization per solution spectrum.
        For other types, this is a global (per-spw) normalization of the
        amplitudes only.
        
        item[minsnr] Specify the SNR below which solution are rejected.
        
        item[combine] Specify which data axes (spw, field, scan, or some
        combination) on which the data should be combined to generate
        a single solution.  E.g., combine='spw' will force combination
        of many spws to form a single solution (per solution interval).
        Similarly, combine='scan' with a long solution interval
        will force the combination of scans to yield individual solutions
        (per field and spw).  Ordinarily, solutions are always broken
        at scans boundaries.  Separate multiple combine options with
        commas.
        
        item[fillgaps] For 'B' solutions, specify the largest solution
        channel gap (which arise due to flagged data) that will be filled
        post-solve via interpolation.  Such solution gaps remain flagged
        by default.
        
        end{description}
        
        Pending improvements:
        
        begin{itemize}
        item{Change t to solint?}
        item{Permit flexible specification of preavg (as for t)}
        end{itemize}
        """
        schema = {'type': {'type': 'cStr'}, 't': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'table': {'type': 'cStr'}, 'append': {'type': 'cBool'}, 'preavg': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'phaseonly': {'type': 'cBool'}, 'apmode': {'type': 'cStr'}, 'refant': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'refantmode': {'type': 'cStr'}, 'minblperant': {'type': 'cInt'}, 'solnorm': {'type': 'cBool'}, 'minsnr': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'combine': {'type': 'cStr'}, 'fillgaps': {'type': 'cInt'}, 'cfcache': {'type': 'cStr'}, 'painc': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'fitorder': {'type': 'cInt'}, 'fraction': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'numedge': {'type': 'cInt'}, 'radius': {'type': 'cStr'}, 'smooth': {'type': 'cBool'}, 'zerorates': {'type': 'cBool'}}
        doc = {'type': type, 't': t, 'table': table, 'append': append, 'preavg': preavg, 'phaseonly': phaseonly, 'apmode': apmode, 'refant': refant, 'refantmode': refantmode, 'minblperant': minblperant, 'solnorm': solnorm, 'minsnr': minsnr, 'combine': combine, 'fillgaps': fillgaps, 'cfcache': cfcache, 'painc': painc, 'fitorder': fitorder, 'fraction': fraction, 'numedge': numedge, 'radius': radius, 'smooth': smooth, 'zerorates': zerorates}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setsolve_result = self._swigobj.setsolve(_str_ec(_pc.document['type']), _any_ec(_pc.document['t']), _str_ec(_pc.document['table']), _pc.document['append'], _pc.document['preavg'], _pc.document['phaseonly'], _str_ec(_pc.document['apmode']), _any_ec(_pc.document['refant']), _str_ec(_pc.document['refantmode']), _pc.document['minblperant'], _pc.document['solnorm'], _pc.document['minsnr'], _str_ec(_pc.document['combine']), _pc.document['fillgaps'], _str_ec(_pc.document['cfcache']), _pc.document['painc'], _pc.document['fitorder'], _pc.document['fraction'], _pc.document['numedge'], _str_ec(_pc.document['radius']), _pc.document['smooth'], _pc.document['zerorates'])
        return _setsolve_result

    def setsolvegainspline(self, table='', append=False, mode='PHAS', splinetime=float(10800), preavg=float(0.0), npointaver=int(10), phasewrap=float(250), refant=[ ]):
        """This function is a specialization of the {stfaf setsolve} method which
        should be used when cubic spline G solutions are desired, e.g., when
        SNR on calibrators is very low.  Currently, this solving mode treats
        dual polarization data on a per-polarization basis.  The option to
        obtain a joint solution (a la 'T') will be provided in the future.
        
        The visibility data are averaged in frequency (for multi-channel data)
        prior to the solution.
        
        This method uses many of the basic parameters as the generic
        {stfaf setsolve}.  Parameters unique to the spline solver are:
        
        begin{description}
        
        item[mode] For phase solutions only, use {stfaf mode='PHAS'}.  For
        amplitude solutions only, use {stfaf mode='AMP'}.  If both are
        desired, use {stfaf mode='PHASAMP'}, and both will be solved for
        using the same spline timescale (this mode also assumes that all
        calibrators have the correct relative flux densities).  If solving for
        phase and amplitude separately (usually in this order), it is usually
        desirable to apply the first one when solving for the second
        one. Spline solution so obtained will be stored in separate
        calibration tables.  In the near future, the {stfaf mode} parameter
        will be consolidated with the generic {stfaf apmode} parameter.
        
        item[splinetime] The spline timescale (time between knots) is
        specified here. The default is 10800 seconds (3 hours).  In future
        this parameter will be consolidated with the generic {stfaf t}
        parameter.  The {stfaf preavg} parameter should be set to a value at
        least 4X shorter than the spline time (an error will occur if there is
        insufficient sampling within the {stfaf splinetime} timescale), and
        consistent with the expected coherence.  Consistent with these constraints,
        use the largest possible value for {stfaf preavg} to optimize the SNR of
        the pre-solve phase-tracking algorithm.
        
        item[npointaver and phasewrap] These parameters tune the
        phase-unwrapping algorithm when {stfaf mode $=$ 'PHAS'}.  Cycle slips
        are detected (and removed before the spline solve) when the median
        phase a sequence of length {stfaf npointaver} (in integrations)
        differs by more than {stfaf phasewrap} degrees from the previous
        sequence.
        
        end{description}
        
        Pending improvements:
        
        begin{itemize}
        item Consolidate more parameters with the generic {stfaf setsolve}
        item Introduce the generic combine options
        item Improve phase-tracking algorithm
        end{itemize}
        """
        schema = {'table': {'type': 'cStr'}, 'append': {'type': 'cBool'}, 'mode': {'type': 'cStr'}, 'splinetime': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'preavg': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'npointaver': {'type': 'cInt'}, 'phasewrap': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'refant': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'table': table, 'append': append, 'mode': mode, 'splinetime': splinetime, 'preavg': preavg, 'npointaver': npointaver, 'phasewrap': phasewrap, 'refant': refant}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setsolvegainspline_result = self._swigobj.setsolvegainspline(_str_ec(_pc.document['table']), _pc.document['append'], _str_ec(_pc.document['mode']), _pc.document['splinetime'], _pc.document['preavg'], _pc.document['npointaver'], _pc.document['phasewrap'], _any_ec(_pc.document['refant']))
        return _setsolvegainspline_result

    def setsolvebandpoly(self, table='', append=False, t=[ ], combine='', degamp=int(3), degphase=int(3), visnorm=False, solnorm=True, maskcenter=int(0), maskedge=float(5.0), refant=[ ]):
        """This function is a specialization of the {stfaf setsolve} method
        which should be used to arrange for bandpass solving when polynomial
        solutions for B are desired, e.g., when per-channel SNR on calibrators
        is too low to obtain a useful sampled bandpass.
        
        Prior to the solution, the visibility data are averaged in time,
        and the solution is performed for both phase and amplitude.
        
        This method uses most of the same parameters as the generic
        {stfaf setsolve}, with a few unique additions:
        
        begin{description}
        
        item[degamp and degphase] The parameters permit specification
        of the polynomial order to use in amp and phase.  Specifying
        0 (zero) yields constant solutions.
        
        item[visnorm] This parameter is used to normalize the assembled
        spectral data, in a per baseline manner.  If set True, this will have
        the effect of removing any non-frequency-dependent closure errors
        (e.g., as caused by source structure, or introduced by the instrument)
        from the data, and should be used with caution.  The resulting
        solutions will be effectively normalized as well.  When {stfaf
        visnorm=F} is used, closure errors in the data (as supplied to the
        solver) may be visible in the form of offsets between the data and
        solutions.  For bandpass calibration, this is usually ok, as the {em
        shape} of the bandpass is the most important aspect of the solution.
        In future this parameter will be generalized and made available
        for other solve types. (NB: Use of {stfaf solnorm=True} still
        provides for post-solve normalization of the solutions.)
        
        item[maskcenter and maskedge] These parameters control how many
        channels are ignored on-the-fly, at the center and edges of each input
        spectral window, respectively.  To avoid edge channels, it is almost
        always better to flag these channels directly, or select against them
        in {stfaf setdata}.  Aggressive use of maskedge (large values), will
        yield polynomial solutions which will tend to diverge at the edges
        (especially when the polynomial degree is also high), because maskedge
        does not change the frequency domain of the solutions.  Such solutions
        should be used with caution in subsequent operations.  (It is best to
        avoid use of maskedge.)
        end{description}
        
        The BPOLY solution is performed for both phase and amplitude, and the
        result will be stored in the same table.  The frequency domain of the
        solutions is limited to only the range of frequencies selected in
        {stfaf selectvis}.  When correcting data with these solutions (for
        other solves or with {stfaf correct}), only data within this domain
        will be corrected.  Data outside (e.g., edge channels avoided in
        {stfaf setdata} for the solve), will not be corrected.  Therefore,
        the same (or narrower) channel selection is recommended for all
        operations using solutions produced by this function and {stfaf
        solve()}.
        
        Note that the {stfaf combine} parmaeter can be used meaningfully with
        the BPOLY solver.  When combine='spw', the data from multiple spws
        will be combined on a common frequency axis, and a single polynomial
        will be determined spanning them all.  This is different than for
        ordinary sampled 'B' solutions, for which combine='spw' causes the
        bandpass to be combined on a common channel axis, effectively yielding
        a mean bandpass for the set of spws.
        """
        schema = {'table': {'type': 'cStr'}, 'append': {'type': 'cBool'}, 't': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'combine': {'type': 'cStr'}, 'degamp': {'type': 'cInt'}, 'degphase': {'type': 'cInt'}, 'visnorm': {'type': 'cBool'}, 'solnorm': {'type': 'cBool'}, 'maskcenter': {'type': 'cInt'}, 'maskedge': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'refant': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'table': table, 'append': append, 't': t, 'combine': combine, 'degamp': degamp, 'degphase': degphase, 'visnorm': visnorm, 'solnorm': solnorm, 'maskcenter': maskcenter, 'maskedge': maskedge, 'refant': refant}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setsolvebandpoly_result = self._swigobj.setsolvebandpoly(_str_ec(_pc.document['table']), _pc.document['append'], _any_ec(_pc.document['t']), _str_ec(_pc.document['combine']), _pc.document['degamp'], _pc.document['degphase'], _pc.document['visnorm'], _pc.document['solnorm'], _pc.document['maskcenter'], _pc.document['maskedge'], _any_ec(_pc.document['refant']))
        return _setsolvebandpoly_result

    def state(self):
        """Request the apply/solve state of the calibrater tool.  A listing of
        all calibration components that have been set for application or
        solving is written to the logger.
        """
        _state_result = self._swigobj.state()
        return _state_result

    def reset(self, apply=True, solve=True):
        """Resets the apply and/or solve components previously set by setapply and
        setsolve.
        """
        schema = {'apply': {'type': 'cBool'}, 'solve': {'type': 'cBool'}}
        doc = {'apply': apply, 'solve': solve}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _reset_result = self._swigobj.reset(_pc.document['apply'], _pc.document['solve'])
        return _reset_result

    def initcalset(self, calset=int(0)):
        """This function re-initializes the calibration scratch columns:
        MODEL_DATA to unity (in total intensity, and unpolarized), and
        CORRECTED_DATA to (observed) DATA.
        Optionally if calset is set to 1 any model saved in the MS header to for calibration
        purposes is deleted
        """
        schema = {'calset': {'type': 'cInt'}}
        doc = {'calset': calset}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _initcalset_result = self._swigobj.initcalset(_pc.document['calset'])
        return _initcalset_result

    def delmod(self, otf=False, field=[ ], spw=[ ], scr=False):
        """This method can be used to delete the model visibility
        data representations in the MS.  The 'otf' representation is
        the new (as of v3.4) 'scratch-less' model data, stored as
        keywords in the MS header containing model data formation
        instructions.  It is generated by the im tool (setjy, ft, and clean
        methods; usescratch=F in im.open), and if present, overrides the
        old-fashioned MODEL_DATA column (if present).  If a user
        wishes to use the MODEL_DATA column _after_ having operated
        with the 'otf' representation, this method can be used
        to delete the 'otf' represenatation to make the MODEL_DATA
        column visible.  (Create the MODEL_DATA column by using
        usescratch=T in the im tool, or by running the cb.open
        with addmodel=T.)
        
        If otf=T, the user may selectively remove only a selection of fields model from the MS by specifying the field parameter. Similarly if the field parameter is specified, selected spws model for those fields may be deleted by specifying the spw.
        
        
        For convenience, this method also provides a means for
        deleting the MODEL_DATA column by setting scr=T.
        """
        schema = {'otf': {'type': 'cBool'}, 'field': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'spw': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'scr': {'type': 'cBool'}}
        doc = {'otf': otf, 'field': field, 'spw': spw, 'scr': scr}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _delmod_result = self._swigobj.delmod(_pc.document['otf'], _any_ec(_pc.document['field']), _any_ec(_pc.document['spw']), _pc.document['scr'])
        return _delmod_result

    def solve(self):
        """Execution of this function initiates a solve for the calibration component
        specified in a previous {stfaf setsolve} execution.  Existing calibration
        components (as specified in one or more {stfaf setapply} executions) will
        be appropriately applied to the observed and model data according to their
        position in the Measurement Equation, and their commutation properties.
        """
        _solve_result = self._swigobj.solve()
        return _solve_result

    def correct(self, applymode=''):
        """This function applies the calibration components specified via one or
        more invocations of the {stff setapply} function to the observed
        visibility data and writes the result to the CORRECTED_DATA column
        of the Measurement Set.
        """
        schema = {'applymode': {'type': 'cStr'}}
        doc = {'applymode': applymode}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _correct_result = self._swigobj.correct(_str_ec(_pc.document['applymode']))
        return _correct_result

    def corrupt(self):
        """This function applies the calibration components specified via one or
        more invocations of the {stff setapply} function to the model
        visibility data and (over-)writes the result to the MODEL_DATA column of the
        Measurement Set.
        """
        _corrupt_result = self._swigobj.corrupt()
        return _corrupt_result

    def initweights(self, wtmode='nyq', dowtsp=False, tsystable='', gainfield='', interp='', spwmap=[  ]):
        """This function initializes the MS weight info in various ways.
        
        If wtmode='ones', SIGMA and WEIGHT will be initialized with 1.0,
        globally.
        
        If wtmode='nyq' (the default), SIGMA and WEIGHT will be initialized
        according to bandwidth and integration time.  This is the
        theoretically correct mode for raw normalized visibilities.
        
        If wtmode='sigma', WEIGHT will be initialized according to the
        existing SIGMA column.
        
        If mode='weight', WEIGHT_SPECTRUM will be initialized according to the
        existing WEIGHT column; dowtspec=T must be specified in this case.
        
        For the above wtmodes, if dowtspec=T (or if the WEIGHT_SPECTRUM column
        already exists), the WEIGHT_SPECTRUM column will be initialized
        (uniformly in channel), in a manner consistent with the WEIGHT column.
        If the WEIGHT_SPECTRUM column does not exist, dowtsp=T will force its
        creation.
        
        The follow modes should be used with extreme care: If
        wtmode='delwtsp', the WEIGHT_SPECTRUM column will be deleted (if it
        exists).  If wtmode='delsigsp', the SIGMA_SPECTRUM column will be
        deleted (if it exists).  Note that creation of SIGMA_SPECTRUM is not
        supported via this method.
        
        Note that this method does not support any prior selection.
        Intialization of the weight information must currently be done
        globally or not at all.  This is to maintain consistency.
        """
        schema = {'wtmode': {'type': 'cStr'}, 'dowtsp': {'type': 'cBool'}, 'tsystable': {'type': 'cStr'}, 'gainfield': {'type': 'cStr'}, 'interp': {'type': 'cStr'}, 'spwmap': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'wtmode': wtmode, 'dowtsp': dowtsp, 'tsystable': tsystable, 'gainfield': gainfield, 'interp': interp, 'spwmap': spwmap}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _initweights_result = self._swigobj.initweights(_str_ec(_pc.document['wtmode']), _pc.document['dowtsp'], _str_ec(_pc.document['tsystable']), _str_ec(_pc.document['gainfield']), _str_ec(_pc.document['interp']), _pc.document['spwmap'])
        return _initweights_result

    def fluxscale(self, tablein, reference=[ ], tableout='', transfer=[ ], listfile='', append=False, refspwmap=[ int(-1) ], gainthreshold=float(-1.0), antenna='', timerange='', scan='', incremental=False, fitorder=int(1), display=False):
        """This function is used to bootstrap the amplitude scale the
        calibration solutions according to specified reference calibrator(s)
        of known flux density.  This is necessary when the flux densities
        of some of your calibrators were unknown (and thus were assumed
        to be 1 Jy) during G solving.
        
        The bootstrapping is achieved by comparing the median gain norm of the
        calibration solutions derived for the calibrators specified in {stfaf
        reference} (one or more sources with known flux densities at the time
        of G solving) with that of the calibrators specified in {stfaf
        transfer}, and enforcing the assumption that the antenna gains are
        constant, on average.  The gain solutions for the transfer sources are
        then re-scaled accordingly.   The {stfaf reference} and {stfaf transfer}
        parameters may be specified using the general field selection syntax
        (as in {stfaf field} in {stfaf selectvis}).
        
        If no {tt transfer} fields are specified, then the solutions for
        all non-reference fields in {tt tablein} will be re-scaled.
        
        If no {tt tableout} is specified the input table will be overwritten
        with the scaled solutions.  Note that the resulting table will only
        contain solutions for those fields implicit in the {tt reference} and
        {tt transfer} specifications.     Use {tt append=T} to append the scaled
        solutions to an existing table.
        
        Use the {stfaf refspwmap} parameter to indicate how data for
        different spectral windows should be matched in calculating the flux
        density scale factor for {stfaf transfer} fields. The default
        behavior for {tt refspwmap} is to insist on precisely matching
        spectral windows for {tt reference} and {tt transfer} fields.  When
        specified, the {stfaf refspwmap} parameter takes a vector of integers
        indicating which spectral window solutions to use as the reference for
        others, such that {tt refspwmap[j]=i} causes solutions (from reference
        fields) observed in the i-th spectral window to be used to reference
        solutions (from transfer fields) observed in the j-th spectral window.
        For example, for the case of a total of 4 spectral windows: if the
        {tt reference} fields were observed only in spw=2 & 4, and the {tt
        transfer} fields were observed variously in all 4 spws, specify {tt
        refspwmap=[2,2,4,4]}.  This will ensure that {tt transfer} fields
        observed in spws 1,2,3,4 will be referenced to {tt reference} field
        data from spws 2,2,4,4, respectively.  Note that if the {tt transfer}
        fields were observed only in spws 1 & 3, the same specification would
        work, but {tt refspwmap=[2,2,4]} would suffice.  In this case,
        nothing need be specified for the 4th spw (there are no transfer
        fields there), and specifying 2 for the 2nd spw is actually
        inconsequential (though required so that the specification of 4 for spw 3
        is properly interpretted).
        
        The  gain values used in the flux scaling determination skewed by
        outliers. The parameters, {tt gainthreshold} and {tt antenna} can be used
        to limit the input gain solutions to be included in the flux scale determination.
        Use the {tt gainthreshold} is a threshold in % from the median values of the
        gain solutions to be used. Use the {tt antenna} to select or de-selesect (using the
        MSSelection syntax) antenna(s). Futher refinements on the selection based on
        timerange and scan are possible.
        
        The derived flux densities for the transfer fields will be reported in
        the logger, and returned to the Python dictionary specified in {tt
        fluxd}.  This will be an 2D array of shape [number-of-spectral-windows
        X number-of-fields]. When mulitple spectral windows are involved the spectral
        index will also be reported by fitting the determined flux densities across
        the freuquencies. The order of a polynomcial to be fitted can be specified with
        {tt fitorder}.
        
        Note that elevation-dependent gain effects may render the basic
        assumption used here invalid, and so should be corrected for prior to
        solving for G, using types 'TOPAC' or 'GAINCURVE' in {tt setapply}.
        
        Note that the visibility data itself is not used directly by this
        function.
        
        Pending improvements:
        
        begin{itemize}
        item Allow antenna and uv-distance selection to improve results for
        resolved calibrators
        item Set the visibility model according to the flux density results
        item An option to use the data to derive the relative flux densities
        end{itemize}
        """
        schema = {'tablein': {'type': 'cStr'}, 'reference': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'tableout': {'type': 'cStr'}, 'transfer': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'listfile': {'type': 'cStr'}, 'append': {'type': 'cBool'}, 'refspwmap': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'gainthreshold': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'antenna': {'type': 'cStr'}, 'timerange': {'type': 'cStr'}, 'scan': {'type': 'cStr'}, 'incremental': {'type': 'cBool'}, 'fitorder': {'type': 'cInt'}, 'display': {'type': 'cBool'}}
        doc = {'tablein': tablein, 'reference': reference, 'tableout': tableout, 'transfer': transfer, 'listfile': listfile, 'append': append, 'refspwmap': refspwmap, 'gainthreshold': gainthreshold, 'antenna': antenna, 'timerange': timerange, 'scan': scan, 'incremental': incremental, 'fitorder': fitorder, 'display': display}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _fluxscale_result = _dict_dc(self._swigobj.fluxscale(_str_ec(_pc.document['tablein']), _any_ec(_pc.document['reference']), _str_ec(_pc.document['tableout']), _any_ec(_pc.document['transfer']), _str_ec(_pc.document['listfile']), _pc.document['append'], _pc.document['refspwmap'], _pc.document['gainthreshold'], _str_ec(_pc.document['antenna']), _str_ec(_pc.document['timerange']), _str_ec(_pc.document['scan']), _pc.document['incremental'], _pc.document['fitorder'], _pc.document['display']))
        return _fluxscale_result

    def accumulate(self, tablein='', incrtable='', tableout='', field=[ ], calfield=[ ], interp='linear', t=float(-1.0), spwmap=[ int(-1) ]):
        """This function enables cumulative calibration using {tt calibrater}.
        It is the analog of the task ``CLCAL'' in classic AIPS.
        
        The {tt accumulate} function is useful when:
        
        begin{itemize}
        item a calibration solution of a particular type already exists,
        item an incremental calibration solution {em of the same type} is desired
        (an incremental solution in this context means derived independently
        from, or determined with respect to, the first)
        item the first calibration cannot be implicitly recovered in the course
        of obtaining the incremental solution
        end{itemize}
        
        For example, a phase-only ``G'' self-calibration on a target source
        may be desired to tweak the full amplitude and phase ``G'' calibration
        already obtained from a calibrator.  The initial calibration (from the
        calibrator) contains amplitude information, and so must be carried
        forward, yet the phase-only solution itself cannot (by definition)
        recover this information, as a full amplitude and phase
        self-calibration would.  In this case, the initial solution must be
        applied while solving for the phase-only solution, then the two
        solutions combined to form a {em cumulative} calibration embodying
        the net effect of both. In terms of the Measaurement Equation, the net
        calibration is the {em product} of the initial and incremental
        solutions.
        
        The analog of {tt accumulate} in classic AIPS is the use of CLCAL to
        combine a series of (incremental) SN calibration tables to form
        successive (cumulative) CL calibration tables.
        
        Cumulative calibration tables also provide a means of generating
        carefully interpolated calibration, on variable user-defined
        timescales, that can be examined prior to application to the data with
        {tt setapply} and {tt correct}.  The solutions for different fields
        and/or spectral windows can be interpolated in different ways, with
        all solutions stored in the same table.
        
        The only difference between incremental and cumulative calibration
        tables is that incremental tables are generated directly from the data
        via {tt solve} or (in the near future) from other ancilliary data
        (e.g. weather information), and cumulative tables are generated from
        other cumulative and incremental tables via {tt accumulate}.  In all
        other respects (internal format, application to data via {tt
        setapply} and {tt correct}, plotting with {tt plotcal}, etc.), they
        are the same, and therefore interchangable.  Thus, {tt accumulate} and
        cumulative calibration tables need only be used when circumstances
        require it.
        
        The {tt accumulate} function represents a generalization on the
        classic AIPS CLCAL model of cumulative calibration in that its
        application is not limited to accumulation of ``G'' solutions (SN/CL
        tables classic AIPS are the analog of ``G'' (and, implicitly, ``T'')
        in {tt aips++}).  In principle, any basic calibration type can be
        accumulated (onto itself), as long as the result of the accumulation
        (matrix product) is of the same type.  This is true of all the basic
        types, except ``D''.  Accumulation is currently supported for ``B'',
        ``G'', and ``T'', and, in future, ``F'' (ionospheric Faraday
        rotation), ``J'' (generic full-polarization calibration),
        fringe-fitting, and perhaps others.  Accumulation of certain
        specialized types (e.g., ``GSPLINE'', ``TOPAC'', etc.) onto the basic
        types will be supported in the near future.  The treatment of various
        calibration from ancilliary data (e.g., system temperatures, weather
        data, WVR, etc.), as they become available, will also make use of {tt
        accumulate} to achieve the net calibration.
        
        Note that accumulation only makes sense if treatment of a uniquely
        incremental solution is required (as described above), or if a careful
        interpolation or sampling of a solution is desired.  In all other
        cases, re-solving for the type in question will suffice to form
        the net calibration of that type.  For example, the product of
        an existing ``G'' solution and an amplitude and phase ``G'' self-cal
        (solved with the existing solution applied), is equivalent to full
        amplitude and phase ``G'' selfcal (with no prior solution applied),
        as long as the timescale of this solution is at least as short as
        that of the existing solution.
        
        Use of {tt accumulate} is straightforward:
        
        The {tt tablein} parameter is used to specify the existing cumulative
        calibration table to which an incremental table is to be applied.
        Initially, no such table exists, and {tt accumulate} will generate
        one from scratch (on-the-fly), using the timescale (in seconds)
        specified by the parameter {tt t}.  These nominal solutions will
        be unit-amplitude, zero-phase (i.e., unit matrix) calibration,
        ready to be adjusted by accumulation.  When {tt t} is negative (the
        default), the table name specified in {tt tablein} must exist and
        will be used.
        
        The {tt incrtable} parameter is used to specify the incremental table
        that should be applied to {tt tablein}.  The calibration type of
        {tt incrtable} sets the type assumed in the operation, so {tt
        tablein} must be of the same type.  If it is not, {tt accumulate}
        will exit with an error message.  (Certain combinations of types
        and subtypes will be supported by accumulate in the future.)
        
        The {tt tableout} parameter is used to specify the name of the output
        table to write.  If un-specified (or ``''), then {tt tablein} will be
        overwritten.  Use this feature with care, since an error here will
        require building up the cumulative table from the most recent distinct
        version (if any).
        
        The {tt field} parameter specifies those field names (standard
        selection syntax) in {tt tablein} to which the incremental solution
        should be applied.  The solutions for other fields will be passed to
        {tt tableout} unaltered.  If the cumulative table was created from
        scratch in this run of {tt accumulate}, then these solutions will be
        unit-amplitude, zero-phase, as described above.
        
        The {tt calfield} parameter is used to specify the fields (standard
        selection syntax) to select from {tt incrtable} to use when applying
        to {tt tablein}.  Together, use of {tt field} and {tt calfield}
        permit completely flexible combinations of calibration accumulation
        with respect to fields.  Multiple runs of {tt accumulate} can be used
        to generate a single table with many combinations.  In future, a
        ``self'' mode will be enabled that will simplify the accumulation of
        field-specific solutions.
        
        The {tt interp} parameter is used to specify the interpolation type
        to use on the incremental solutions, as in {tt setapply}.  The
        currently available interpolation types are ``nearest'', ``linear'',
        and ``aipslin''.  See the {tt setapply} URM documentation for more
        details.
        
        The {tt spwmap} parameter enables accumulating solutions from
        differing spectral windows.  See {tt setapply} for details
        on how spwmap works.
        
        Pending improvements:
        
        begin{itemize}
        item Implement a ``self'' mode (independent of interpolation type),
        to simplify or eliminate use of the {tt field} and {tt calfield}
        parameters in some contexts (e.g., self-cal)
        item More interpolation modes, e.g., ``cubic'', and interpolation
        timescale (timerange to permit interpolation)
        item Handle propogation (or not) of bad/flagged solutions
        item Support of specialized types (e.g., TOPAC) onto the basic
        types
        item Smoothing (probably a separate function)
        end{itemize}
        """
        schema = {'tablein': {'type': 'cStr'}, 'incrtable': {'type': 'cStr'}, 'tableout': {'type': 'cStr'}, 'field': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'calfield': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'interp': {'type': 'cStr'}, 't': {'type': 'cFloat', 'coerce': _coerce.to_float}, 'spwmap': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}}
        doc = {'tablein': tablein, 'incrtable': incrtable, 'tableout': tableout, 'field': field, 'calfield': calfield, 'interp': interp, 't': t, 'spwmap': spwmap}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _accumulate_result = self._swigobj.accumulate(_str_ec(_pc.document['tablein']), _str_ec(_pc.document['incrtable']), _str_ec(_pc.document['tableout']), _any_ec(_pc.document['field']), _any_ec(_pc.document['calfield']), _str_ec(_pc.document['interp']), _pc.document['t'], _pc.document['spwmap'])
        return _accumulate_result

    def activityrec(self):
        """This funtion enables returning generic information about recent activity.
        
        
        Pending improvements:
        
        begin{itemize}
        item ??
        end{itemize}
        """
        _activityrec_result = _dict_dc(self._swigobj.activityrec())
        return _activityrec_result

    def specifycal(self, caltable='', time='', spw='', antenna='', pol='', caltype='', parameter=[ float(1.0) ], infile='', uniform=True):
        """This function enables specifying calibration parameters externally.
        """
        schema = {'caltable': {'type': 'cStr'}, 'time': {'type': 'cStr'}, 'spw': {'type': 'cStr'}, 'antenna': {'type': 'cStr'}, 'pol': {'type': 'cStr'}, 'caltype': {'type': 'cStr'}, 'parameter': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'infile': {'type': 'cStr'}, 'uniform': {'type': 'cBool'}}
        doc = {'caltable': caltable, 'time': time, 'spw': spw, 'antenna': antenna, 'pol': pol, 'caltype': caltype, 'parameter': parameter, 'infile': infile, 'uniform': uniform}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _specifycal_result = self._swigobj.specifycal(_str_ec(_pc.document['caltable']), _str_ec(_pc.document['time']), _str_ec(_pc.document['spw']), _str_ec(_pc.document['antenna']), _str_ec(_pc.document['pol']), _str_ec(_pc.document['caltype']), _pc.document['parameter'], _str_ec(_pc.document['infile']), _pc.document['uniform'])
        return _specifycal_result

    def smooth(self, tablein, tableout, field=[ ], smoothtype='median', smoothtime=float(60.0)):
        """This function provides for time-dependent smoothing of sampled
        calibration solutions.  Currently supported types are 'G', 'B', and 'T'.
        (Smoothing on the frequency axis for 'B' will be supported in the near
        future.)
        
        Two (sliding) smoothing types are currenlty supported: 'median' or
        'mean', one of these options should be specified in {stfaf
        smoothtype}.  The full width (in seconds) of the smoothing filter
        should be specified in {stfaf smoothtime}.   Amplitude and
        (ambiguity-corrected) phase are smoothed separately.
        
        Use {stfaf field} to limit the smoothing operation to a subset of the
        fields (standard selection syntax) found in the calibration table
        (other fields will pass to the output table unsmoothed).  If {stfaf
        field} is left blank, all fields in the table will be smoothed.
        
        The smoothing is always done independently for each field, but
        scan boundaries are not observed.  Thus, if the {stfaf smoothtime}
        is large enough, smoothing may occur over many boundaries.
        
        Flagged solutions in the input table will not participate in the
        smoothing calculation, but will be replaced with smoothed values
        if the smoothing window covers one or more unflagged solutions when
        centered on the flagged point.
        
        Pending improvements:
        
        begin{itemize}
        item Add other smoothtypes?
        item Add spw and other selection on input table
        item Add A/P toggle
        end{itemize}
        """
        schema = {'tablein': {'type': 'cStr'}, 'tableout': {'type': 'cStr'}, 'field': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'smoothtype': {'type': 'cStr'}, 'smoothtime': {'type': 'cFloat', 'coerce': _coerce.to_float}}
        doc = {'tablein': tablein, 'tableout': tableout, 'field': field, 'smoothtype': smoothtype, 'smoothtime': smoothtime}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _smooth_result = self._swigobj.smooth(_str_ec(_pc.document['tablein']), _str_ec(_pc.document['tableout']), _any_ec(_pc.document['field']), _str_ec(_pc.document['smoothtype']), _pc.document['smoothtime'])
        return _smooth_result

    def rerefant(self, tablein, tableout, refantmode='flexible', refant=[ ]):
        """TBD
        
        Pending improvements:
        
        begin{itemize}
        item TBD
        end{itemize}
        """
        schema = {'tablein': {'type': 'cStr'}, 'tableout': {'type': 'cStr'}, 'refantmode': {'type': 'cStr'}, 'refant': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}}
        doc = {'tablein': tablein, 'tableout': tableout, 'refantmode': refantmode, 'refant': refant}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _rerefant_result = self._swigobj.rerefant(_str_ec(_pc.document['tablein']), _str_ec(_pc.document['tableout']), _str_ec(_pc.document['refantmode']), _any_ec(_pc.document['refant']))
        return _rerefant_result

    def listcal(self, caltable, field=[ ], antenna=[ ], spw=[ ], listfile='', pagerows=int(50)):
        """calibrater.listcal() lists antenna gain solutions in tabular
        form.  The table is organized as follows.  Solutions are output by
        begin{enumerate}
        item Spectral window,
        item Antenna,
        item Time,
        item Channel,
        item and Polarization.
        end{enumerate}
        The inner-most loop is over polarization.
        A ``Spw Header'' row is printed each time the spectral window changes.
        In addition  to listing the spectral window ID (SpwID), the Spw Header
        also lists the date of observation (Date), the calibration table name (CalTable), and the measurement
        set name (MS name).  A lower-level ``antenna header'' is printed each time the antenna
        names change or every `pagerows' of output, whichever comes first.
        The antenna header column are described here:
        
        begin{tabular}{ll}
        hline hline
        Column Name   & Description 
        hline
        Ant           & Antenna name 
        Time          & Visibility timestamp corresponding to gain solution 
        Field         & Field name 
        Chn           & Channel number 
        Amp           & Complex solution amplitude 
        Phs           & Complex solution  phase 
        F             & Flag 
        hline hline
        end{tabular}
        
        Elements of the ``F'' column contain an `F' when the datum is flagged,
        and ` ' (whitespace) when the datum is not flagged.
        
        Presently, the polarization mode names (for example: R, L)
        are not given, but the ordering of the polrization modes (left-to-right) is
        equivalent to the order output by task listobs (see ``Feeds'' in listobs output).
        """
        schema = {'caltable': {'type': 'cStr'}, 'field': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'antenna': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'spw': {'type': 'cVariant', 'coerce': [_coerce.to_variant]}, 'listfile': {'type': 'cStr'}, 'pagerows': {'type': 'cInt'}}
        doc = {'caltable': caltable, 'field': field, 'antenna': antenna, 'spw': spw, 'listfile': listfile, 'pagerows': pagerows}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _listcal_result = self._swigobj.listcal(_str_ec(_pc.document['caltable']), _any_ec(_pc.document['field']), _any_ec(_pc.document['antenna']), _any_ec(_pc.document['spw']), _str_ec(_pc.document['listfile']), _pc.document['pagerows'])
        return _listcal_result

    def posangcal(self, posangcor, tablein, tableout=''):
        """This function is used to apply position angle calibration for
        observations made using circularly polarized feeds.  According to the
        Measurement Equation formalism, this correction should be applied to a
        {tt D} (instrumental polarization) calibration table.
        
        If no {tt D} calibration is performed (and thus no such table is
        available), the correction can be applied to a {tt G} table, but it
        should NEVER be applied to both, and always applied to a {tt D} table
        if one is available.  An input table must be specified.  If no output
        table is specified, then the input table will be modified in place.
        
        Specify, as a vector of values, a position angle adjustment (in degrees)
        for each spectral window.  If only one value is specified, it will be
        duplicated to all spectral windows; otherwise, the number of values
        specified must match the number of spectral windows.  The sign
        convention for the position angle adjustment is such that the specified
        value is the that which, when added to the position angle implied by the
        data, will yield the correct position angle.  For example, if {tt G-},
        {tt D-}, and {tt P-}calibrated data for 3c286 suggests a position
        angle of 45 degrees, the posangcor value should be -12 degrees as this
        will yield the correct position angle of 33 degrees when added.  In
        general, posangcor equals correct position angle minus observed position
        angle.
        
        A future version of this function will have an option to recognize
        standard position angle calibrators and determine the correction
        automatically.
        
        (NB: It may be desirable to use solutions for 'X' to handle
        position angle calibration, rather than this method.)
        """
        schema = {'posangcor': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'tablein': {'type': 'cStr'}, 'tableout': {'type': 'cStr'}}
        doc = {'posangcor': posangcor, 'tablein': tablein, 'tableout': tableout}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _posangcal_result = self._swigobj.posangcal(_pc.document['posangcor'], _str_ec(_pc.document['tablein']), _str_ec(_pc.document['tableout']))
        return _posangcal_result

    def linpolcor(self, tablein='', tableout='', fields=[  ]):
        """THIS METHOD IS CURRENTLY DISABLED.
        
        This function can be used to correct the gains derived from secondary
        calibrators with unknown or variable polarization.  It should only be
        used for arrays with linear (X/Y) feeds and an Alt-Az mount for which
        the observed polarization varies with feed position angle on the sky.
        
        The function fits the gains with a sine and cosine term in feed position
        angle and extracts the Q and U components of the secondary calibrator.
        This is only possible if there is sufficient range in the position angle
        (i.e., minimum of about 6 scans spanning at least 90 degrees in position
        angle).  Check the error of the fit to judge if the fit was succesfull,
        it should generally be smaller than 0.5%.
        
        Use the {stfaf fields} argument to select calibrator fields to be
        fitted.  The function takes a calibration table as input, and can write
        the adjusted gain solutions to the same table on output, or create a new
        table containing these results.  The function also prints the derived
        polarization for each field for each spectral window.
        """
        schema = {'tablein': {'type': 'cStr'}, 'tableout': {'type': 'cStr'}, 'fields': {'type': 'cStrVec', 'coerce': [_coerce.to_list,_coerce.to_strvec]}}
        doc = {'tablein': tablein, 'tableout': tableout, 'fields': fields}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _linpolcor_result = self._swigobj.linpolcor(_str_ec(_pc.document['tablein']), _str_ec(_pc.document['tableout']), [_str_ec(_x) for _x in _pc.document['fields']])
        return _linpolcor_result

    def plotcal(self, antennas, fields, spwids, plottype='AMP', tablename='', polarization=int(1), multiplot=False, nx=int(1), ny=int(1), psfile=''):
        """This function plots a calibration table either to a plotter or
        to a file.
        
        The argument {stfaf plottype} can take the following values
        for all types of solutions:
        begin{description}
        item[AMP] Gain Amplitude vs. Time
        item[1/AMP] Inverse Gain Amplitude vs. Time (useful for
        comparing with classic AIPS)
        item[PHASE] Gain Phase vs. Time
        item[RI] Gain Real vs. Imaginary
        item[RLPHASE] Right/Left Gain phase difference (if polarizations are R,L)
        item[XYPHASE] X/Y Gain phase difference (if polarizations are X,Y)
        end{description}
        
        The argument {stfaf plottype} can take the following values
        for D tables
        
        begin{description}
        item[DAMP] Cross-polarized Gain Amplitude vs. Time
        item[DPHASE] Cross-polarized Gain Phase vs. Time
        item[DRI] Cross-polarized Gain Real vs. Imaginary
        end{description}
        
        The quality of the solutions can be examined with the following
        {stfaf plottype} choices:
        begin{description}
        item[FIT] Fit per spectral window
        item[FITWGT] Fit weight per spectral window
        item[TOTALFIT] Total fit
        end{description}
        
        By default, all antennas (as specified in the antennas argument) will
        appear on the same plot. Separate plots (all with the same scale)
        for each antenna can be activated by setting multiplot=T.  The multiplot
        argument only separates plots by antenna (not, e.g., by the field_id(s)
        specified in the fields argument).  If multiplot=T, the nx and ny
        arguments can be used to specify the number of plots per page.
        
        At the moment, only one polarization can be plotted per execution.
        This restriction will be relaxed in the near future.
        
        For B solutions, the plotting will loop over timestamps (if more than
        one).
        
        A hardcopy plot can be created by specifying the texttt{psfile}
        argument (which is especially useful for batch processing when a
        display screen is not available).  This will cause the plot to be
        written to a PostScript file which can be subsequently sent to a
        printer.
        """
        schema = {'antennas': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'fields': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'spwids': {'type': 'cIntVec', 'coerce': [_coerce.to_list,_coerce.to_intvec]}, 'plottype': {'type': 'cStr'}, 'tablename': {'type': 'cStr'}, 'polarization': {'type': 'cInt'}, 'multiplot': {'type': 'cBool'}, 'nx': {'type': 'cInt'}, 'ny': {'type': 'cInt'}, 'psfile': {'type': 'cStr'}}
        doc = {'antennas': antennas, 'fields': fields, 'spwids': spwids, 'plottype': plottype, 'tablename': tablename, 'polarization': polarization, 'multiplot': multiplot, 'nx': nx, 'ny': ny, 'psfile': psfile}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _plotcal_result = self._swigobj.plotcal(_pc.document['antennas'], _pc.document['fields'], _pc.document['spwids'], _str_ec(_pc.document['plottype']), _str_ec(_pc.document['tablename']), _pc.document['polarization'], _pc.document['multiplot'], _pc.document['nx'], _pc.document['ny'], _str_ec(_pc.document['psfile']))
        return _plotcal_result

    def modelfit(self, vary, niter=int(0), compshape='P', par=[ float(1.0),float(0.0),float(0.0) ], file=''):
        """This method fits single-component models (points, elliptical Gaussians or elliptical Disks_
        to the CORRECTED_DATA of the selected field.  A first guess for the component
        parameters may be specified in the {stfaf par} parameter.
        """
        schema = {'vary': {'type': 'cBoolVec'}, 'niter': {'type': 'cInt'}, 'compshape': {'type': 'cStr'}, 'par': {'type': 'cFloatVec', 'coerce': [_coerce.to_list,_coerce.to_floatvec]}, 'file': {'type': 'cStr'}}
        doc = {'vary': vary, 'niter': niter, 'compshape': compshape, 'par': par, 'file': file}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _modelfit_result = self._swigobj.modelfit(_pc.document['vary'], _pc.document['niter'], _str_ec(_pc.document['compshape']), _pc.document['par'], _str_ec(_pc.document['file']))
        return _modelfit_result

    def createcaltable(self, caltable, partype, caltype, singlechan):
        """Creates an empty calibration table that can subsequently be filled
        with by using the table tool.
        """
        schema = {'caltable': {'type': 'cStr'}, 'partype': {'type': 'cStr'}, 'caltype': {'type': 'cStr'}, 'singlechan': {'type': 'cBool'}}
        doc = {'caltable': caltable, 'partype': partype, 'caltype': caltype, 'singlechan': singlechan}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _createcaltable_result = self._swigobj.createcaltable(_str_ec(_pc.document['caltable']), _str_ec(_pc.document['partype']), _str_ec(_pc.document['caltype']), _pc.document['singlechan'])
        return _createcaltable_result

    def updatecaltable(self, caltable):
        """This method can be used to update a caltable (from v3.4 or later)
        to the current version of CASA.
        
        The following updates are currently supported.
        
        o At CASA v4.1.0, the OBSERVATION subtable and OBSERVATION_ID column
        were added to caltables.  This method adds trivial versions of
        these elements to pre-v4.1 caltables.
        """
        schema = {'caltable': {'type': 'cStr'}}
        doc = {'caltable': caltable}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _updatecaltable_result = self._swigobj.updatecaltable(_str_ec(_pc.document['caltable']))
        return _updatecaltable_result

    def close(self):
        """Close the {tt calibrater} tool, which is hardly ever necessary.
        """
        _close_result = self._swigobj.close()
        return _close_result

    def done(self):
        """This function is redundant with the {stfaf close} method.
        """
        _done_result = self._swigobj.done()
        return _done_result

    def parsecallibfile(self, filein):
        """TBD
        """
        schema = {'filein': {'type': 'cStr'}}
        doc = {'filein': filein}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _parsecallibfile_result = _dict_dc(self._swigobj.parsecallibfile(_str_ec(_pc.document['filein'])))
        return _parsecallibfile_result

    def setvi(self, old=False, quiet=False):
        """Use this method to control whether the modern (old=False) or old-style (old=True)
        VisibilityIterator is used by the calibration application.  General users should
        avoid use of this function unless they understand what this means.
        
        This method will be removed from the calibrater tool in v5.1.
        """
        schema = {'old': {'type': 'cBool'}, 'quiet': {'type': 'cBool'}}
        doc = {'old': old, 'quiet': quiet}
        assert _pc.validate(doc,schema), str(_pc.errors)
        _setvi_result = self._swigobj.setvi(_pc.document['old'], _pc.document['quiet'])
        return _setvi_result


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% STM 2007-04-13  split from previous version
% STM 2007-04-15  put tool info here
% JO 2010-03-12 edited for R3.0.1
% JO 2010-10-12 edited for Release 3.1.0

\chapter{Imaging Data}
\label{chapter:imtool}

This chapter describes how to make and deconvolve images starting
from a calibrated MeasurementSet.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The {\tt im} Toolkit}
\label{section:imtool.tools}

The {rm tool} for imaging and deconvolution is imager ({\tt im}).  It
has been designed to do gridding/degridding of visibility data,
Fourier transforms, deconvolution using various methods, etc. A
complete overview of the capabilities of Imager can be found in the
User Reference Manual for the {\tt imager} tool on the web:

\small
\begin{verbatim}
(http://aips2.aoc.nrao.edu/weekly/docs/user/SynthesisRef/node118.html#imager);
\end{verbatim}
\normalsize

\vspace{3mm}
\noindent 
{\bf Note:} at this time the Reference Manual still refers to the {\it
Glish} syntax so you will have to convert this to python syntax.

There are two sorts of tool functions in {\tt im}; passive and active.
The passive functions like {\tt setimage}, {\tt setdata} etc. set the
state of the {\tt im} tool.  Then, active functions such as {\tt
makeimage}, {\tt clean} etc. act on the data according to the
previously set state.

To use an {\tt im} tool, one must first construct it from a
MeasurementSet and then configure it (set its ``state'').  When you
are finished, you destroy the tool (which of course does not affect
the actual MeasurementSet on disk).  To construct an {\tt imager} tool
for a measurement set located at /home/data/data.ms:

\small
\begin{verbatim}
im.open('/home/data/data.ms')            # Load data into imager tool
im.summary()                             # Summarize state of tool
im.close()                               # End the tool
\end{verbatim}
\normalsize

The {\tt summary} function is always useful to summarize the current
state of the {\tt imager} tool.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Setting up the {\tt im} Tool}
\label{section:imtool.setdata}

\subsection{Data Selection}
\label{section:imtool.setdata.select}

To make an image from the visibilities one needs to select the part of
the data from the MeasurementSet that is going to be used (e.g which
pointing or channels or spectral window that is going to be imaged).
This is done with the imager.setdata function.  If you don't run this
function, you get all of the data.

Here are some examples (refer to the User Reference Manual for more
details):

\small
\begin{verbatim}
im.setdata(mode='channel', nchan=15,      # Select 15 channels, third
             spwid=2, fieldid=3)          #  spectral window  and fourth field
                                          # REMEMBER: everything is 0-based!

im.setdata(mode='channel', nchan=256,     # Select every second channel
             step=2, spwid=2, field=3)    #  to make 256 total channels

im.setdata(mode='velocity', nchan=63,     # Select data based on
             mstart=quantity(20.,'km/s'), #  radio velocity
             mstep=quantity(-100.,'m/s'),
             spwid=2,
             fieldid=3)
im.setdata(mode='opticalvelocity',        # Select data based on
             nchan=63,
             mstart=quantity(20.'km/s'),  #  optical velocity
             mstep=quantity(-100.,'m/s')) #

# Consider a more complex data selection with diferent number of channels and
# different spectral windows:

im.setdata(mode='channel', spwid=[1,2],   # Select spectral windows 2 & 3,
             start=[3,4],                 #  spwid 1: start at 4, select 10 chans
             nchan=[10,12], step=[1,1])   #  spwid 2: start at 5, select 12 chans
                                          #  step by 1 channel for each spwid
\end{verbatim}
\normalsize

Other functions like {\tt imager.filter} and {\tt imager.uvrange} can
also further reduce the data selected.

\subsection{Setting Image Parameters}
\label{section:imtool.setdata.setimage}

To set the actual imaging parameters use the {\tt imager.setimage}
function.  This is a {\bf required} function in {\tt Imager} (in fact,
the only one presently).  This function is passive; it just sets state
so that when you tell {\tt Imager} to do something (like make an
image), it knows what to do.

This function controls things like image size, cell size, spectral and
polarization selection, sampling, phasecenter, and number of facets
(for wide-field imaging).  Images constructed afterwards (using {\em
e.g.} the {\tt imager.clean} function) will have these parameters.

One important point to note is that the image size does NOT have to be
a power of two.  Just choose some reasonably composite even number
close to the number that you want.  {\bf Do not} use a prime number
since the Fourier Transform will then be very slow.

Another important point is that the data selection between {\tt setdata}
and {\tt setimage} should be aligned, that is, there must be some overlap
(e.g., don't select fieldid=1 in {\tt setdata} and fieldid=2 in {\tt setimage}).
If you aren't doing any averaging, then the data selection fields
({\tt fieldid, mode, nchan, start, spwid, etc}) should be the same in both
function calls; see below for more details.

As an example, to set the image parameters for a simple image cube:

\small
\begin{verbatim}
  im.setimage(nx=600, ny=600,              # Define image to be 600x600 pixels
     cellx=quantity(0.5,'arcsec'),
     celly=quantity(0.5,'arcsec'),         #  with 0.5'' pixels for
     fieldid=2, mode='channel',            #  field 3 and image 20 channels
     nchan=20, start=10)                   #  starting at channel 11.
\end{verbatim}
\normalsize

The phase center is that of the specified field center. In addition,
each selected channel will be imaged as one channel of the output
image.

\subsection{Channel Selection and Combination}
\label{section:imtool.setdata.setchans}

Functions {\tt imager.setdata} and {\tt imager.setimage} both have
arguments {\tt nchan, start} and {\tt step}.  {\tt setdata} is used to
select channels.  {\tt setimage} is used to specify how many {\bf
output} channels the image will have, and how the input channels
should be combined (averaging, gridding).

You should call {\tt setdata} first.  After you have called this
function, subsequent active {\tt Imager} function calls only have
available to them the data that you selected.

Note however, that when you call {\tt setimage}, the specification of
the channels is still in an absolute sense.  Thus, if you set {\tt
nchan=10, start=20} in {\tt setdata}, and you wish to image all of
these channels (let us say one image plane per channel), you must {\bf
also} set {\tt nchan=10, start=20} in {\tt setimage}.

You might think that you have already selected the 20 channels you
want with {\tt setdata} and therefore in function {\tt setimage}
setting {\tt start=1} would select the first of those 20 channels.
This is {\bf not} the way it works.  If you asked for, say, channel 1
with {\tt setimage} when you did {\bf not} select channel 1 with
function {\tt setdata}, that channel would be imaged but empty in the
output image.

You use the channel selection parameters in {\tt setimage} to
specify how the selected channels will be combined and how many output
channels the image will have.  Basically, there are two sorts of ways
that you might like to use the channels that you have selected.

Firstly, in a multi-frequency synthesis image, all of the selected
channels are gridded onto the $uv$ plane to reduce band-width smearing
(which would be incurred if you averaged the channels and then
gridded).  In this case, the {\tt step} argument is not generally
relevant; leave it at 1 if explicitly 'mfs' is used.  For example:

\small
\begin{verbatim}
  im.setdata(mode='channel',      # Select 32 channels and start at channel 11
     nchan=32, start=10, step=1)
  im.setimage(mode='mfs',         # In mfs mode, create the average of
     nchan=1, start=0, step=1)    #  the 32 channels selected above
\end{verbatim}
\normalsize

Or, if you want a straight average:

\small
\begin{verbatim}
  im.setdata(mode='channel',      # select 32 channels starting at channel 11
     nchan=32, start=10, step=1)
  im.setimage(mode='channel',     # Select 1 channel - this will be the
     nchan=1, start=10, step=32)  #  average of the 32 channels selected above
\end{verbatim}
\normalsize

Secondly, when you make a spectral-line cube, you may wish to
select/combine channels in a variety of ways according to the science
you want to do.  Here are some examples.

\small
\begin{verbatim}
  im.setdata(mode='channel',       # Select 200 consecutive channels starting
     nchan=200, start=10, step=1)  #  with channel 11
  im.setimage(mode='channel',      # Form an image plane for each
     nchan=200, start=10, step=1)  #  selected channel


  im.setdata(mode='channel',       # Select 200 channels starting with channel
     nchan=200, start=10, step=5)  #  11, pick every fifth channel
  im.setimage(mode='channel',      # Form an image plane for each
     nchan=200, start=10, step=5)  #  selected channel


  im.setdata(mode='channel',       # Select 200 channels starting with channel
     nchan=200, start=10, step=5)  #  11, pick every fifth channel
  im.setimage(mode='channel',      # Each channel of the image is formed by
     nchan=100, start=10, step=10) #  averaging 2 successively selected channels
\end{verbatim}
\normalsize


In the above example, channels 11, 16, 21, 26, 31, etc...  are
selected.  During imaging, channels 11 and 16 will be averaged to form
output image channel 0.  Channels 21 and 26 are averaged to form
output channel 1 and so on.

Of course you could also use {\tt mode='mfs'} when combining groups of
channels if you want an output image of more than one channel.  In
this case the combination is done by gridding rather than averaging.

Now to an example when one wants to make a cube image from multiple spectral
windows:

\small
\begin{verbatim}
  im.setdata(mode='channel',               # Select 600 data channels from
     spwid=[0,1,2], nchan=[200,200,200],   #  3 spectral windows(200 from each)
     start=[0,0,0], step=[1,1,1],          #  start at channel 1, step by 1,
     fieldid=1)                            #  for field 2
  im.setimage(mode='channel',              # Create 150 channels, average
     spwid=[0,1,2], nchan=150,             #  4 channels for each image
     start=0, step=4,                      #  plane.
     fieldid=1)                            #
\end{verbatim}
\normalsize


In the above example we select 600 data channels from 3 spectral
windows (200 from each spectral window). Then in the {\tt setimage}
step we make imager combine 4 channels to make one image channel.
Note, the spectral windows should have some overlapping channels for
this procedure.  {\tt imager} will figure out what the overlap is and
create a continuous image cube from all 3 spectral windows.

Now consider an example in which all data in spectral windows 1 and 2
are selected.  Then define an image in terms of velocity values:

\small
\begin{verbatim}
  im.setdata(fieldid=1, spwid=[0,1])     # Select field 2 and sp windows 1 & 2
  im.setimage(nx=800, ny=800,            # Image will have 800x800 pixels
     cellx=quantity(0.5,'arcsec'),
     celly=quantity(0.5,'arcsec'),       # 0.5'' on a side, create 30 channels,
     mode='velocity', nchan=30,          #  start at -10km/s and step by
     mstart=quantity(-10.,'km/s'),
     mstep=quantity(1.8,'km/s'),         #  1.8km/s.  Do this for field 2
     spwid=[0,1], fieldid=1)             #  and use both spectral windows
\end{verbatim}
\normalsize

Examples for mosaics are given in Section
\ref{section:imtool.mosaic.example}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Weighting}
\label{section:imtool.weight}

The above steps show how to set up the {\tt Imager} tool as desired.  In
addition, before imaging one may wish to set some values in the
MeasurementSet itself.  This is necessary for visibility weighting.  The
visibility imaging weights are computed prior to the actual imaging.

The first time an {\tt Imager} tool is attached to a MeasurementSet it
initializes the imaging weights to the natural weighting scheme.
Thereafter, whatever weighting scheme you last used is the one you
will get if you don't explicitly run one of the weighting functions.

The weights for the imaging process are computed, changed, and examined by
the following functions.

\begin{itemize}
   \item {\tt im.weight} -- sets the column using one of natural,
          uniform, or Briggs (robust) weighting.  For the latter two
          methods, one can specify the field of view over which the
          minimization of the sidelobes is done (thus achieving what
          is often called super-uniform weighting).  Below are some
          examples of how to set imaging weights:

\small
\begin{verbatim}
  im.weight(type='natural')                # Natural weighting
  im.weight(type='uniform')                # Uniform over entire field of view
  im.weight(type='uniform', npixels=300)   # Uniform over specified size
  im.weight(type='briggs', rmode='norm',   # An example of Briggs
     robust=0.5)                           #  weighting
\end{verbatim}
\normalsize

   \item {\tt im.filter} -- applies an optimal filter for a given
          shape (often called 'tapering'). In the following example we
          apply a Gaussian filter:

\small
\begin{verbatim}
  im.filter(type='gaussian',                 # Apply a Gaussian taper
     bmaj=quantity(4.0,'arcsec'),
     bmin=quantity(2.5,'arcsec'),            #  that is 4x2.5 arcsec in size
     bpa=quantity(60.,'deg'))                #  at a position angle of 60deg
\end{verbatim}
\normalsize

%   \item {\tt im.plotweights} -- plots the imaging weights either as a
%         function of {\it uv} distance or on a gridded plane. 

   \item {\tt im.sensitivity} -- calculates and returns the
          sensitivity of the resulting weighting both absolutely and relative
          to natural weighting. 

   \item {\tt im.fitpsf} -- calculates the dirty point spread function
         and returns the best fitting Gaussian. 
\end{itemize}

{\bf WARNING:} All the weighting schemes modify the MeasurementSet and
thus are conserved even after destroying the Imager tool and may no
longer be suitable for subsequent imaging.  You can of course reset
the weighting scheme with the im.weight function.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Creating Images}
\label{section:imtool.create}

It may be helpful to use the im.advise function to help determine the
cell size, as well as the number of pixels for a given field of view.

Imagine we want to make an image over a field of view of 10~arcmin.
The {\tt im.advise} function will return the maximum pixel size
required and number of pixels. If the number of facets required is
larger than 1 then one needs a wide-field imaging algorithm as
described in the {\tt wide-field} Section below . The recommendations
should always be considered in the context of your imaging goals
before being used.  For example, to use the {\tt advise} function on a
split MeasurementSet that contains only calibrated source data:

\small
\begin{verbatim}
  im.open('source.ms')                           # Create the imager tool
  im.advise(fieldofview=quantity(10.,'arcmin'))  # Provide advice if FOV=10'

  # Logger will report something like:
    Maximum uv distance = 31068.1 wavelengths
    Recommended cell size < 3.31956 arcsec
    Recommended number of pixels = 192
    Dispersion in uv, w distance = 16011.2, 6277.93 wavelengths
    Best fitting plane is w = -0.0543279 * u + -0.418078 * v
    Dispersion in fitted w = 4882.22 wavelengths
    Wide field cleaning is not necessary
\end{verbatim}
\normalsize

It is often useful to make a dirty image of the field before
deconvolution. Use the {\tt im.makeimage} function to make a dirty
image and the point spread function:


\small
\begin{verbatim}
  im.makeimage(type='corrected', # Make a dirty image and store
       image='dirty.image')      #  it in the file called 'dirty.image'

  im.makeimage(type='psf',       # Make a PSF image and store it
       image='dirty.beam')       #  in the file on disk called 'dirty.beam'
\end{verbatim}
\normalsize
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Deconvolution}
\label{section:imtool.decon}

At this point, you are ready to deconvolve the point spread function
(usually called the dirty beam) from the dirty image.  The goal of
this step is to correct the dirty image for the sidelobes in the point
spread function which arise from the limited Fourier plane coverage in
your observation.

The available deconvolution algorithms are CLEAN, MEM and
multiscale-CLEAN.  Each are described below.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{CLEAN deconvolution} 
\label{section:imtool.decon.clean}

H\"ogbom, Clark and multi-scale variants of the CLEAN algorithm are
available using the {\tt im.clean} function.

If you use a multi-scale algorithm, you should also set up the scale
sizes via the {\tt im.setscales} function.

\vspace{3mm}
\noindent {\bf CLEAN hints}

For data using a PSF with high sidelobes, data that hasn't been
properly calibrated, or in mosaics in which the PSF used is very
different between different fields, the clean residuals may begin to
diverge (rather than converge to zero). In these cases, there are a
number of controls to help rein the cleaning process:

\begin{itemize}
  \item Reconcile the visibilities often and regenerate new residuals
        from the residual visibilities. 
  \item If using one of the multi-field algorithms (mf), the
        {\tt setmfcontrol} parameters provide additional controls on the
        process.:
     \begin{itemize}
     \item cyclefactor: The threshold in a major cycle by default is
           1.5 times the product of the peak residual and the maximum outer
           sidelobe. This can be increased to raise the threshold. 
     \item cyclespeedup: Number of iterations after which it will
           increase the threshold in a major cycle by 2. 
      \end{itemize}
 \item Manually set {\tt niter} to a small value and restart clean
       multiple times. {\tt im} subtracts the model visibility everytime it
       is started with a model image. This wya, one can force a major
       cycle every {\tt niter} iterations. 
 \item Use a mask around the region where one believes there is real
       emission. In confused regions or with strong sources, use
       interactive masking to change the 
       mask by looking at the residual after some iteration of clean. 
 \item Use a very low gain.
 \item Re-calibrate, edit the data.
\end{itemize}

Example: Force major cycles:

\small
\begin{verbatim}
im.open("orion.ms" )                       # load data into imager (im) tool
im.setdata(mode="none" ,                   # set all channels
        spwid=[0, 1] ,                     # set spectral windows 0 and 1
        fieldid=6)                         # set field 7
im.setimage(nx=500, ny=500,                # set 500 x 500
        cellx=quantity(2.0,'arcsec'),      # set cells to be 2"x2"
        celly=quantity(2.0,'arcsec'),
        stokes="I" ,                       # set Stokes I
        spwid=[0,1],                       # image spectral windows 1 and 2
        fieldid=6)                         # image field 7
im.weight(type="briggs",                   # Briggs weighting parameters
        robust=0,
        fieldofview=quantity(10.,arcsec'))
im.make('field_7c')                        # make a blank image to use as starting model
im.setscales(scalemethod='uservector',     # set multiscale clean scales
        uservector=[0,3,10,50])
im.setmfcontrol(stoplargenegatives=-1)     # continue component search even if
                                           # we've found negative components

  for k in range(10):                         # do a loop to force major cycles based
     im.clean(algorithm='mfmultiscale',    #  on the number of iterations
     niter=2000,                           # in the initial trial, 10000 iterations
                                           # diverged so we choose a 2000 iterations
                                           # (fraction of 10000) to force the major cycle
     gain=0.1, threshold='0.005Jy',        #  force major cycles every 2000 iterations
     model=['field_7c'],
     residual=['field_7c.residual'],
     image=['field_7c.restored'],
     mask=['orion.mask2'])                 # use a tight mask around emission
                                           # you can generate this with interactivemask
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Maximum Entropy Method Deconvolution (MEM)}
\label{section:imtool.decon.mem}

Maximum entropy and maximum emptiness methods are available. Functions
that implement MEM are {\tt im.mem} and {tt dc.mem}. 

\small
\begin{verbatim}
  im.setdata(mode='channel',       # Select 200 consecutive channels starting
     nchan=200, start=10, step=1)  #  with channel 11
  im.setimage(mode='channel',      # Form an image plane for each
     nchan=200, start=10, step=1)  #  selected channel
  im.mem(algorithm='entropy',      # Select maximum entropy algorithm
     niter=10,                     # niter is smaller than that used in CLEAN as
                                   # it is not the components but the number of
                                   # iterations to maximize the entropy
     sigma=quantity(0.1,'Jy'),     # target noise to achieve in residual image
     targetflux=quantity(10.,'Jy'),# an estimate of the total flux in the image -
                                   # if uncertain, start with 1/10th to 1/2 of the
                                   # expected source flux
     constrainflux=F,              # set this to 'T' if you want the total flux fixed
                                   # to the target flux specified above
     prior='priorimage',           # if available, an image that gives some knowledge of
                                   # how the flux is distributed. This is not necessary.
     image=['maxen.image'],        # output images
     model=['maxen.model'],
     residual=['maxen.resid'],
     mask=['mask.im'])             # If needed you can specify a region to constrain the
                                   # flux
\end{verbatim}
\normalsize

\vspace{3mm}
\noindent {\bf MEM hints}

How to set up MEM so it can converge; how to decide when to stop MEM:

\begin{itemize}

   \item Run MEM with only a few iterations (niter=5-10) and no
         mask. The image will be poor but you can use it to define a
         mask. This is critical as MEM can easily diverge if you have
         complicated emission and no mask. Go through this procedure,
         increasing niter a bit until you have a good mask.

   \item Start with about half of the flux density expected in the
         final image. This allows MEM adequate cycles to achieve
         convergence. If you start with the full known flux density
         MEM may not converge to the correct flux. If you start with
         too little flux density, MEM may obtain a divergent flux. If
         in doubt, start with a small value, and watch the
         convergence. If you get no convergence on the final map flux
         with 20 to 50 iterations, increase the input Target Flux
         until you see MEM behaving reasonably. Note: when using a
         single-dish image as the starting model, the target flux
         should be set to the value of the single-dish flux since this
         is a known, rigid constraint.

   \item Use a sigma input that is about or lower than what you expect
         for the final image. This is not too critical. If it is
         clearly too high, MEM will stop before it has obtained a good
         image. You want to make sure sigma is low enough that MEM
         continues to deconvolve the image until it has converged to a
         good solution. You will probably stop MEM manually anyway
         based on the displayprogress plot.

   \item When you have arrived at good initial inputs to MEM and you
         have a good mask, the displayprogress plot will show
         discontinuities between each major cycle but steadily
         increasing flux.  If, during a cycle, the peak flux and sigma
         show signs of instability (they get a small bump). This is
         the first sign that MEM is digging too deep.  You will want
         to stop MEM before the peak and sigma become unstable.

   \item If you stop the iterations before MEM gets unstale will get
         you a nice flat residual map and a good deconvolved image
         with low background. If you allow MEM to dig deeper, you will
         get increased background, stripes and a worse residual image.

   \item When in doubt, make lots of images and compare. Also, compare
         MEM with CLEAN or multi-scale CLEAN.
\end{itemize}

The deconvolution methods do not keep a list of CLEAN components in
sequence.  Instead the CLEAN components are immediately added to the
model image.  This allows interoperability of the CLEAN and MEM
algorithms as well the deconvolution functions in the {\tt
Deconvolver} tool.  It also allows editing of the resulting images
using the Image tool.

The deconvolution functions can return the residual and restored
images, as well as the updated model image. In addition, there are
{\tt imager.residual} and {\tt imager.restore} functions that also
compute residual and restored images. The distinction is that in the
former, the residual is that calculated by the deconvolution method at
the end of iteration, whereas the latter returns the residual
calculated by going back to the original visibility data (except for
the cases of multi-field and wide-field algorithms).

An example of using Clark CLEAN deconvolution with the {\tt imager}
tool is given below:

\small
\begin{verbatim}
im.clean(algorithm='clark',     # Clean a single field with Clark clean
     niter=2000, gain=0.2,      #  using 2000 iterations, set loop gain=0.2,
     model=['model_2000'],      #  The model image is called model_2000,
     residual=['residual_2000'],#  the residual image is residual_2000,
     image=['restored_2000'])   #  the final restored image is restored_2000.
                                #  All images are written to disk.
\end{verbatim}
\normalsize

If the model image does not pre-exist it will be created and filled
with the CLEAN delta function components found.  If it does pre-exist
(it may be non-empty (perhaps the result of a prior deconvolution) its
Fourier transform is first subracted.  This is also how you would
continue to CLEAN deeper from a prior run of {\tt clean or mem}.

Note that the model image is updated when this function finishes.
So if it was non-empty on input, you should save a copy first,
if you wish to preserve that model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Multi-scale CLEAN}
\label{section:imtool.decon.msclean}

\vspace{3mm}
\noindent {\bf Background on CLEAN versus Multi-scale CLEAN:} 
Delta function CLEAN algorithms, such as the Clark or Hogbom
algorithms, must use a modest gain factor (traditionally 0.1) in order
to image extended emission in a reasonable manner.  Otherwise,
emissions and sidelobes get confused and error striping can result.

Multi-scale CLEAN algorithms attempt to recognize that the emission in
the sky usually comes in a variety of scale sizes; it decomposes the
image into Gaussians of the specified scale sizes.  This means it does
not spend huge amounts of time CLEANing large extended sources
pretending that they are really collections of delta functions.
However, note: because you are CLEANing multiple scale sizes,
multi-scale CLEAN generally takes longer than CLEAN to run.

The {\tt im.setscales} function allows you to choose these scales,
either with an automatic method (you say how many scales you want) or
by direct specification of the scale sizes in pixels.

Multi-scale CLEAN does not suffer from the same problems as delta
function CLEAN and can use a larger value of the gain factor.
Sometimes an oscillatory pattern will occur in the total cleaned flux
with the peak residuals bouncing back and forth between positive and
negative.  If this occurs, try reducing the gain factor or try
reducing the size of the largest scale.

As an example:

\small
\begin{verbatim}
im.setdata(mode='channel', nchan=15,   # Select 15 channels,
     start=10, step=1,                 #  starting with channel 11, use
     spwid=2, fieldid=3)               #  spectral window 3 and field 4
im.setimage(nx=600, ny=600,            # Set up the imaging parameters
     cellx=quantity(0.5,'arcsec'),     #  Combine all channels into a single
     celly=quantity(0.5,'arcsec'),
     mode='mfs',                       #  plane using multi-frequency synthesis.
     spwid=2, fieldid=3))
im.setscales(scalemethod='nscales',    # Set up multi-scale components
     nscales=3)                        # Specify number of scales, allow imager
                                       #  to determine the scale sizes.
im.clean(algorithm='msclean',          # Deconvolve using multi-scale CLEAN
           model=['model'],            #  Call the model image 'model' and
           image=['restored'],         #  restored image 'restored'
           niter=100, gain=0.3)        #  clean down 100 iterations using a gain loop
                                       #  of 0.3.
\end{verbatim}
\normalsize

\vspace{3mm}
\noindent {\bf Multi-scale CLEAN hints}

\begin{itemize}

   \item Use im.setscales to set scalemethod='uservector'. Look at the
         general distribution of emission and choose scales that are
         appropriate for the emission (e.g., start with 0 and 3
         pixels; add scale sizes until the largest scale is about the
         size of the largest diffuse clump in the map). For example,
         assume you have emission that covers a 4 arcminute area, and
         there is significant diffuse emission that looks like it has
         a size scale of about 30 - 40 arcseconds. With 1 arcsecond
         pixels, choose deconvolution scales of [0,3,10,30]
         pixels. You can go smaller (e.g., [0,2,5,10]), but don't go
         much larger.

   \item The more scale sizes you choose, the more memory it will take
         to deconvolve the image. Be conservative.

   \item The largest scale you choose should fit in any deconvolution
         masks you set (or multi-scale CLEAN will not be able to use
         the largest scale).

   \item If you have a mosaic where the fields are not sampled very
          quickly (e.g., field uv coverages differ somewhat) then the
          PSF will also differ between fields, sometimes
          significantly. CASA finds an average PSF that is common to
          all fields and cleans down to a certain level in each major
          cycle.  In almost any mosaic that is taken with current
          instrumentation, fields are observed at different times and
          can be observed at slightly different frequencies. Thus, the
          PSFs between fields will differ enough that convergence in
          multi-scale CLEAN can be challenging. Try: in
          imager.setmfcontrol, start with cyclefactor=3 and
          cyclespeedup=500.

   \item While multi-scale CLEAN is running, watch the progress. If
         there is significant large-scale emission, initial major
         cycles will only get flux on the largest scale. As the number
         of cycles increase, more scales will begin to accumulate
         flux. Eventually, smaller scales will go negative; don't
         panic. The smaller scales are compensating for errors in the
         large scale flux distribution. Stop the iterations when you
         see minimal or negative flux on all scales. We recommend
         using the im.setmfcontrol method with the
         stoplargenegatives=-1 setting.  Notice as the number of
         iterations increases, the final threshold obtained in the
         residual image decreases.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Mosaicing}
\label{section:imtool.mosaic}

The Fourier transform relationship between the Fourier plane and
the image plane must include the primary beam:

$ V(u) = \int A(x) I(x) e^{-i2 \pi u x} dx $

Where $V(u)$ is the measured visibilities; $A(x)$ is the primary beam
response; and $I(x)$ is the true brightness distribution on the sky.

Hence, given the image, one can simulate the corresponding $uv$
data.  However, given the data and desiring the image, we have an
inverse problem to solve.

Early attempts at mosaicing treated each field independently,
deconvolving and self-calibrating each, and then sewing the overlapping
fields' images together via the basic mosaicing equation:

$I(x) = \frac{ \sum_f I_{f}(x)  A_{f}(x) } { \sum_f A^{2}_{f}(x) }.$

Where the subscript $f$ refers to each field in the mosaic.  However,
Cornwell (1988) demonstrated that better results can be obtained via a
simultaneous deconvolution of the data from all the fields.  This
simultaneous deconvolution was achieved by using maximum entropy (MEM)
or maximum emptiness as a solution engine to solve the inverse
problem.  Total power could be added as additional fields with their
own primary beam.  However, MEM's positivity bias, which is
detrimental to low SNR imaging, led to a search for other algorithms
to image multi-field data.

Sault et al. (1996) have implemented mosaicing algorithms which
can use either CLEAN or MEM for simultaneous deconvolution.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The CASA Mosaicing Algorithm}
\label{section:imtool.mosaic.algorithm}

Cornwell, Holdaway, and Uson (1994) proposed the following mosaicing
algorithm: generate the mosaic of the dirty images and a single
approximate point-spread function (PSF), and then proceed with any
conventional single field deconvolution algorithm.  For high-quality
Fourier-plane coverage and similar PSF's for all fields in the mosaic,
this approach is not limited by the differences in the approximate PSF
and each field's actual PSF until the possible image dynamic range
exceeded a few hundred to one.

CASA takes this approach to mosaicing a step further: perform
an incremental deconvolution of the residuals with the approximate PSF,
with an exact subtraction of the cumulative model brightness
distribution at the end of each incremental ``major cycle''
(similar in concept to the major cycles of the Clark CLEAN).

If all of the fields are observed with many short snapshots over and
over again (this is the preferred way to make a mosaic observation)
then each field will have similar Fourier coverage and hence similar
synthesized beams.  An approximate PSF can be created which is a
fairly good match to the actual PSF of each of the fields.  Also, if
the sky-coverage of the observed fields is Nyquist or better, then the
approximate, shift-invariant PSF will be a reasonable match to the
actual PSF of sources at various locations across the mosaic.  The
residual visibilities from each field can be transformed and mosaiced
to make a single residual mosaic image.  This mosaic image can be
deconvolved with the deconvolution method of your choice; for example,
with Clark CLEAN, Multiscale CLEAN, maximum entropy, or maximum
emptiness.

The deconvolution algorithm cannot deconvolve arbitrarily deeply,
because at some level the discrepancies between our approximate
shift-invariant PSF and the true PSF at any location in the image will
become apparent, and we will start ``cleaning'' error flux.  Hence, we
need to stop deconvolving when we have gotten down to the level of
these PSF discrepancies.  At this point, we take the part of the model
brightness distribution we have just deconvolved and calculate model
visibilities (using the measurement equation) and subtract them from
the (corrected) data visibilities.  To the extent that the primary
beam and sky pointing are exact, the visibility subtraction is also
exact.  The residual visibilities can then be re-mosaiced, but the
peak residual is at a much lower level.  The process of deconvolving
with the approximate, shift-invariant PSF then continues, and another
increment to the model brightness distribution is formed, removed from
the remaining residual visibilities, and added to the cumulative model
brightness distribution.  Borrowing from the Clark CLEAN's
terminology, we call each cycle of incremental deconvolution and exact
visibility subtraction a ``major cycle''.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{How to Set Up a Mosaic Image}
\label{section:imtool.mosaic.set}

\subsubsection{Set the Data Fields}
\label{section:imtool.mosaic.set.fields}

Mosaicing can be a time consuming process, so it may be worthwhile to make
a restricted version of the mosaic first.  For example, you may want to
image a few fields at lower resolution to reduce the number of
pixels you are imaging.  Eventually, you will want to image most or all
of the observed fields. Use the {\tt setdata} function to restrict the
data over which you will generate your image, e.g.,

\small
\begin{verbatim}
  im.setdata(fieldid=range(0,4))       # Select first 4 fields
\end{verbatim}
\normalsize

\vspace{3mm}
\noindent {\bf Set the Image}

One of the fields must be specified in {\tt im.setimage} to provide
the direction of the resultant image's reference pixel.  For example,
with a 25 pointing (5 x 5 raster) observation, field 13 could be the
central field:

\small
\begin{verbatim}
  im.setdata(fieldid=range(0,25))    # Select all 25 pointings
  im.setimage(nx=256, ny=256,        # Create a 256x256 resultant image
     cellx=quantity(3.,"arcsec"),    # Choose a cell size of 3x3 arcseconds
     celly=quantity(3.,"arcsec"),
     fieldid=12)                     # Select field 13 as the center
\end{verbatim}
\normalsize

\subsubsection{Setting the Voltage pattern (primary beam)}
\label{section:imtool.mosaic.set.pb}

We must account for the primary beam pattern when imaging the same
region but from different pointings. CASA currently has primary beam patterns stored for:

\begin{enumerate}
   \item ATCA
   \item GBT
   \item GMRT
   \item HATCREEK
   \item NMA
   \item NRAO12M
   \item NRAO140FT
   \item OVRO
   \item VLA
   \item WSRT
   \item OTHER
\end{enumerate}

in addition, there are specific beams available for each of the following:

\begin{enumerate}
   \item ATCA\_L1, ATCA\_L2, ATCA\_L3, ATCA\_S, ATCA\_C, ATCA\_X, GBT, GMRT,
   HATCREEK, NRAO12M, NRAO140FT, OVRO, VLA, VLA\_INVERSE, VLA\_NVSS,
   VLA\_2NULL, VLA\_4, VLA\_P, VLA\_L, VLA\_C, VLA\_X, VLA\_U, VLA\_K, VLA\_Q,
   WSRT, WSRT\_LOW 
\end{enumerate}

\small
\begin{verbatim}
im.setvp(dovp=T)  # dovp=do the voltage pattern correction
                    # this will default to use the voltage pattern for the
                    # telescope used and frequency observed. If no such
                    # default exists, a warning is issued.
\end{verbatim}
\normalsize

although rare, if a voltage pattern is not provided, you can specify
your own voltage pattern and bind it to the telescopes in a
MeasurementSet by using the {\tt vpmanager} (voltage pattern
manager. The Vpmanager will produce a table describing the different
telescopes' voltage patterns, and this table can be used by Imager.
 
See the vpsection of the User Reference Manual for details: 
\small
\begin{verbatim}
http://aips2.nrao.edu/stable/docs/user/SynthesisRef/node228.html
\end{verbatim}
\normalsize

\subsubsection{Mosaic Weighting}
\label{section:imtool.mosaic.set.wt}

If you use ``uniform'' or ``briggs'' weighting, the weighting details
will depend upon the way the data are gridded.  However, if all fields
are specified in function {\tt setdata}, then the weights from all
fields will be gridded onto a single grid for the purposes of
calculating the weights.  This is valid for natural weighting but will
not be valid for other types of weighting.  You probably want to
weight the data on a field-by-field basis:


\small
\begin{verbatim}
  im.weight(type="uniform",mosaic=T)  # This will weight each field separately
\end{verbatim}
\normalsize

\vspace{3mm}
\noindent {\bf Mosaic Options}

For mosaicing, there is a key option which can be used. In particular,
the gridding can use the primary beam as the convolution function. This
is achieved using the option {\tt ftmachine="mosaic"}.

\small
\begin{verbatim}
  im.setoptions(ftmachine='mosaic')   # do a mosaic gridding
\end{verbatim}
\normalsize

The normal gridder uses a spheroidal function to grid the data. For
mosaics, using the Fourier transform of the primary beam as the
gridding function has some advantages.

After a major cycle, the primary beam correction using the mosaic
gridder leaves the (uncleaned) noise floor flat while it gets the
deconvolved component scaled properly for flux scale. The use of the
spheroidal gridding function, after correcting for the primary beam,
tends to lift the noise at the edge of the beams and thus is
non-optimal for images with emission extending to the edge of the
mosaic.

In addition, controls are available using the {\tt setmfcontrol}
function to help adjust the cycle parameters (the conditions for
ending the deconvolution cycles) for multi-field (and wide-field)
imaging.

\small
\begin{verbatim}
  # Set the image plane flux scale type to "SAULT"
  # Set a cutoff for the minimum primary beam level to use
  # constpb is used for SAULT weighting to set the flux scale constant above
  # this level.
  im.setmfcontrol(scaletype='SAULT', # This selects Sault weighting which uses a
                                     # primary beam function that is flat across most
                                     # of the mosaiced image but is attenuated at
                                     # the edges of the mosaic so that the noise level
                                     # does not become excessive there
                  minpb=0.07,        # minimum primary beam level to use in each field
                  constpb=0.4)       # The noise is constant above this primary
                                     # beam level
\end{verbatim}
\normalsize

\subsection{Mosaic Deconvolution}
\label{section:imtool.mosaic.deconv}

To image and deconvolve, use either imager's CLEAN or MEM functions.
Only algorithms with the ``mf'' prefix will perform multi-field
imaging correctly (i.e. algorithm ``clark'' will grid the data from
all specified fields onto the same grid, resulting in a very confused
image.  CLEAN's mosaicing methods include {\tt mfclark}, {\tt
mfhogbom}, and {\tt mfmultiscale}, while MEM's mosaicing methods
include {\tt mfentropy} and {\tt mfemptiness}.  Some hints for CLEAN
and MEM are provided at \ref{section:imtool.mosaic.details.msclean} and
\ref{section:imtool.mosaic.details.mem}, 
respectively.  A full example of how
to create a mosaic image is given below. A detailed script is given at
the end of this chapter.

\small
\begin{verbatim}
im.open('data.ms')  # load data into imager
                                                # choose all fields (1-10) and all channels
im.setdata(mode='channel', nchan=62, start=0,   # restrict the data to the
     step=1,fieldid=range(0,10), spwid=[0,1])   # first two spectral windows
im.setimage(nx=640, ny=256,                     # select the output image size
     cellx=quantity(0.5,'arcsec'),              # and cell size properties
     celly=quantity(0.5,'arcsec'),stokes='I',
     mode='channel',
     nchan=18,start=2,step=5,fieldid=0,
     spwid=[0,1])                               # do 18 channels starting
                                                # at channel 3 and averaging 5
                                                # channels; use field 1 as the mosaic
                                                # field center
im.setvp(dovp=T)                                # do primary beam correction
im.weight(type="uniform",mosaic=T)              # use uniform weighting for each field
im.setoptions(padding=1.0, ftmachine='mosaic')  # do mosaic gridding
im.clean(algorithm="mfclark" , niter=1000,      # use mfclark algorithm
     gain=0.1, threshold=quantity(0.005,'Jy'),
     model=["src.all.cln.model"],               # stop cleaning at a threshold
                                                # of 0.005 Jy
     image=["srcmos"], residual=["src.all.cln.resid"])
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mosaic Details}
\label{section:imtool.mosaic.details}

\subsubsection{Controlling the Major Cycles}
\label{section:imtool.mosaic.details.cycles}

The key to making the incremental deconvolution in CASA multi-field
imaging successful lies in controlling just how deeply to deconvolve
in the major cycles.  The control parameters discussed here can be set
with{\tt im.setmfcontrol}.  Deconvolving too deeply with the
approximate PSF will waste computation time as slightly different PSF
sidelobes add and subtract components.  Not deconvolving deeply enough
also causes problems as it necessitates more major cycles, again
slowing down the computation time.

\begin{itemize}
  \item by increasing the {\tt cyclefactor}.  The major cycle cleaning
        threshold is a fraction of the peak image residual.  That
        residual fraction is determined by the cyclefactor multiplied
        by the peak negative sidelobe of the approximate PSF.
        Stopping the major cycle cleaning sooner can be accomplished
        by increasing the cyclefactor.  Values ranging between 2 and 4
        are common.

   \item by decreasing the {\tt cyclespeedup}. What if the {\tt
         cyclefactor} is set too low? The cycle threshold as
         calculated above can be made to drift upwards by setting the
         {\tt cyclespeedup}.  The threshold will double every {\tt
         cyclespeedup} iterations in the major cycle until the major
         cycle stops.  If the {\tt cyclespeedup} is less than or equal
         to 0.0, no adjustments to the calculated cycle threshold will
         be made.
\end{itemize}

In addition to these cycle control parameters, which are applicable to
mosaicing with CLEAN, Multi-Scale CLEAN, MEM, or Maximum Emptiness,
there are two more control arguments set by {\tt im.setmfcontrol}
which are applicable only to Multi-Scale CLEAN.  These are {\tt
stoplargenegatives} and {\tt stoppointmode}, which are discussed
below.

\subsubsection{Multi-Scale CLEAN Hints}
\label{section:imtool.mosaic.details.msclean}

Sometimes in the first few iterations of Multi-scale CLEAN in the
mosaicing context, the largest scale will be dominated by large
negative residuals (i.e. this is just the negative bowl, integrated
over the area of the largest clean-component scale).  One way to fix
this is to make the largest scale smaller.  Another way is to use a
tighter mask which excludes finding large scale components in the bowl
region.  And a third, ad hoc way is to stop the major cycle when a
negative component is found on the largest scale.  This allows the
exact subtraction to proceed, often resulting in a reduced bowl level.
Stopping the major cycle upon encountering a negative component on the
largest scale should only be performed on the first few cycles, as
during subsequent cycles small amplitude large scale components may be
required to make adjustments in the image.  The number of cycles for
which stopping when a negative component is found on the largest scale
can be controlled by the parameter {\tt stoplargenegatives} in {\tt
imager.setmfcontrol}.  As smaller scales may require negative
components to correct for errors made by ``over-cleaning'' in the
larger cycles, no restriction should be placed on negative components
from smaller size scales.

\subsubsection{MEM Hints}
\label{section:imtool.mosaic.details.mem}

If there are bright unresolved or barely resolved sources in the field,
it may be advantageous to perform a Clark Clean down to the level of the
peak extended emission, or include a component list in the model,
because MEM does not work well on bright point-like sources.

The maximum entropy/emptiness algorithm has been modified to fit into
the incremental deconvolution/major cycle framework adopted by
mosaicing in CASA.  These algorithms deal with both the incremental
brightness distribution, which it seeks to solve given the approximate
PSF and the residual mosaic image, and the cumulative brightness
distribution for the calculation of the entropy function and its
gradients.  When maximum entropy starts up, it typically takes the
algorithm four or five iterations to ``find itself'' and get the
control parameters set to achieve the proper balance between the
gradients of the entropy and the $\chi^2$.  Once a good balance is
struck, the algorithm makes marked progress towards convergence.  At
the end of a major cycle, the relevant control parameters are saved
and used for the next major cycle.

An example similar to the single field case but with the algorithm
changed to 'mfentropy' for multiple fields:


\small
\begin{verbatim}
im.setdata(mode='channel',         # Select 200 consecutive channels starting at 11
     fields=range(0,10),           # Select 10 mosaic fields
     nchan=200, start=10, step=1)  #
im.setimage(mode='channel',        # Form an image plane for each selected channel
     nx=300,ny=300,                # Create a 300x300 pixel image with
     cellx=quantity(2.,'arcsec'),
     celly=quantity(2.,'arcsec'),  # 2"x2" pixels
     nchan=200,start=10,step=1,    # use all channels selected in setdata
     field=5)                      # Use field 6 as the mosaic center
im.mem(algorithm='mfentropy',      # Select maximum entropy algorithm for mosaic
     niter=10,                     # niter is smaller than that used in CLEAN as
                                   # it is not the components but the number of
                                   # iterations to maximize the entropy
     sigma=quantity(0.1,'Jy'),     # target noise to achieve in residual image
     targetflux=quantity(10.,'Jy'),# an estimate of the total flux in the image -
                                   # if uncertain, use 1/10 of the expected flux
     constrainflux=F,              # set this to 'T' if you want the total flux fixed
                                   # to the target flux specified above
     prior='priorimage',           # if available, an image that gives some knowledge of
                                   # how the flux is distributed. This is not necessary.
     image=['maxen.image'],        # output images
     model=['maxen.model'],
     residual=['maxen.resid'],
     mask=['mask.im'])             # If needed you can specify a region to constrain the
                                   # flux
\end{verbatim}
\normalsize 


\subsubsection{Flux Scale Images}
\label{section:imtool.mosaic.details.fluxscale}

When correcting for the effects of the primary beam to achieve an
accurate and uniform flux scale across the image (i.e.  by dividing by
the primary beam in the case of a single field observation), the noise
and errors at the edge of the mosaic sky coverage are amplified.  The
noise amplification distracts from the visual beauty of the image and
may complicate the image's display and interpretation.

Sault et al (1996) endorse a different image plane weighting in the
mosaicing which results in a constant noise level across the image, but
has a variable flux scale, e.g., for Nyquist sampled mosaics, flux scale
decreases outside of the overlap region of the mosaic field - just as the
single field fluxscale decreases toward the edge of the primary beam.

In CASA an image plane weighting similar to Sault's scheme has been
implemented, but the noise goes to zero outside the region covered by
the primary beams.  The flux scale is position dependent, but it is
mostly flat over most of the mosaic sky coverage (depending on how
{\tt constpb} is set within the {\tt setmfcontrol} function and how
much overlap there is between pointing centers).  In order to get a
constant flux image across the mosaic, one must divide by the
fluxscale image (See Section \ref{chapter:ia} for details
on manipulating images).  The flux scale images can be created by
setting the {\tt fluxscale} argument in Imager's {\tt setmfcontrol}
function (in case an inverse-Sault weighting is needed to correct the
image). Regions outside the multi-field primary beam pattern will have
a zero value.

\subsubsection{Masks with Mosaic Fields}
\label{section:imtool.mosaic.details.masks}

Routinely in single field deconvolution, only the inner quarter of an
image is deconvolved so that the sidelobes from this region can be
correctly subtracted from the entire image.  However, in the
multi-field case, such a restriction usually does not exist.  The
major cycles only deconvolve down to a certain level, fixed by the
sidelobe characteristics of the PSF.  After that, the exact
subtraction of the deconvolved flux is carried out.  Typically, the
exact subtraction is performed by multiplying the brightness
distribution by a field's primary beam, convolving by that field's
exact PSF, multiplying by the primary beam again, and subtracting from
the previous cycle's residual mosaic.  The two primary beam
multiplications ensure that the far out effects of the PSF, which will
not be correct due to the full-image deconvolution, will not effect
the model brightness distribution.

If no mask is used, the major cycle deconvolution algorithms create a
mask from the generalized primary beam pattern of all observed fields,
with zero outside the outermost fields' primary beam main lobes.  If
you don't want this mask for some reason, you should supply your own
mask image.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{An Example Mosaic Script}
\label{section:imtool.mosaic.example}

The following script makes an interferometer-only mosaic image from
the multi-field test measurementset which is distributed with CASA:

\small
\begin{verbatim}
  im.open('XCAS.ms')
  # Use all the data for the mosaic
  im.setdata(mode="none",
             spwid=[1:2], fieldid=[1:7])

  # Use the first field as the image center
  im.setimage(nx=256, ny=256, cellx="3arcsec",
              celly="3arcsec", stokes="I", doshift=F,
              mode="mfs", spwid=[1:2], fieldid=1,  facets=1)

  # Weight each field individually
  im.weight(type="uniform",mosaic=T)

  # Use all the data for the mosaic
  im.setdata(mode="none", nchan=1, start=1, step=1,
             spwid=[1:2], fieldid=[1:7])

  # Using the mosaic gridder that uses the FT of the Primary Beam as the gridding function
  im.setoptions(ftmachine='mosaic')

  # Use the voltage pattern (primary beam) - it will lookup the telescope and use the
  # appropriate PB for the observing frequency
  im.setvp(dovp=T, usedefaultvp=T, dosquint=F)

  # Make a MEM image  (using  mask image) - set names for results
  maskname = ['mem.mask']              # maskname will be mem.mask
  modname = ['mem.model']              # modname will be mem.model
  imgname = ['mem.image']              # imgname will be mem.image
  resname = ['mem.resid']              # resname will be mem.resid
  scalename = ['mem.scale']            # scalename will be mem.scale

  # set some multi-field control parameters.
  im.setmfcontrol(cyclefactor=3.0,  # set to 3.0* max sidelobe * max residual
     cyclespeedup=20.0,             # threshold doubles in this many iterations
     fluxscale=scalename)           # name of fluxscale image
  im.mem(algorithm='mfentropy',     # use multi-field Maximum Entropy algorithm
     niter=80, sigma='0.001Jy',     # number of iterations and target sigma
     targetflux='10.0Jy',           # target flux for final image
     constrainflux=F,               # constrain image to match target flux
     displayprogress=T,  fixed=F,   # display progress, don't keep model fixed
     complist='', prior='',         # set these to blank
     mask=maskname,                 # setup output file names
     model=modname,
     image=imgname,
     residual=resname)

  # Make a multi-scale CLEAN image  for comparison
  modname = ['msclean.model']          # modname will be msclean.model
  imgname = ['msclean.image']          # imgname will be msclean.image
  resname = ['msclean.resid']          # resname will be msclean.resid
  scalename = ['msclean.scale']        # scalename will be msclean.scale

  im.setscales(scalemethod='uservector',  # method by which scales are set
     uservector=[0.0, 3.0, 10.0, 20.0])   # vector of scale sizes in pixels

  ### please note the use of parameter stoplargenegatives
  ### which is set to false to let multi-scale clean to continue despite hitting
  ### a negative on the largest scale

  im.setmfcontrol(cyclefactor=3.0,  # set to 3.0 * max sidelobe * max residual
     stoplargenegatives=-1,         # continue despite negatives
     fluxscale=scalename)           # name of fluxscale image
  im.clean(algorithm='mfmultiscale',# use multi-field multi-scale algorithm
     niter=1000, gain=0.6,          # number of iterations and loop gain
     threshold='0Jy',               # stop cleaning at this threshold
     displayprogress=T, fixed=F,    # display progress, don't keep model fixed
     complist='',                   # name of component list
     mask=maskname,                 # set names for produced files
     model=modname,
     image=imgname,
     residual=resname)

  # unload data from tool
  im.close()
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Imaging combined single dish/synthesis data}
\label{section:imtool.SDcombo}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Methods}
\label{section:imtool.SDcombo.methods}

Below is a list of current methods used to combine single dish and
synthesis data (Stanimirovic 2002).

\begin{itemize}
\item {\bf  Feathering} in the image domain (IMMERGE in miriad,
      IMERG in AIPS, im.feather in CASA). Images are feathered
      together in the Fourier plane. Intermediate size scales are
      down-weighted to give interferometer resolution while preserving
      single-dish total flux density.

      {\it This is the fastest and least computer intensive way to add
	short-spacings. Also the most robust way relative to the other
	3 methods which all require a non-linear deconvolution at the
	end.}

\item {\bf Linear combination} - the single-dish image and the
      interferometer dirty image are linearly combined in the image
      plane, a composite beam is constructed, and the resulting
      composite image is deconvolved with the composite beam. Existing
      packages don't directly support this method but it can be done
      via image manipulation and subsequent deconvolution.

      {\it Straight linear combination is not optimal but this method
	has the advantage that it does not require either Fourier
	transformation of the single-dish data which can suffer
	severely from edge effects, nor deconvolution of the
	single-dish data which is especially uncertain and leads to
	amplification errors.}

\item {\bf Model Image} - use the single-dish image as the starting
      model and subtract this model from the uv data. In the shortest
      uv spacing, the single-dish-sampled structure will be preserved
      in the model information. In the uv overlap region, the source
      structure can be modified from the single-dish flux density
      distribution during deconvolution using the interferometer uv
      data. In the interferometer-only region of the uv-plane, the
      deconvolution will proceed as usual with no single-dish
      constraints.

      {\it this works effectively with good uv overlap (i.e., large
      single-dish).} 

\item {\bf Full Joint Deconvolution} - single-dish and interferometer
      data are gridded together. All regions of the uv-plane are
      jointly deconvolved.

      {\it Theoretically the best way to do short spacing
	correction. This method depends heavily on a good estimate of
	the interferometer and single-dish noise variances.}
\end{itemize}

Note: These techniques rely on images (data and masks) having the same
number of axes. If errors are encountered with complaints about image
shapes, use the image.summary function to look at the input images
axes.

% Examples are provided for adding an axis to an image (\ref{reorder})
% and also for regridding an existing image to another coordinate system
% (\ref{exregrid}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Feathering}
\label{section:imtool.SDcombo.feather}

In the image feathering technique, first the calibrated single-dish
image is corrected for the beam response and the calibrated
interferometric data are Fourier transformed and deconvolved to create
an interferometer-only image.

The feathering technique does the following:

\begin{itemize}
\item The single-dish and interferometer images are Fourier
      transformed.
\item The beam from the single-dish image is Fourier transformed
      (FTSDB(u,v)).
\item The Fourier transform of the interferometer image is multiplied
      by (1-FTSDB(u,v)).  This basically down weights the shorter
      spacing data from the interferometer image.
\item The Fourier transform of the single-dish image is scaled by the
      volume ratio of the interferometer restoring beam to the single
      dish beam.
\item The results from c and d are added and Fourier transformed
      back to the image plane.
\end{itemize}

The term feathering derives from the tapering or down-weighting of the
data in this technique; the overlapping, shorter spacing data from the
deconvolved interferometer image is weighted down compared to the
single dish image while the overlapping, longer spacing data from the
single-dish are weighted down compared to the interferometer image.

The tapering uses the transform of the low resolution point spread
function. This can be specified as an input image or the appropriate
telescope beam for the single-dish.  The point spread function for a
single dish image may also be calculated using {\tt makeimage}.

Advice: Note that if you are feathering large images, be advised to
have the number of pixels along the X and Y axes to be composite
numbers and definitely not prime numbers. In general FFTs work much
faster on even and composite numbers. You may use subimage function of
the image tool to trim the number of pixels to something desirable.

Note: This method is analogous to the AIPS IMERG task and the MIRIAD
immerge task with option 'feather'.

\vspace{3mm}
\noindent {\bf Feathering Example:}

\small
\begin{verbatim}
  im.setvp(dovp=T)                  # Do primary beam correction; it will use the default
                                    # primary beam for the single-dish telescope
                                    # and frequency
  im.feather(image='feathered.image'# Resulting, combined image
    highres='synthesis.image',      # Synthesis image
    lowres='singledish.image')      # Single-dish image
                                    # If the beam response of the single-dish telescope
                                    # is not stored in AIPS++ then, one can optionally
                                    # specify the 'lowpsf' image if  available.
\end{verbatim}
\normalsize

The feather task works on both single plane images and on multi-plane
images (data cubes).  The synthesis and single-dish images must have
the same number of axes however; for example, default images in CASA
have axes of: 1) Direction (e.g., RA) 2) Direction (e.g., Dec), 3)
Stokes (e.g., I), and 4) Spectral (e.g., frequency or velocity). These
axes can be manipulated (added or deleted) as necessary using the {\tt
image} tool; this tool has not yet been ported to CASA .

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{uv-plane Combination}
\label{section:imtool.SDcombo.uvCombo}

There are two principal methods for the uv-plane combination of
single-dish and synthesis data. 

\begin{itemize}
\item Use the single-dish image as a starting model for the
      deconvolution (CLEAN or MEM).
\item Full joint deconvolution of the datasets.
\end{itemize}

\vspace{3mm}
\noindent {\bf Use single-dish image as starting model}

In this first technique, a non-linear combination of the synthesis and
single-dish data is performed in the uv plane. In the CASA
implementation, the single-dish image is used to make a model (clean
component) image which is then used as the starting point for the
deconvolving algorithm to interpolate the missing short baselines.

During the deconvolution step in the CLEAN process, the
interferometric data is extrapolated to shorter spacings.  When
starting CLEAN with a model from a single-dish image, the single-dish
image is Fourier transformed and data in the area of uv-overlap is
compared in a major cycle.  The uv spacings provided by the
single-dish image thus provides information (constraints) which help
to prevent CLEAN from over-extrapolating in this region of the
uv-plane.

The {\tt imager} function, {\tt setsdoptions} can be used to set a
factor by which to scale the single-dish image, if necessary
(typically to convert from K to Jy/beam).

The {\tt sdpsf} parameter (optional) should be used if an external PSF
image of the single dish is needed to calculate the beam parameters of
the primary beam of the dish. This is usually needed if the
single-dish image is from a non standard telescope or the beam is not
in the CASA system; see the example in {\tt feather} -
\ref{section:imtool.SDcombo.feather} for generating a beam in this fashion.

A mask image can be provided to the clean algorithm. This mask image
helps guide the clean (and mem) algorithms and should be chosen
carefully based on the 'known' emission.  

Eventually, it will be possible to create a mask image from an
existing image via an {\tt interactivemask} task.  But this is not
implemented yet.  In CASA you will need to use the {\tt makemask} task
to create simple clean boxes.

There are two ways to get a model from a single-dish image:

\begin{itemize}
\item Directly convert the single-dish image from Jy/beam to Jy/pixel.
\item Deconvolve the single-dish image with MEM or multiscale-CLEAN
      (using large scales only) to obtain a model image (Jy/pixel). 
\end{itemize}

\vspace{3mm}
\noindent {\bf Example}

Example: Directly convert the single-dish image to a model and use
this as a starting model for the deconvolution.

\small
\begin{verbatim}
  im.open(filename='n4826_both.ms')    # Create imager tool using synthesis data
  im.setdata(fieldid=range(0,7),       # Select mosaic fields 1-7
             spwid=[0,1,2])            # Select spectral windows 1-3
  im.setimage(nx=256, ny=256,          # Resultant image will be 256x256
     cellx=quantity(1.,'arcsec'),
     celly=quantity(1.,'arcsec'),      #   with 1" pixels
     stokes='I',                       # Resultant image will be Stokes I
     mode='channel',                   # Define image planes by channel
     nchan=30,                         #   30 planes
     start=46,                         #   Starting with channel 47
     step=4,                           #   Averaging 4 channels
     fieldid=0,                        #   Use fieldid=1 as the phase center reference
     spwid=[0,1,2])                    #   Use spectral windows 1-3
  im.setmfcontrol(scaletype="NONE",    # Set some multi-field processing parameters
                                       #   NONE indicates no scaling
     minpb=0.1)                        #   Level at which the primary beam will be applied
  im.setvp(dovp=T)                     # Do primary beam correction

                                       # Make starting model image from single-dish image
  im.makemodelfromsd(sdimage='n4826_12mchan.im', # specify single-dish image
     modelimage='n4826_joint1',        # specify name of output model image
     maskimage='n4826.mask')           # specify make image

                                       # joint deconvolution and clean
  im.clean(algorithm='mfclark',        # Use multi-field clark algorithm
     model=['n4826_joint1'],           # Use model image generated above as the initial model
     gain=0.2, niter=500)              # set gain and iterations
                                       # you can specify a clean mask if desired - see
                                       # Section 5.3.4.1 on interactivemask
                                       # Note: if the output image name isn't specified, the
                                       # restored image name will be the model image name,
                                       # 'n4826_joint1' appended with '.restored'

  im.close()                           # Close tool
\end{verbatim}
\normalsize

When combining single-dish images (in feather or uv-plane
combination), the single-dish image can be scaled by a factor
(typically to convert from K to Jy/beam) using the {\tt setsdoptions}
function.

\small
\begin{verbatim}
  im.setsdoptions(scale=0.5)
\end{verbatim}
\normalsize

\vspace{3mm}
\noindent {\bf Full Joint Deconvolution}

This functionality is currently under construction.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{References for Single-Dish and Interferometric Data Combination}
\label{section:imtool.SDcombo.refs}

\begin{enumerate}
   \item For a review of techniques see: Stanimirovic, S. 2002,
         astro-ph/0205329, "Short-Spacings Correction from the Single
         Dish perspective".
   \item Emerson, D. T. 1974, {\it MNRAS}, {\bf 169}, 607
   \item Helfer et al., 2003, {\it ApJS}, {\bf 145}, 259, Appendix B
   \item Holdaway, M. A. 1999, in ASP Conf. Ser. 180, Synthesis
         Imaging in Radio Astronomy II, ed. ed. G. B. Taylor,
         C. L. Carilli, \& R. A. Perley (San Francisco: ASP), 401
   \item Stanimirovic, S., Staveley-Smith, L., Dickey, J. M., Sault,
         R. J., \& Snowden, S. 1999, {\it MNRAS}, {\bf 302}, 417 
   \item Vogel, S. N., Wright, M. C. H., Plambeck, R. L., \& Welch,
         W. J. 1984, {\it ApJ}, {\bf 283}, 655 
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Wide Field Imaging}
\label{section:imtool.widefield}

The problem of imaging interferometric data for wide fields involves
correcting for the non-co-planarity of the array when inverting the
visibilities in the Fourier basis.  The distortions in the image
domain increase as a function of distance from the phase center.  This
distortion, if not corrected, limits the imaging dynamic range for
fields with significant emission away from the phase center.  The
measurement equation for such an observation is

$ V(u,v,w)=\int\int I(l,m) e^{2\pi\iota(u l + v m + w \sqrt{1-l^2-m^2})}
\frac{dl dm}{\sqrt{1-l^2-m^2}} $

with the usual meaning for the various symbols.  The two algorithms
in CASA for correcting for the non-co-planarity are called the
``w-projection'' and the ``faceted imaging'' algorithm.

\subsection{W-Projection}
\label{section:imtool.widefield.wproj}

The w-projection algorithm is a matched filter approach.  A set of
filters corresponding to various value of $w$ for the $e^{2\pi\iota w
\sqrt{1-l^2-m^2}}$ term are constructed and applied to the 2D
co-planar visibility function to evaluate the 3D non-co-planarity
visibilities as:

$ V(u,v,w)=G(u,v,w)*V(u,v) $

where $G(u,v,w)$ are the filters.  For fast evaluation of the
left-hand side, $G$ is pre-computed for a discrete set of $w$ with
uniform sampling in $\sqrt{w}$ and the filter corresponding to the
nearest value of the $w$ is used.

This effectively increases the limit before which the errors due to
the non-coplanar array dominates.  The errors in the PSF computed
using the w-projection approach are smaller than those incurred in
using the approximate PSF in the minor cycle of Clark-Clean.
Effectively therefore, Clark-Clean (and its variants) uses one form of
approximate PSF in the minor cycle, while w-projection uses another.
The accuracy of the major cycle in w-projection depends on the
resolution at the which the w-axis is sampled by the filters.  For VLA
L-band imaging, 256 samples along the w-axis is probably sufficient
(set via the {\tt facets} argument of the {\tt setimage()} method of
the {\tt imager}).

\subsection{Faceted Imaging}
\label{section:imtool.widefield.facet}

The tradition approach for wide-field imaging involves approximating
the (curved) sky by a set of tangent planes. The size of the facets is
set such that the 2D approximation of the measurement equation is
valid on each facet. The part of sky covered by each facet is them
imaged and deconvolved in the usual manner by phase rotating the
visibilities to the center of each facet.  The Clean-ed images for
each of the facets are then appropriately rotated and projected onto a
single 2D tangent image.  The accuracy of the major cycle for this
algorithm also depends on the number (and hence the size) of the
facets, but the dependence is different from that of the w-projection
algorithm.

It can be shown that the imaging on each facet in the image domain is
equivalent to a shear operation in the visibility domain.  The CASA
implementation of the faceted imaging algorithm uses this technique,
which effectively does the faceting in the visibility domain rather
than in the image domain.  The functional advantage of this approach is
that the users see (and manage) a single 2D image as against multiple
facet images when the faceting is done in the image domain.  This is a
significant advantage, when using faceted imaging.

\subsection{Comparison of the two methods}
\label{section:imtool.widefield.compare}

The w-projection algorithm can be shown to be about 10x faster than the
faceted algorithm.  The major cost of major-minor cycle based
deconvolution algorithms is the cost of the major cycle.  The dominant
cost of major cycle is in the the prediction of the visibilities, given
a model image.  Typically, in faceted imaging approach, each major
cycle involves predicting the visibilities for each facet.  Though
the facets without any emission need not be predicted saving some
compute time, this saving disappears for typical P- and L-bands fields
which invariable have emission is most facets.

The disadvantage of the w-projection algorithm is that it needs the
entire image for the minor cycle.  Since a single image covers the
entire field of view, this approach requires larger run-time memory.
This can however be relaxed by putting smaller fields around the
dominant flanking sources in the field of view, which can be of
smaller sizes.

\subsection{Example --- Faceted Single Field Imaging}
\label{section:imtool.widefield.exfacet}

A typical script for imaging a Measurement Set named {\tt MS} using the
w-projection algorithm is as follows.  The number of facets in this
case corresponds to the number of discreet values of $w$ for which the
gridding convolution functions are evaluated.  This ultimately
determins the imaging dynamic range.  However since the runtime is
only weakly dependant on the number of facets, setting it to a high
number like 256 is sufficient for VLA L-band imaging.

\small
\begin{verbatim}
    #
    # Set the various paraments of imaging
    #
    MS       = ''                    # Name of the MS

    ALGO     = 'mfclark'             # The algorithm to use for
                                       # deconvolution

    IMSIZE   = [4096,4096]           # The image size

    CELLSIZE = ['2arcsec','2arcsec'] # The cellsize

    SPWID    = [1,2]                 # Spectral windows to image

    FIELDID  = 1                     # Field IDs to image

    NFACETS  = 256                   # No. of w-planes.

    STOKES   = 'I'                   # Stokes value

    MODEL_IMAGE_NAME ='1046.im'      # Name of the image files.
                                     # The restored Clean-ed image
                                     # and the residual imgaes are
                                     # stored in images with
                                     # ``.clean'' and ``.res''
                                     # appended to this name.

    NITER    = 10000                 # No. of Clean components

    THRESHOLD= '100e-3mJy'           # The Cleaning threshold.  The
                                     # iterations are stopped when
                                     # the magnitude of the
                                     # strongest components is lower
                                     # than this value.

    DOINTERACTIVE = F                # Set it to T to do interactive
                                     # box setting in-between iterations.

    im.open(MS)

    im.setdata(spwid=SPWID,fieldid=FIELDID,mode='channel')

    im.setimage(nx=IMSIZE[1],ny=IMSIZE[2],
                cellx=CELLSIZE[1],celly=CELLSIZE[2],
                facets=NFACETS,stokes=stokes,
                spwid=SPWID,fieldid=FIELDID)
                im.setoptions(ftmachine='wproject')

    im.clean(algorithm=ALGO,
             niter=NITER,threshold=THRESHOLD,
             interactive=DOINTERACTIVE,
             model=[MODEL_IMAGE_NAME],
             image=[MODEL_IMAGE_NAME+'.clean'],
             residual=[MODEL_IMAGE_NAME+'.res'])
\end{verbatim}
\normalsize

\subsection{Wide Field Imaging References}
\label{section:imtool.widefield.refs}

See the EVLA Memo: 
\url{http://www.aoc.nrao.edu/evla/geninfo/memoseries/evlamemo67.pdf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
